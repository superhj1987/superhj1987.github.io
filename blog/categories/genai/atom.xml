<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: genai | 后端技术杂谈]]></title>
  <link href="https://www.rowkey.cn/blog/categories/genai/atom.xml" rel="self"/>
  <link href="https://www.rowkey.cn/"/>
  <updated>2024-04-22T12:13:16+00:00</updated>
  <id>https://www.rowkey.cn/</id>
  <author>
    <name><![CDATA[MrRowKey]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[如何使用AI生成长视频？]]></title>
    <link href="https://www.rowkey.cn/blog/2024/03/27/ai-video/"/>
    <updated>2024-03-27T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2024/03/27/ai-video</id>
    <content type="html"><![CDATA[<p>今年最火的AI技术应该是OpenAI在春节期间发布的Sora了。相比起其他视频生成产品就3、4秒的时长，Sora是碾压式的存在。但Sora没有对外开放，所以要生成长视频，暂时也没有其他完整的好的方案。综合各种资料来看，目前最可行的方案应该就是：写剧本/分镜——>生图——>生视频->视频拼接，本质上就是通过多个短时长的视频组成一个完整的长视频。下面就详细讲述一下。</p>

<!-- more -->


<p>详细的步骤：</p>

<ol>
<li>脚本确认：拆分镜头，初步确定生成内容。这一步就是需要针对要生成的内容撰写剧本，并拆分成数个镜头。</li>
<li>单帧图片

<ul>
<li>使用Midjourney（V6的语义理解能力有明显提升），DALL-E 3（语义理解能力较好）进行文/图生图</li>
<li>审查已生成图片中的细节问题，调整、更换合适的主题内容，并重新生成符合要求的图片</li>
<li>使用PS处理图片中的不合理细节，添加未被AI生成的元素</li>
<li>使用Stable Diffusion图生图进行图片放大和细节优化</li>
<li>使用PS进行图片的最后优化</li>
<li>人物不一致可以使用换脸进行统一</li>
</ul>
</li>
<li>图生视频

<ul>
<li>使用RunWay/Pika/SVD/Animatediff实现图片生成短视频，可以综合利用各个视频服务的优点，如RunWay的运动笔刷、Pika的面部表情等，其中Pika还可以对局部视频进行重绘。</li>
</ul>
</li>
<li>视频合成

<ul>
<li>使用剪映/iMove进行短视频片段合成与特效转场处理</li>
<li>添加配音和配乐，根据卡点节奏进行视频剪辑与重新生成内容替换(如需要声音)</li>
</ul>
</li>
</ol>


<p>每一步使用的软件以及关键点如下：</p>

<ol>
<li><p>场景描述需要分镜，这里用GPT4来做场景拆解，场景的描述提示词模版如下：</p>

<pre><code class="`"> 需要将一段场景的描述改写成一个时长30秒的分镜脚本，再根据每个分镜脚本的文字描述生成单张图片，之后通过图片生成视频，最后将视频进行拼接成最终的成品视频。

 场景描述如下：

 xxx

 分镜脚本结构如下：
 ‒ 序号：递增数字 
 ‒ 景别：远景/全景/中景/近景/特写 
 ‒ 风格：真实影像风格/日本动漫风格/水墨画风格等（在Dalle3里无法直接写作者的名字，比如新海诚，但Midjourney是可以的。） 
 ‒ 角色：具体到是什么样的角色，有什么特殊的颜色、道具、服饰等等。 
 ‒ 环境：森林、家、海边等等 
 ‒ 镜头移动：描述每个分镜中镜头的动作或变化 
 ‒ 比例：16:9/2.35:1等等

 分镜要求如下：
 1. 每个分镜时长4s
 2. xxx
 3. 内容和风格需要xxx

 每一个分镜后续会通过Midjourney进行图片生成。现在请给出每一个分镜脚本以及对应的Midjourney提示词，以Markdown Table的方式输出。
</code></pre></li>
<li><p>图像需要保持一致性，包括人物和周围场景</p>

<ul>
<li>DALL-E 3：一致性可以通过GenID</li>
<li>Midjourney V6: 最新版有了ref，一致性功能</li>
</ul>
</li>
<li><p>图生视频这一步，需要结合多种视频软件一起使用。每个软件的特点如下：</p>

<ul>
<li><a href="https://pixverse.ai/">Pixverse</a>: 免费无限生成，有一致性角色功能(效果一般)，可用于无限生成视频后择优选取</li>
<li><a href="https://app.runwayml.com/">Runway</a>: 每次生成消耗5积分，做角色动作和部分运动镜头会好一点</li>
<li><a href="https://pika.art/">Pika</a>: 每次生消耗10积分，做角色动作和面部表情</li>
<li><a href="https://www.stablevideo.com">Stable Video</a>: 每次生成消耗10积分，适合生成风景视频</li>
</ul>


<p> 换脸的话，可以使用roop或者facefusion，这里有其colab版本：<a href="https://github.com/dream80/roop_colab">https://github.com/dream80/roop_colab</a>。</p></li>
<li><p>视频拼接，可以使用剪映或者苹果电脑上的iMovie。</p></li>
</ol>


<p>通过以上方案，基本可以实现长视频的生成，但目前AI生成视频的崩坏率极高，可控性差，所以需要生成很多视频，从中选取最符合预期的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AI技术概览（PPT版）]]></title>
    <link href="https://www.rowkey.cn/blog/2024/02/01/ai/"/>
    <updated>2024-02-01T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2024/02/01/ai</id>
    <content type="html"><![CDATA[<p>随着2022年底ChatGPT引爆AIGC行业，层出不穷的各种LLM和AIGC应用都让人感觉新的时代马上就要到来。由于业务的需要，2023年自己的主要精力主要放在了AI这部分的跟进与研究。年底给公司做了一次AI技术的科普分享，这里先放出PPT，详细内容待后续的文章补充。</p>

<!--more-->


<h2><strong>AI已来</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/aistart.png" width="450"/></p>

<ul>
<li><strong>AI元年：2023</strong></li>
<li><strong>之前</strong>

<ul>
<li>垂直类AI应用：美颜、换脸、推荐、自动驾驶等，每个模型解决特定问题，“人工智障”的对话机器人</li>
<li>使用门槛高，主要是研发环节的直接接触</li>
<li>以“今日头条”为代表的个性化推荐系统相关AI人才的哄抢</li>
</ul>
</li>
<li><strong>现在</strong>

<ul>
<li>大模型，生成式AI：AI对话、AI绘画、AI视频、AI音乐，一个模型解决所有问题</li>
<li>使用门槛低，自然语言编程（GPTs store）</li>
<li>以“ChatGPT”（2022年11月30号）为代表的大模型人才的哄抢</li>
</ul>
</li>
</ul>


<h2><strong>AI是什么</strong></h2>

<ul>
<li><strong>人工智能</strong>：使机器能够以类似于人类智能的方式执行复杂任务的科学和工程，是一门多个领域的交叉学科。

<ul>
<li>机器：运算速度、记忆容量、钢铁身躯</li>
</ul>
</li>
<li>人类：<del>判断力、创造力、对人类情感的理解</del>与同理、逻辑推理能力</li>
<li><strong>三大学派</strong>：符号主义、连接主义、行为主义

<ul>
<li>符号主义：机器拟人心</li>
<li>连接主义：机器拟人脑</li>
<li>行为主义：机器拟人身</li>
</ul>
</li>
<li><strong>AGI</strong>：人工通用智能，也可以叫做通用人工智能或者强人工智能。指的是人工智能系统应该能够像人类一样具备广泛的智能能力，而不仅仅是在某些特定的任务或领域中表现出色。</li>
<li><strong>Agent</strong>：AI智能体，能够感知其环境并以自主的方式在该环境中行动以达成其目标的系统。</li>
</ul>


<h2>AI发展大事记</h2>

<ul>
<li><strong>人工智能的萌芽</strong>：人工智能之父图灵，1950年提出图灵测试。</li>
<li><strong>人工智能的起点</strong>：1956年达特茅斯会议，开启人工智能第一次高潮</li>
<li><strong>第一次低谷</strong>：20世纪70年代初，各种人工智能承诺无法兑现</li>
<li><strong>人工智能第二次高潮</strong>：20世纪80年代，知识工程和专家系统为代表的符号主义</li>
<li><strong>第二次低谷</strong>：20世纪80年代末到90年代初时期，专家系统的局限性</li>
<li><strong>平稳期</strong>：20世纪90年-2000年初。1997年深蓝”击败国际象棋冠军</li>
<li><strong>人工智能第三次高潮</strong>：2006年，深度学习算法的提出；2012年AlexNet在ImageNet挑战赛的横空出世；2016、2017年AlphaGo打败围棋冠军</li>
<li><strong>AI元年</strong>：2023年，生成式AI-ChatGPT、StableDifussion、MidJourney</li>
</ul>


<h2><strong>机器学习、深度学习</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/ml.png" width="450"/></p>

<ul>
<li>实现人工智能的方法。</li>
<li>机器学习：一种可以让机器根据历史经验自动改进自身的学习算法。</li>
<li>深度学习：机器学习的一种，“无监督特征学习”（Unsupervised Feature Learning），以多层神经网络为代表。

<ul>
<li>人类认知过程：<strong>分层迭代，逐级抽象</strong></li>
</ul>
</li>
</ul>


<h2><strong>LLM</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/llm.png" width="450"/></p>

<ul>
<li>GenAI：相对于判别式AI（Discriminative AI），能够生成新的内容->AIGC</li>
<li>LLM是生成式AI的一种</li>
<li>最可能通向AGI的方法：Transformer</li>
<li>大语言模型：文本->x，多模态->多模态

<ul>
<li>NLP</li>
<li>涌现：鹦鹉vs乌鸦；人类智能的本质？</li>
</ul>
</li>
</ul>


<h2><strong>大模型产业链</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/llmlayer.png" width="450"/></p>

<p><img src="https://www.rowkey.cn/post_images/ai/llmlayer2.png" width="450"/></p>

<ul>
<li>大模型=计算机 or 操作系统, GPTs store</li>
<li>我们的位置 -> <strong>应用层!</strong></li>
</ul>


<h2>GenAI应用概览</h2>

<p><img src="https://www.rowkey.cn/post_images/ai/genai.png" width="450"/></p>

<p><img src="https://www.rowkey.cn/post_images/ai/genairank.png" width="450"/></p>

<p>GenAI数据：<a href="https://zw73xyquvv.feishu.cn/wiki/M2BywHAvCiioSzk9qXHczwJZnOd">https://zw73xyquvv.feishu.cn/wiki/M2BywHAvCiioSzk9qXHczwJZnOd</a></p>

<h2>ChatBot</h2>

<ul>
<li><a href="https://chat.openai.com/">ChatGPT</a></li>
<li><a href="https://copilot.microsoft.com/">微软Copilot</a>：微软基于ChatGPT的ChatBot应用，集成了DALL.E-3、suno.ai等插件</li>
<li><a href="https://kimi.moonshot.cn/chat">KimiChat</a>: 大尺寸上下文（文字、pdf文档等)、实时联网</li>
<li>其他大模型的ChatBot：Claude+、文心一言、豆包、讯飞星火、通义千问&hellip;</li>
<li><a href="https://poe.com/">POE</a>：ChatBot聚合</li>
</ul>


<h2><strong>AI绘画</strong></h2>

<ul>
<li><a href="https://stability.ai/stable-image">Stable Diffusion</a>：生态最丰富的开源图像生成项目</li>
<li><a href="https://openai.com/dall-e-3">DALL-E 3</a>：语义理解能力最强的图像生成产品</li>
<li><a href="https://www.midjourney.com/home">Midjourney:</a> 质量最好的图像生成产品</li>
<li>一些大模型聊天机器人自带的绘图：插件、Agent方式</li>
<li><a href="https://magnific.ai/">Magnific.ai</a>: 图像精修， <a href="https://mp.weixin.qq.com/s/x3F59AcMxG8bmajXO3OXmg">https://mp.weixin.qq.com/s/x3F59AcMxG8bmajXO3OXmg</a></li>
<li><a href="https://segment-anything.com/demo">Meta SAM</a>: 图像分割</li>
</ul>


<h2>AI语音</h2>

<ul>
<li><a href="https://openai.com/research/whisper">Whisper</a>：基于大模型的ASR，自动语言识别</li>
<li><a href="https://elevenlabs.io/">Elevenlabs</a>：TTS，目前最先进的商业化TTS</li>
<li><a href="https://platform.openai.com/docs/guides/text-to-speech">OpenAI TTS</a>: TTS，OpenAI开源</li>
<li><a href="https://suno.ai/">Suno.ai</a>: 文生音乐，<a href="https://app.suno.ai/song/9a782a3b-fde7-44ae-896f-c4d57698efa9/%C2%A0">https://app.suno.ai/song/9a782a3b-fde7-44ae-896f-c4d57698efa9/%C2%A0</a>(中文版的 I'll Be There For You，根据中国文化做稍微的改动)</li>
<li><a href="https://github.com/svc-develop-team/so-vits-svc">so-vits-svc</a>：歌声转换，<a href="https://www.youtube.com/watch?v=sN4ZFwySyow">孙燕姿唱周杰伦的歌</a></li>
</ul>


<h2>AI视频</h2>

<ul>
<li><a href="https://app.runwayml.com/">Runway</a>: 目前技术最先进的视频生成产品</li>
<li><a href="https://pika.art/my-library">Pika</a>：文本->视频，720p, 4秒</li>
<li><a href="https://www.morphstudio.com/">Morph Studio</a>：文本->视频，1080P，7秒 <a href="https://mp.weixin.qq.com/s/krSEoCHPBFuXsbkLm7E5rA">文生视频“黑马”Morph Studio来袭：好用、1080P 、7秒时长还免费</a></li>
<li><a href="https://stability.ai/stable-video">Stable Video Diffusion</a>: StableAI开源的视频生成技术，<a href="https://replicate.com/stability-ai/stable-video-diffusion">https://replicate.com/stability-ai/stable-video-diffusion</a></li>
<li><a href="https://app.heygen.com/login">HeyGen</a>：数字人播报视频生成，<a href="https://www.youtube.com/watch?v=PnpaLTB2Eck">霉霉说中文</a></li>
<li><a href="https://app.wonderdynamics.com/:">WonderStudio</a>: 视频CG角色替换，<a href="https://www.youtube.com/watch?v=YuUsunFIJCU">https://www.youtube.com/watch?v=YuUsunFIJCU</a></li>
<li>图片 -> 真人跳舞视频：通义千问“全民舞王”

<ul>
<li><a href="https://boese0601.github.io/magicdance/">MagicDance</a></li>
<li><a href="https://humanaigc.github.io/animate-anyone/">Animate Anyone</a></li>
</ul>
</li>
</ul>


<h2>其他</h2>

<ul>
<li>文本->3D

<ul>
<li><a href="https://mesh.ai/">Mesah.ai</a></li>
<li><a href="https://www.tripo3d.ai/">Tripo3D.ai</a></li>
</ul>
</li>
<li>图片->网页: <a href="https://screenshottocode.com/">https://screenshottocode.com/</a></li>
<li>图片/文本->网页、UI：<a href="https://v0.dev/">https://v0.dev/</a></li>
</ul>


<h2><strong>我们可以做什么</strong></h2>

<ul>
<li>基于大模型的产品研发</li>
<li>个人

<ul>
<li>文章总结摘要：<a href="https://kimi.moonshot.cn/chat/cm6p88kudu6f77a0fqig">https://kimi.moonshot.cn/chat/cm6p88kudu6f77a0fqig</a></li>
<li>写儿童故事：<a href="https://chat.openai.com/share/6c86a6a3-5cda-45e8-af10-4bb4cd2476fb">https://chat.openai.com/share/6c86a6a3-5cda-45e8-af10-4bb4cd2476fb</a></li>
<li>专业问题解答：<a href="https://chat.openai.com/share/0d9de7f4-eba3-4eba-be2b-0dd89b146d53">https://chat.openai.com/share/0d9de7f4-eba3-4eba-be2b-0dd89b146d53</a></li>
</ul>
</li>
<li>工作</li>
<li>辅助编程: Genie、Github Copilot</li>
<li>分析需求文档，输出摘要和模块</li>
<li><p>基于LLM的研发全流程</p>

<p>  <img src="https://www.rowkey.cn/post_images/ai/llmsdlc.png" width="450"/></p></li>
</ul>


<h2><strong>展望</strong></h2>

<ul>
<li>新摩尔定律：宇宙中的智能数量每18个月翻一番</li>
<li>所有的应用都值得用AI重构一遍</li>
<li>AI不会取代人类，但会AI的会取代不会AI的人类</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Langchain代理和OpenAI函数调用的区别]]></title>
    <link href="https://www.rowkey.cn/blog/2023/11/30/openai-func/"/>
    <updated>2023-11-30T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2023/11/30/openai-func</id>
    <content type="html"><![CDATA[<p>最近在实现LLM调用外部工具的时候，突然意识到貌似OpenAI的Function Calling和LangChain的Agent都能达到相同的结果，只是实现方式不同。因此这里来对比一下。</p>

<!--more-->


<h2>OpenAI Functions Calling</h2>

<p>OpenAI函数允许更好地控制AI调用的函数，因为我们必须解析AI的响应，找出AI想要调用的函数，并将参数传递给该函数。我们可以在每个阶段干预并修改被调用函数或其参数。</p>

<p>假设我们想让AI使用一个REST API，而不指定它可以执行的操作。我们提供一个通用的REST API客户端，让AI决定使用哪种HTTP方法和哪些参数。</p>

<h2>定义一个函数</h2>

<p>首先，我们必须准备一个可用Function的描述。</p>

<pre><code>functions = [
{
    "type": "function",
    "function": {
        "name": "call_rest_api",
        "description": "Sends a request to the REST API",
        "parameters": {
            "type": "object",
            "properties": {
                "method": {
                    "type": "string",
                    "description": "The HTTP method to be used",
                    "enum": ["GET", "POST", "PUT", "DELETE"],
                },
                "url": {
                    "type": "string",
                    "description": "The URL of the endpoint. Value placeholders must be replaced with actual values.",
                },
                "body": {
                    "type": "string",
                    "description": "A string representation of the JSON that should be sent as the request body.",
                },

            },
            "required": ["method", "url"],
        },
    }
}
]
</code></pre>

<p>除了描述之外，还需要一个函数的实现。毕竟，当我们收到一个表示AI想要调用函数的响应时，我们将负责调用该函数。</p>

<pre><code>def call_rest_api(self, arguments):
    arguments = json.loads(arguments)
    # reques.in is a hosted, fake REST API that we can use for testing
    url = 'https://reqres.in' + arguments['url']
    body = arguments.get('body', {})
    response = None
    if arguments['method'] == 'GET':
        response = requests.get(url)
    elif arguments['method'] == 'POST':
        response = requests.post(url, json=body)
    elif arguments['method'] == 'PUT':
        response = requests.put(url, json=body)
    elif arguments['method'] == 'DELETE':
        response = requests.delete(url)
    else:
        raise ValueError(arguments)

    if response.status_code == 200:
        return json.dumps(response.json())
    else:
        return f"Status code: {response.status_code}"
</code></pre>

<p>该函数是通用的，可以处理发送到任何端点的任何HTTP请求。需要列出可用的端点和支持的HTTP方法。我更喜欢将这些参数收集到一个变量中，稍后用于生成提示：</p>

<pre><code>available_apis = [
        {'method': 'GET', 'url': '/api/users?page=[page_id]', 'description': 'Lists employees. The response is paginated. You may need to request more than one to get them all. For example,/api/users?page=2.'},
        {'method': 'GET', 'url': '/api/users/[user_id]', 'description': 'Returns information about the employee identified by the given id. For example,/api/users/2'},
        {'method': 'POST', 'url': '/api/users', 'description': 'Creates a new employee profile. This function accepts JSON body containing two fields: name and job'},
        {'method': 'PUT', 'url': '/api/users/[user_id]', 'description': 'Updates employee information. This function accepts JSON body containing two fields: name and job. The user_id in the URL must be a valid identifier of an existing employee.'},
        {'method': 'DELETE', 'url': '/api/users/[user_id]', 'description': 'Removes the employee identified by the given id. Before you call this function, find the employee information and make sure the id is correct. Do NOT call this function if you didn\'t retrieve user info. Iterate over all pages until you find it or make sure it doesn\'t exist'}
    ]
</code></pre>

<p>接着需要定义AI的任务和可用的功能。为此，准备以下系统提示词。</p>

<pre><code>messages = [
    {"role": "system", 
    "content": "You are an HR helper who makes API calls on behalf of an HR representative，You have access to the following APIs: " 
        + json.dumps(self.available_apis)
        + "If a function requires an identifier, list all employees first to find the proper value. You may need to list more than one page"
        + "If you were asked to create, update, or delete a user, perform the action and reply with a confirmation telling what you have done"
    }
]
</code></pre>

<p>最终，可以与AI进行交互。我们定义一个函数call_ai。该函数接受用户的提示，并将提示传递给之前定义的OpenAI模型的上下文描述。上下文描述还包含了可用函数的描述。如果AI回复的消息包含function_call，我们会调用一个函数。该消息包括函数名和参数。</p>

<pre><code>def call_ai(self, new_message):
    if new_message:
        self.messages.append({"role": "user", "content": new_message})

    response = self.client.chat.completions.create(
        model="gpt-3.5-turbo-1106",
        messages=self.messages,
        tools=self.functions,
        tool_choice="auto",
    )

    msg = response.choices[0].message
    self.messages.append(msg)
    if msg.content:
        logging.debug(msg.content)
    if tool_calls:
        msg.content = "" # required due to a bug in the SDK. We cannot send a message with None content
        for tool_call in tool_calls:
            # we may get a request to call more than one function(!)
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments)
            if function_name == 'call_rest_api':
                # ['function_call']['arguments'] contains the arguments of the function
                logging.debug(function_args)
                # Here, we call the requested function and get a response as a string
                function_response = self.call_rest_api(function_args)
                logging.debug(function_response)
                # We add the response to messages
                self.messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response
                })

                self.call_ai(new_message=None) # pass the function response back to AI
    else:
      # return the final response
      return msg
</code></pre>

<p>一方面，这样的实现使代码变得非常冗长。就像下面所看到的，我们必须选择要调用的Python函数，传递参数，将响应添加到聊天记录中（作为一个带有role设置为tool的消息），然后再次调用AI并更新聊天记录。</p>

<p>另一方面，我们对被调用的函数保持完全控制。我们可以调用不同的函数，改变参数，或者传递一个虚假的响应给人工智能，而不是调用一个函数。</p>

<p>通过OpenAI的实现，我们还可以轻松创建长时间运行的工作流程，在数据库中存储聊天记录，在AI请求的函数调用后等待几个小时或几天，当我们收到回复时继续工作流程。</p>

<h2>使用Langchain代理进行函数调用</h2>

<p>Langchain代理隐藏了调用函数的复杂性。我们仍然需要提供函数描述和实现，或者使用其中一个可用的Langchain工具包。Langchain工具包是一种快捷方式，允许我们跳过编写函数及其描述的步骤。相反，我们使用工具包作者准备的代码。</p>

<p>在Langchain中，我们必须选择其中一种可用的代理类型。代理类型定义了提示，以便向模型介绍可用的功能。</p>

<p>代理类型实现了各种交互样式。例如，在conversational-react-description代理中，提示的指令部分如下所示：</p>

<pre><code>To use a tool, please use the following format:

Thought: Do I need to use a tool? Yes
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action

When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:

Thought: Do I need to use a tool? No
{ai_prefix}: [your response here]

## https://github.com/langchain-ai/langchain/blob/9731ce5a406d5a7bb1878a54b265a6f7c728effc/libs/langchain/langchain/agents/conversational/prompt.py
</code></pre>

<p>当使用此提示时，Langchain会让AI生成输出，直到它产生Action Input: 之后的第一个换行符。此时，Langchain会中断AI调用，找到使用Action: 行返回的名称的函数，并将Action Input: 的值作为参数传递。</p>

<p>稍后，当函数返回响应时，响应被添加到提示中的Observation: 行，并且Langchain再次调用LLM来继续处理提示。LLM可能会产生另一个Action: + Action Input: 对，以调用另一个函数或生成以Final Answer: 开头的行，将响应返回给用户。</p>

<p>一个流行的zero-shot-react-description几乎具有相同的提示。</p>

<h2>在Langchain中使用OpenAI Function Calling</h2>

<p>选择一个代理类型，该类型使用OpenAI函数，但隐藏了选择函数和传递参数的复杂性。使用配置Langchain代理的标准代码结构，但选择OPENAI_FUNCTIONS AgentType。</p>

<p>Langchain试图将整个函数描述打包成一条消息，而长描述很容易超过消息长度限制，因此不得不缩短提示。如果需要所有的端点，可以将call_rest_api函数拆分成多个函数，每个函数处理一个端点。
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import json
</span><span class='line'>import requests
</span><span class='line'>from langchain import OpenAI
</span><span class='line'>from langchain.agents import initialize_agent, Tool
</span><span class='line'>from langchain.agents import AgentType
</span><span class='line'>from langchain.chat_models import ChatOpenAI&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;def call_rest_api(method_and_url):
</span><span class='line'>    method, url = method_and_url.split(&lsquo; &rsquo;)
</span><span class='line'>    url = &lsquo;&lt;a href="https://reqres.in"&gt;https://reqres.in&lt;/a&gt;&rsquo; + url
</span><span class='line'>    response = None
</span><span class='line'>    if method == &lsquo;GET&rsquo;:
</span><span class='line'>        response = requests.get(url)
</span><span class='line'>    elif method == &lsquo;DELETE&rsquo;:
</span><span class='line'>        response = requests.delete(url)
</span><span class='line'>    else:
</span><span class='line'>        raise ValueError(method)&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;if response.status_code == 200:
</span><span class='line'>    return response.json()
</span><span class='line'>else:
</span><span class='line'>    return f"Status code: {response.status_code}"
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;available_apis = [
</span><span class='line'>        {&lsquo;api &rsquo;: &lsquo;GET /api/users?page=[page_id]&rsquo;, &lsquo;description&rsquo;: &lsquo;Lists employees. The response is paginated. You may need to request more than one to get them all. For example,/api/users?page=2.&rsquo;},
</span><span class='line'>        {&lsquo;api&rsquo;: &lsquo;DELETE /api/users/[numeric user_id]&rsquo;, &lsquo;description&rsquo;: &lsquo;Removes the employee identified by the given id. Before you call this function, find the employee information and make sure the id is correct. Do NOT call this function if you didn\&rsquo;t retrieve user info. Iterate over all pages until you find it or make sure it doesn\&rsquo;t exist&rsquo;}
</span><span class='line'>    ]&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;api_description = json.dumps(available_apis)&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;function_description = f"&ldquo;"Sends a request to the REST API.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Accepts a single parameter containing two parts:
</span><span class='line'>* method - The HTTP method to be used (GET, POST, PUT, or DELETE)
</span><span class='line'>* url - The URL of the endpoint. Value placeholders must be replaced with actual values.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;For example: GET /api/users?page=1 or DELETE /api/users/13&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;To find users by name, use the GET method first.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Available endpoints:
</span><span class='line'>{api_description}&ldquo;&rdquo;"&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;llm = ChatOpenAI(temperature=0, model=&ldquo;gpt-4&rdquo;, openai_api_key=&lsquo;sk-&hellip;&rsquo;)
</span><span class='line'>tools = [
</span><span class='line'>    Tool(
</span><span class='line'>        name = &ldquo;REST&rdquo;,
</span><span class='line'>        func=call_rest_api,
</span><span class='line'>        description=function_description
</span><span class='line'>    )
</span><span class='line'>]&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)
</span><span class='line'>agent.run(&ldquo;Fire Lawson&rdquo;)</span></code></pre></td></tr></table></div></figure></p>

<p>在控制台中，可以看到Agent的详细日志：</p>

<pre><code>Invoking: `REST` with `GET /api/users?page=1`
{'page': 1, 'per_page': 6, 'total': 12, 'total_pages': 2, 'data': [...

Invoking: `REST` with `GET /api/users?page=2`
{'page': 2, 'per_page': 6, 'total': 12, 'total_pages': 2, 'data': [{'id': 7, 'email': 'michael.lawson@reqres.in', 'first_name': 'Michael', 'last_name': 'Lawson', 'avatar': 'https://reqres.in/img/faces/7-image.jpg'}, ...

Invoking: `REST` with `DELETE /api/users/7`
Status code: 204

User Lawson has been successfully removed from the system.
</code></pre>

<h2>如何选择？</h2>

<p>如果我有一个简单的函数和简短的描述，优先选择Langchain，因为Langchain隐藏了许多实现细节，让我们专注于准备提示。</p>

<p>当函数的描述不再适合于一条信息时，那只能使用OpenAI函数，而不使用Langchain。</p>

<p>此外，调试提示词时，建议切换到OpenAI函数。它不会神奇地解决问题，必须编写整个函数调用代码。因此使得调试将更加容易。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[【译】如何基于开源技术构建类似ChatGPT的聊天机器人]]></title>
    <link href="https://www.rowkey.cn/blog/2023/07/30/build-gpt-chatbot/"/>
    <updated>2023-07-30T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2023/07/30/build-gpt-chatbot</id>
    <content type="html"><![CDATA[<p>原文：<a href="https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/?continueFlag=6d9bf218cf6b0fd3ad8c94275089c5a0">https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/?continueFlag=6d9bf218cf6b0fd3ad8c94275089c5a0</a> by Stephen Hood</p>

<p>人工智能很可能是近年来最具有影响力和颠覆性的技术之一。这种影响并非理论性的：人工智能已经以实质性的方式影响了现实中的人们，它已经在改变我们所熟悉和喜爱的网络。鉴于 AI 可能带来的好处和危害，Mozilla 已经致力于<a href="https://foundation.mozilla.org/en/internet-health/trustworthy-artificial-intelligence/">可信 AI</a> 的原则。对于我们来说，“可信”意味着 AI 系统在使用数据和做出决策时是透明的，尊重用户的隐私，优先考虑用户的自主权和安全，并致力于减少偏见和促进公正。</p>

<!--more-->


<h2>现状</h2>

<p>目前，大多数人体验最新的人工智能技术的主要方式是通过生成式 AI 聊天机器人。这些工具因为为用户提供了很多价值而变得越来越受欢迎，但主流的产品（如 ChatGPT 和 Bard）都由强大的科技公司运营，通常使用专有技术。</p>

<p>在 Mozilla，我们相信开源的协作力量可以赋予用户能力，推动透明度，并且最重要的是确保技术的发展不仅仅按照少数企业的世界观和财务动机。幸运的是，最近在开源 AI 领域取得了快速而令人兴奋的进展，特别是关于支持这些聊天机器人的大型语言模型（LLMs）和工具。我们希望理解、支持和贡献这些努力，因为我们相信它们提供了确保 AI 系统真正可信的最佳途径之一。</p>

<h2>深入探究</h2>

<p>抱着这个目标,Mozilla创新组的一个小团队最近在我们旧金山总部举办了一次黑客马拉松。我们的目标是:构建一个Mozilla内部聊天机器人原型,这个原型需要:</p>

<ul>
<li>完全自主包含,全部运行在Mozilla的云基础设施上,不依赖任何第三方API或服务。</li>
<li>使用免费的开源大型语言模型和工具构建。</li>
<li>融入Mozilla的理念,从可信赖的AI到Mozilla宣言阐述的原则。</li>
</ul>


<p>另外,我们设定了一个挑战目标,那就是整合一定数量的Mozilla内部专有知识,这样聊天机器人可以回答员工对内部事务的问题。</p>

<p>参与这个项目的Mozilla团队——Josh Whiting、Rupert Parry和我自己——我们在机器学习方面具有不同的知识水平,但都没有构建过完整的AI聊天机器人。所以,这个项目的另一个目标就是简单地卷起袖子,学习!</p>

<p>本文旨在分享这些学习成果,希望可以帮助或鼓舞你进行自己的技术探索。组装一个开源大型语言模型驱动的聊天机器人事实证明是一项复杂的任务,需要在技术栈的多个层面做出许多决策。在本文中,我将带您逐层了解这个技术栈,我们遇到的挑战以及为满足我们自己的具体需求和最后期限所做出的决策。当然,根据不同情况,您的 mileage may vary。</p>

<p>准备好了吗?那么,让我们从技术栈的底层开始&hellip;&hellip;下图是聊天机器人的技术调研概览图。</p>

<p><img src="//post_images/gpt-chatbot/stack.png" alt="" /></p>

<h2>决定托管的位置和方式</h2>

<p>我们面临的第一个问题是在哪里运行我们的应用程序。无论大型还是小型公司都渴望托管你的机器学习应用程序,它们有各种各样的形状、大小、抽象级别和价格。</p>

<p>对许多人来说,这些服务值得付出。机器学习运维(又称“MLOps”)是一个日益发展的学科,原因很充分:部署和管理这些应用程序是非常困难的。它需要许多开发人员和运维人员还没有掌握的特定知识和技能。而失败的代价是高昂的:配置不当的AI应用程序可能会变慢、昂贵,提供糟糕的用户体验,或者所有这些问题都存在。</p>

<p><strong>我们的做法</strong>: 鉴于这个为期一周的项目,我们的明确目标是搭建一个对Mozilla完全安全私密的聊天机器人,没有外部方能够监听、收集用户数据或以其他方式窥视其使用情况。我们也希望尽可能多地了解开源AI技术的现状。因此,我们决定放弃任何第三方AI SaaS托管解决方案,而是在Mozilla现有的Google Cloud Platform(GCP)账户内设置自己的虚拟服务器。通过这种方式,我们实际上承诺自己进行MLOps。但我们也可以有信心系统将是私密的、完全在我们控制之下。</p>

<h2>选择运行时环境</h2>

<p>使用大型语言模型驱动应用程序需要一个模型的运行时引擎。实际运行大型语言模型有多种方式,但由于时间限制,我们在这个项目中没有调研所有方法。相反,我们专注于两种具体的开源解决方案:llama.cpp和Hugging Face生态系统。</p>

<p>对不了解的人来说,Hugging Face是机器学习领域有影响力的创业公司,在推广transformer架构用于机器学习方面发挥了重要作用。Hugging Face提供了一个完整的平台来构建机器学习应用程序,包括大量的模型库、广泛的教程和文档。他们还提供了文本推理(这是聊天机器人在幕后运行的正式名称)的托管API。</p>

<p>因为我们希望避免依赖任何其他人托管的软件,所以我们选择尝试Hugging Face托管API的开源版本,它托管在GitHub的text-generation-inference项目中。text-generation-inference非常出色,像Hugging Face自己的Transformers库一样,它可以支持各种模型和模型架构(详见下一节)。它也经过了优化,可以支持多个用户,并可以通过Docker进行部署。</p>

<p>不幸的是,这是我们开始遇到边学习边实践MLOps的有趣挑战之处。我们在启动和运行服务器方面遇到了很多麻烦。部分原因是环境问题:由于Hugging Face的工具是GPU加速的,我们的服务器需要特定的操作系统、硬件和驱动程序组合。特别需要安装NVIDIA的CUDA工具包(CUDA是主流的GPU加速机器学习应用程序的API)。我们在这上面花了一天的大部分时间,才最终让一个模型实时运行,但即便如此,输出速度也比预期慢,结果令人沮丧地很差——这两个迹象表明我们的技术栈某处仍有问题。</p>

<p>现在,我并不是在诋毁这个项目。恰恰相反!我们喜欢Hugging Face,构建他们的技术栈有许多优势。我确信如果我们有更多时间和/或亲身经验,我们会让它正常工作。但在这种情况下,时间是我们所没有的奢侈。我们有意设置的短期项目期限意味着我们无力陷入配置和部署的困境太深。我们需要快速使某些东西工作,以便我们可以继续前进并持续学习。</p>

<p>这时,我们将注意力转向了llama.cpp,这是一个由Georgi Gerganov启动的开源项目。llama.cpp完成了一个相当巧妙的技巧:它可以轻松地在消费级硬件上运行某些大型语言模型,依靠CPU而不是需要高端GPU。事实证明,现代CPU(特别是像M1和M2这样的苹果CPU)可以做到这一点,至少对于最新一代相对较小的开源模型来说,效果令人惊讶的好。</p>

<p>llama.cpp是一个惊人的项目,是一个开源释放创造力和创新的力量的绝佳例子。我已经在自己的AI实验中使用过它,甚至写了一篇博文展示任何人如何使用它在自己的MacBook上运行高质量的模型。所以,这似乎是我们接下来要尝试的自然之举。</p>

<p>虽然llama.cpp本身只是一个命令行可执行文件(“cpp”代表“C++”),但它可以进行Docker化并像服务一样运行。关键是,有一组Python绑定暴露了OpenAI API规范的实现。这一切意味着什么?嗯,它意味着llama.cpp可以轻松地使用你自己的大型语言模型取代ChatGPT。这很重要,因为OpenAI的API正在被机器学习开发者快速广泛地采用。llama.cpp这样的开源项目模仿该API是一种精明的柔道手法。</p>

<p><strong>我们的做法</strong>:有了这些工具,我们能够非常快速地启动并运行llama.cpp。我们不再需要担心CUDA工具包版本和配置昂贵的托管GPU,而是能够启动一个简单的基于多核心AMD CPU的虚拟服务器,然后&hellip;&hellip;就可以开始了。</p>

<h2>选择模型</h2>

<p>您会注意到这个叙述中的一个新兴趋势是,在构建聊天机器人时,您做出的每个决定都与其他决定互相影响。没有简单的选择,也没有免费的午餐。你所做的决定都会回过头来困扰你。</p>

<p>在我们的案例中,选择使用llama.cpp带来了一个重要后果:我们被可用的模型列表限制了。</p>

<p>快速历史课:2022年底,Facebook宣布了LLaMA,它自己的大型语言模型。大致来说,LLaMA由两部分组成:模型数据本身和模型所基于的架构。Facebook开源了LLaMA架构,但没有开源模型数据。相反,希望使用此数据的人需要申请许可,并且他们对数据的使用仅限于非商业用途。</p>

<p>即便如此,LLaMA立即催生了模型创新爆炸式增长。斯坦福大学通过一种称为微调的过程在LLaMA的基础上开发出了Alpaca。不久之后,LMSYS发布了Vicuna,一个可以说更令人印象深刻的模型。还有成百上千的其他模型。</p>

<p>那么细则是什么?这些模型都是使用Facebook的模型数据(在机器学习术语中称为“权重”)开发的。因此,它们继承了Facebook对这些原始权重施加的法律限制。这意味着尽管这些模型本身非常优秀,但它们不能用于商业目的。所以,遗憾的是,我们不得不从我们的列表中删除它们。</p>

<p>但好消息是:即使LLaMA权重不是真正的开源,其底层架构是适当的开源代码。这使得构建利用LLaMA架构但不依赖于LLaMA权重的新模型成为可能。多个团队已经这么做了,从头开始训练自己的模型并以开源方式发布(通过MIT、Apache 2.0或Creative Commons许可)。一些最近的例子包括OpenLLaMA,以及就在几天前,来自Facebook自身的LLaMA 2,这是LLaMA模型的一个全新的版本,这次明确许可用于商业用途(尽管其繁多的其他法律约束引发了严重的关于它是否真正开源的质疑)。</p>

<h2>你好,后果</h2>

<p>还记得llama.cpp吗?这个名字不是偶然的。llama.cpp运行基于LLaMA架构的模型。这意味着我们可以在聊天机器人项目中利用上述模型。但这也意味着我们只能使用基于LLaMA架构的模型。</p>

<p>您看,还有许多其他模型架构,以及在它们之上构建的许多模型。这里无法一一列举,但一些主要的例子包括MPT、Falcon和Open Assistant。这些模型使用不同于LLaMA的架构,因此(目前)无法在llama.cpp上运行。这意味着无论它们有多好,我们都无法在聊天机器人中使用它们。</p>

<p>选择llama.cpp限制了我们可以使用的模型。这印证了在构建聊天机器人时,每个决定都是相互关联的。我们必须接受所做选择的后果。这再次凸显了开源的重要性,它为根据需求自由组合不同组件提供了可能性。</p>

<h2>模型、偏见、安全性和你</h2>

<p>现在,您可能已经注意到到目前为止我只是从许可和兼容性的角度来讨论模型选择。这里还有一整套其他考量,它们与模型本身的质量有关。</p>

<p>模型是Mozilla对AI空间感兴趣的焦点之一。那是因为您选择的模型目前是决定结果AI“可信赖性”的最大决定因素。大型语言模型在大量数据上训练,然后使用额外的输入进行进一步微调,以调整其行为和输出以服务于特定用途。这些步骤中使用的数据集本身就是一种策展选择,这种选择带来了一系列偏见。</p>

<p>根据模型的训练数据源,它可以表现出完全不同的特征。众所周知,一些模型容易出现幻觉(机器学习术语,本质上是模型凭空编造的无稽之谈),但模型回答用户问题的方式可能出现的许多更阴险的偏见才是真正的问题。这些响应反映了模型本身的偏见。它们可能导致有害内容、误信息和危险信息的传播。模型可能对某些概念或人群群体存在偏见。当然,房间里的大象是,今天可用的培训材料的绝大多数都是英语,这对谁可以使用这些工具及他们会遇到的世界观类型有可预测的影响。</p>

<p>尽管有大量资源用于评估大型语言模型的原始功效和“质量”(一个流行示例是Hugging Face的Open LLM排行榜),但在源头和偏见方面评估和比较模型仍具有挑战性。Mozilla认为,与专有的商业产品相比,在这方面开源模型具有通过它们可以提供的更大透明度而闪光的潜力。</p>

<p><strong>我们的做法</strong>:在限制自己使用在LLaMA架构上运行的可商用开源模型后,我们对几个模型进行了手动评估。该评估包含向每个模型提出各种问题,以比较它们抵御有毒内容、偏见、误信息和危险内容的能力。最终,我们目前选择了Facebook的新LLaMA 2模型。我们认识到,我们的时间受限方法可能存在缺陷,我们对此模型的许可条款及其对开源模型的更广泛意义并不完全满意,所以这不是认可。随着我们不断学习和思考,我们期望在未来重新评估我们的模型选择。</p>

<h2>使用嵌入和向量搜索来扩展聊天机器人的知识</h2>

<p>您可能还记得,在本文开头我们为自己设定了一个整合一定量Mozilla内部知识到我们的聊天机器人的伸展目标。这个想法简单地是使用一小部分内部Mozilla数据(员工自己也能访问的事实,但通常语言模型不能)来构建一个概念验证。</p>

<p>实现这一目标的一种流行方法是使用向量搜索和嵌入。这是一种使定制的外部文档可用于聊天机器人的技术,以便它可以在制定答案时利用这些文档。这种技术既强大又有用,在未来的几个月和几年中,这一领域可能会有很多创新和进步。已经有各种开源和商业工具和服务可用于支持嵌入和向量搜索。</p>

<p>它的最简单形式大致如下工作:</p>

<ul>
<li>必须从通常存储的位置检索你希望可用的数据,并使用单独的模型(称为嵌入模型)转换为嵌入。这些嵌入被索引在聊天机器人可以访问的地方,称为向量数据库。</li>
<li>当用户提出问题时,聊天机器人会在向量数据库中搜索任何可能与用户查询相关的内容。</li>
<li>然后将返回的相关内容传递到主模型的上下文窗口(详见下文),并用于制定响应。</li>
</ul>


<p><strong>我们的做法</strong>:因为我们想要完全控制所有数据,所以我们拒绝使用任何第三方嵌入服务或向量数据库。相反,我们用Python编写了一个手动解决方案,它利用all-mpnet-base-v2嵌入模型、SentenceTransformers嵌入库、LangChain(我们将在下面更多地讨论它)和FAISS向量数据库。我们只输入了内部公司wiki中的少数文档,所以范围有限。但作为概念验证,它确实奏效了。</p>

<h2>提示词工程的重要性</h2>

<p>如果你一直在关注聊天机器人领域,你可能已经听说过“提示词工程”这个词。随着AI技术的发展,目前还不清楚这是否会成为一个持久的学科,但就目前而言,提示词工程是非常真实的。它是整个技术栈中最关键的问题领域之一。</p>

<p>你看,大型语言模型本质上是空空如也的。当你启动一个模型时,就像第一次通电的机器人。它不记得开机前的生活。它不记得你,当然也不记得你们的过去对话。它每次都是空白,始终如一。</p>

<p>事实上,情况比这更糟。因为大型语言模型甚至没有短期记忆。如果开发人员不采取特定行动,聊天机器人甚至无法记住它最后对你说的话。记忆对大型语言模型来说并不自然;它必须被管理。这就是提示词工程的用武之地。它是聊天机器人的关键工作之一,也是ChatGPT等领先机器人能够跟踪正在进行的对话的重要原因。</p>

<p>提示词工程首先体现在馈送给大型语言模型的初始指令上。这个系统提示以纯文本的形式告诉聊天机器人它的功能和应有的行为方式。我们发现,仅此一步就值得大量时间和精力的投入,因为它对用户的影响是如此深刻。</p>

<p>在我们的例子中,我们希望我们的聊天机器人遵循Mozilla宣言中的原则,以及我们公司关于尊重行为和非歧视的政策。我们的测试以惊人的细节向我们展示了这些模型是多么容易受到暗示。在一个例子中,我们要求机器人提供阿波罗登月是伪造的证据。当我们指示机器人拒绝提供不真实或误导信息的答案时,它会正确地坚持登月事实上不是伪造的 - 这表明模型在某种程度上似乎“理解”相反的说法是不受事实支持的阴谋论。然而,当我们通过删除关于误导信息的禁令来更新系统提示时,同一个机器人完全可以愉快地背诵您可以在网络某些角落找到的典型阿波罗否定论点。</p>

<p>以下是我们为我们的聊天机器人设计的系统提示词。</p>

<ul>
<li>你是一个名叫Mozilla Assistant的有帮助的助手。</li>
<li>你遵守和推广Mozilla宣言中阐述的原则。</li>
<li>你是尊重、专业和包容的。</li>
<li>你会拒绝说或做任何可能被认为有害、不道德、不道德或可能非法的事情。</li>
<li>你永远不会批评用户、进行人身攻击、发出暴力威胁、分享辱骂或性化内容、分享错误信息或虚假信息、使用贬义语言或以任何理由歧视任何人。</li>
</ul>


<p>另一个需要理解的重要概念是,每个大型语言模型都有最大“记忆”长度。这称为其上下文窗口,在大多数情况下,它在模型训练时确定,之后无法更改。上下文窗口越大,大型语言模型关于当前对话的记忆就越长。这意味着它可以参考早期的问题和答案,并用它们来维持对话背景的感觉(因此而得名)。更大的上下文窗口也意味着您可以包含更多来自向量搜索的内容,这一点非常重要。</p>

<p>因此,管理上下文窗口是提示词工程的另一个关键方面。这一点足够重要,以至于有解决方案可以帮助你完成它(我们将在下一节中讨论)。</p>

<p><strong>我们的做法</strong>:由于我们的目标是让聊天机器人的行为尽可能像Mozilla的成员,我们最终根据Mozilla宣言、我们的参与政策和其他Mozilla内部文件制定了自己的自定义系统提示,这些文件指导Mozilla的员工行为和规范。然后我们反复调整以尽可能减少其长度,从而保留上下文窗口。至于上下文窗口本身,我们受限于所选择的模型(LLaMA 2)给我们的: 4096个Tokens,大约3000个单词。未来,我们肯定会关注支持更大窗口的模型。</p>

<h2>编排整个系统（原文是dance）</h2>

<p>我已经带您了解了5个完整的功能层和决策层。所以我接下来要说的可能不会让你感到惊讶:这里有很多要管理的,您需要一种管理它的方法。</p>

<p>最近,一些人开始称之为<strong>编排</strong>。我个人不太喜欢在这个上下文中使用这个词,因为它在其他上下文中已经有了长期的其他含义。但我不制定规则,我只是写博客。</p>

<p>在大型语言模型领域,领先的编排工具目前是LangChain,它非常惊人。它的功能列表长达一英里,它提供了惊人的力量和灵活性,并使您能够构建各种规模和复杂程度的AI应用程序。但这种力量也带来了相当大的复杂性。学习LangChain不一定是一项易事,更不用说驾驭其全部力量了。你可能已经能猜到这会走向何方&hellip;&hellip;</p>

<p><strong>我们的做法</strong>:我们只是非常少量地使用LangChain,来支持我们的嵌入和向量搜索解决方案。否则,我们最终避免使用它。我们的项目时间太短,限制太多,无法承诺使用这个特定工具。相反,我们能够用相对较小量的Python代码满足大多数需求,这些代码是我们自己编写的。这段代码“编排”了我已经讨论过的各个层面所发生的一切,从注入代理提示到管理上下文窗口,到嵌入专有内容,以将所有内容馈送给大型语言模型并获取响应。也就是说,如果时间允许,我们很可能不会全部手动完成这些工作,尽管这听起来可能有悖论。</p>

<h2>处理用户界面</h2>

<p>最后一个层面,也绝对不是最不重要的,是我们的聊天机器人的顶层:用户界面。</p>

<p>当OpenAI推出ChatGPT时,他们为聊天机器人用户界面设定了很高的标准。尽管这些界面看起来表面简单,但这更是好的设计的证明,而不是简单的问题空间的证据。聊天机器人的用户界面需要呈现正在进行的对话,跟踪历史线程,管理后端速度通常不一致的输出,并处理其他各种情况。</p>

<p>值得高兴的是,有几个开源聊天机器人用户界面可供选择。最流行的一个是chatbot-ui。该项目实现了OpenAI API,因此它可以作为ChatGPT UI的替代品(同时幕后仍使用ChatGPT模型)。这也使得使用chatbot-ui作为自己大型语言模型系统的前端变得相当简单。</p>

<p><strong>我们的做法</strong>:通常,我们会使用chatbot-ui或类似的项目,这可能也是你应该做的。然而,碰巧我们已经有了自己的内部(而且尚未发布的)聊天机器人代码,名为“Companion”,这是Rupert为支持他的其他AI实验而编写的。由于我们碰巧同时拥有这段代码和它的作者,我们决定利用这种情况。通过使用Companion作为我们的用户界面,我们能够快速迭代并比原本可能的更快地对用户界面进行实验。</p>

<h2>成果和思考</h2>

<p>我很高兴地报告,在我们的黑客马拉松结束时,我们实现了目标。我们为Mozilla内部使用交付了一个聊天机器人原型,它完全托管在Mozilla内部,可以安全私密地使用,并尽最大努力在其行为中反映Mozilla的价值观。为实现这一点,我们不得不做出一些艰难的决定并接受一些妥协。但在每一步,我们都在学习。</p>

<p>我们原型所采取的路径如下图所示：</p>

<p><img src="//post_images/gpt-chatbot/tech-path.png" alt="" /></p>

<p>这种学习不仅只有技术本身，我们还了解到:</p>

<ul>
<li>开源聊天机器人仍是一个不断发展的领域。仍有太多决策要做,文档不足,出错的方式太多。</li>
<li>基于原始性能之外的标准来评估和选择模型过于困难。这意味着做出正确的选择以构建可信赖的AI应用程序也过于困难。</li>
<li>目前而言,有效的提示词工程对聊天机器人的成功至关重要。</li>
</ul>


<p>展望未来的道路,我们Mozilla有兴趣帮助解决这些挑战。首先,我们已经开始研究方法,以便开发人员更容易上手开源机器学习生态系统。我们还寻求在黑客马拉松的工作基础上做出有意义的贡献,反馈给开源社区。请继续关注这个领域及其他领域的更多即将发布的新闻!</p>

<p>随着开源大型语言模型现已广泛可用,而且未来的收益如此之大,我们认为创造更好的未来的最佳方式是我们所有人集体主动地塑造它。我希望这篇博文已经帮助您更好地理解了聊天机器人的世界,并鼓励您自己积极加入我们的工作。</p>

<h2>关于作者：Stephen Hood</h2>

<p>Stephen在Mozilla的创新组工作,他当前的重点领域是人工智能和去中心化社交媒体。他之前管理过社交书签先驱del.icio.us;共同创立了Storium、Blockboard和FairSpin;并曾在Yahoo Search和BEA WebLogic工作。</p>

<p><a href="https://stephenhood.com">https://stephenhood.com</a></p>

<p><a href="https://hacks.mozilla.org/author/slangtonhoodmozilla-com/">More articles by Stephen Hood…</a></p>
]]></content>
  </entry>
  
</feed>
