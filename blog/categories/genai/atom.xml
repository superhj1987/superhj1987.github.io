<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: genai | 后端技术杂谈]]></title>
  <link href="https://www.rowkey.cn/blog/categories/genai/atom.xml" rel="self"/>
  <link href="https://www.rowkey.cn/"/>
  <updated>2025-02-26T09:32:24+00:00</updated>
  <id>https://www.rowkey.cn/</id>
  <author>
    <name><![CDATA[HJ]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[DeepSeek简单分享]]></title>
    <link href="https://www.rowkey.cn/blog/2025/02/23/deepseek/"/>
    <updated>2025-02-23T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2025/02/23/deepseek</id>
    <content type="html"><![CDATA[<p>本文内容来自一次内部分享。主要是对目前非常火的DeepSeek的一些自己的认知和理解。</p>

<!-- more -->


<h2>DeepSeek是什么？</h2>

<p>DeepSeek是一个由中国人推出的媲美ChatGPT O1能力的开源推理大模型，其中文能力更强，而且由于背后公司数据的特点，在金融方面具有优势。这里所说的推理大模型是相对于之前的非推理模型，更加强化了推理、逻辑分析和决策能力，可以看做是把之前的CoT能力直接做到了模型里。DeepSeek本身是包括V3和R1两个模型，参数都达到6000亿，也就是现在市面上很多人说的满血版。而DeepSeek开源的几个蒸馏版本的模型其实本质还是qwen和llama，只是用了R1的推理数据做了微调。</p>

<h2>DeepSeek生态位</h2>

<p>综合了各种榜单和一些评测，并基于公司实际使用的经验，对现在主流的大模型做了如下梯队排名：</p>

<p><img src="https://www.rowkey.cn/post_images/deepseek/dp_rank.png" width="450"/></p>

<p>在选择模型时需要注意：</p>

<ul>
<li>开源模型可以私有化部署提供无审查的服务</li>
<li>国内模型在中文上有优势</li>
</ul>


<p>通过这个梯度，也可以看到DeepSeek并不是能力最强的，但R1确实是国内最好的推理模型。而非推理模型国内的通义千问是能力最强的。这里需要提到的一点就是Kimi其实也和DeepSeek差不多同一时间推出了推理模型的，能力也没有差太多，但由于不是完全开源的，所以被DeepSeek给完全盖住了。</p>

<h2>DeepSeek为什么这么火?</h2>

<p>如第一部分所说，本质上DeepSeek是一个中国公司做到了O1水平并且开源了的推理大模型。具体来说，之所以它这么火有以下几点：</p>

<ul>
<li>ChatGPT o1出来后，给业界出了一道题，然后DeepSeek给解出来了，并且是以低成本的方式实现了，甚至还给开源了。</li>
<li>对于国内来说，由于zz原因，很长一段时间是无法使用国外的第一梯队大模型的。所以，有了DeepSeek这种能用的模型，自然是迅速出圈。</li>
<li>对于国外来说，则是高估了领先中国的速度，低估了中国的追赶速度。</li>
</ul>


<h2>为什么是DeepSeek?</h2>

<p>国内外很多大模型厂商，为什么是DeepSeek做出来了呢？</p>

<ul>
<li>DeepSeek背后是幻方量化，这家公司号称多内私募量化四巨头，非常赚钱，有一年就捐了3个亿做慈善。虽然DeepSeek是相对独立的一家公司，但其中的关联肯定小不了，所以大概率是不缺钱的，也不是奔着赚钱去的。因此，可以类似高校一样单纯的做研究。与之相比，Kimi就有商业化的诉求，所以能看到Kimi在大量的投放广告。</li>
<li>DeepSeek的招人门槛很高，虽然创始人是浙大的，但团队成员基本上是清北级别的。</li>
<li>DeepSeek曾号称有国内最多的A100显卡。</li>
<li>创始人梁文峰是很有技术追求的一个人，不管是量化还是大模型，据各种报道，都是自己亲身在一线写代码、写论文的。</li>
<li>我自己的认知，其实OpenAI推出o1后，大家都在研究，都在探索，方法也都有区别，DeepSeek这次做出来是有一点运气成分。</li>
</ul>


<p>这里还想提的是，春节期间所谓的国运一说，我觉得如果DeepSeek在不长的时间能追上甚至超过o3，那真的可以说国运了。</p>

<h2>DeepSeek的创新</h2>

<p>DeepSeek由于受限于显卡的性能（H800），通过工程优化上的创新提升了算法效率，从而也大大降低了成本。</p>

<ul>
<li>DeepSeekMoE：采用了大量细粒度的专家，因此推理时，能大幅降低成本。</li>
<li>负载均衡优化：采用Auxiliary-loss-free算法提高了MoE路由的效率。</li>
<li>内存优化：重计算、使用CPU内存和参数共享</li>
<li>通信优化：DualPipe</li>
<li>计算优化：FP8混合精度训练</li>
<li>其他：MLA(多头潜在注意力)、MTP（多Token预测）、GPRO（强化学习算法）等</li>
<li>NSA：原生稀疏注意力，长文本能力</li>
</ul>


<h2>使用</h2>

<p>推理模型是有使用场景的，适合需要深度思考的场景，如设计、审查、推理、复杂计算等。如果让其做一些简单的任务，如实现代码，可能会思考来思考去，反而降低效率。结合推理模型+非推理模型是现在一种常用的方式，如DeepSeek R1 + Claude 3.5 sonnet就是使用R1来做方案设计，使用Claude来写代码。</p>

<p>不同于之前的非推理模型，推理模型的提示词跟侧重于描述清楚任务目标，过多的引导反而是干扰。</p>

<p>此外，通过DeepSeek对蒸馏模型的证明，一些行业模型也可以通过DeekSeek R1的推理数据来微调，实现蒸馏的效果。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[美国AI之旅]]></title>
    <link href="https://www.rowkey.cn/blog/2024/06/05/usa-ai/"/>
    <updated>2024-06-05T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2024/06/05/usa-ai</id>
    <content type="html"><![CDATA[<p>5月底去了一趟旧金山，和一些华人AI科学家进行了交流，也参加了旧金山由GPTDao和微软联合举办的GenAI大会。这里输出一些收获。</p>

<!-- more -->


<ol>
<li>一个华人科学家分享他们团队在做消费级设备（车载、手机）大模型的创业。苹果最近发布的Apple Intelligence也是类似的思路。之前陈天奇团队做的mlc-llm同样是在做这样的事情，再结合特斯拉的FSD也是基于Transformer的自动驾驶决策，这个方向还是很有机会的。但国内貌似很少听到类似的项目。</li>
<li>Amino: 一家华人创办的VC公司。看到他们投的一家针对美国移民多这一特点的电商平台，每个国家的人进去看到都是来自这个国家的商品，这个估计只有美国是合适的。另外，他们也分享了目前硅谷还是创业者导向的，一个好的创业项目，需要投资人去争取。这家公司的创始人有个抖音号叫硅谷李师傅，在持续分享硅谷的一些东西。</li>
<li>Meta AI：分享了Meta大模型方面的进展，印象比较深刻的是实时图像生成，可以边输入提示词，边生成图像。网址：<a href="https://www.meta.ai/?icebreaker=imagine">https://www.meta.ai/?icebreaker=imagine</a></li>
<li>Tesla：分享了他们在自动驾驶方面的进展。特斯拉的FSD不同于目前主流自动驾驶技术的是使用了基于Transformer的驾驶决策，通过使用保险公司大量驾驶分数好的司机的数据来训练这个模型，对比Waymo基于激光雷达，成本会低非常多。但受限于保密的原因，其他有干货的东西感觉不是很多。</li>
<li>Nvidia: 分享了他们正在开发的多模态大模型。自己这次发现英伟达虽然主要精力在芯片，但其实也在大量地做各种AI模型层、应用层的尝试，包括后来在GenAI会议上Jim Fan讲的具身智能，这里有这个分享的总结：<a href="https://mp.weixin.qq.com/s/DF0GBx99vodq0dYM98iRFA%E3%80%82">https://mp.weixin.qq.com/s/DF0GBx99vodq0dYM98iRFA%E3%80%82</a></li>
<li>听了Google科学家讲述Google在多模态大模型方面的进展。印象比较深的一点，就是现在业界对小公司的包容度大，对大公司包容度小，因此经常会放大谷歌的问题，某种维度上是不公平的。</li>
<li>硅谷的人才流动很频繁，没有什么绝对的技术壁垒，而且硅谷是没有竞业协议的。所以，OpenAI的优势并没有那么绝对。目前谷歌已经从OpenAI挖回来了不少大模型人才。</li>
<li>旧金山GenAI Summit 2024

<ul>
<li>硅谷这边各种小的应用都能支撑起一家创业公司，比如会场在用的otter.ai就是实时记录会议内容，和钉钉、飞书的闪记的功能是一样的。</li>
<li>华人团队做的天机阁AI测算，这个是我们公司比较关注的一个赛道，天机阁的应用体验做的很一般，但测算的体验确实不错。应该是有自己的专有数据的。</li>
<li>Groq的AI加速芯片：在芯片层面提速的AI服务。这个之前贾杨青是质疑过其成本的。</li>
<li>贾杨青的Lepton AI是在做AI云原生，能够快速部署大模型应用。</li>
<li>合成数据对AI发展的重要性：随着现实数据逐渐被用完，需要大量的合成数据来训练模型，这方面目前还存在着很多挑战。</li>
</ul>
</li>
<li>贾杨青分享中提到的理查德·萨顿教授的作品《痛苦的教训》中的一句话："从70年的人工智能研究中可以得出的最大教训是，利用计算的通用方法最终是最有效的，而且差距很大。"

<ul>
<li><strong>通用方法</strong>：在人工智能研究中，通用方法指的是那些可以应用于广泛问题的算法和技术，而不是专门为特定问题设计的解决方案。通用方法通常具有更广泛的适用性和更长的生命周期。</li>
<li><strong>利用计算</strong>：这一点强调了计算能力的重要性。在过去的几十年中，计算机的处理能力和速度有了巨大的提升，这使得复杂的算法和大规模数据处理成为可能。</li>
<li><strong>最有效的</strong>：萨顿教授指出，通用方法结合强大的计算能力，往往比特定问题的专用方法更有效。也就是说，使用计算能力来推动通用算法的发展，能够在更大范围内取得成功，并且效果更显著。</li>
<li><strong>差距很大</strong>：这一点强调了效果上的显著差异。萨顿教授认为，通用方法相对于专用方法，其优势不仅仅是略胜一筹，而是有着明显的、显著的效果提升。</li>
<li>总的来说，萨顿教授的这句话提醒我们，在人工智能领域，应该注重发展那些可以广泛应用的通用算法，并充分利用现代计算技术的力量。这样的方法不仅更为高效，而且在各种不同的应用场景中都能表现出色。</li>
</ul>
</li>
<li>美国对新事物的接受度没有那么高，因此Tesla在美国反而没有国内常见。不过，FSD在美国已经全面推行。打Uber的时候司机开启了FSD，整体感觉还是很丝滑的。</li>
<li>美国的油价挺高的，所以日本车在美国占用率很高，随处可见的也是丰田、本田这些车。</li>
<li>Google的Waymo在旧金山随处可见，有同行的朋友有邀请码体验了一下，驾驶没有任何问题，基本和打普通出租车没有任何区别。但其改造一辆车的成本非常昂贵，后来听朋友说，由于特斯拉的RoboTaxi即将发布，Waymo的很多人都离职了。特斯拉的FSD目前看来才是未来的自动驾驶发展方向。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何使用AI生成长视频？]]></title>
    <link href="https://www.rowkey.cn/blog/2024/03/27/ai-video/"/>
    <updated>2024-03-27T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2024/03/27/ai-video</id>
    <content type="html"><![CDATA[<p>今年最火的AI技术应该是OpenAI在春节期间发布的Sora了。相比起其他视频生成产品就3、4秒的时长，Sora是碾压式的存在。但Sora没有对外开放，所以要生成长视频，暂时也没有其他完整的好的方案。综合各种资料来看，目前最可行的方案应该就是：写剧本/分镜——>生图——>生视频->视频拼接，本质上就是通过多个短时长的视频组成一个完整的长视频。下面就详细讲述一下。</p>

<!-- more -->


<p>详细的步骤：</p>

<ol>
<li>脚本确认：拆分镜头，初步确定生成内容。这一步就是需要针对要生成的内容撰写剧本，并拆分成数个镜头。</li>
<li>单帧图片

<ul>
<li>使用Midjourney（V6的语义理解能力有明显提升），DALL-E 3（语义理解能力较好）进行文/图生图</li>
<li>审查已生成图片中的细节问题，调整、更换合适的主题内容，并重新生成符合要求的图片</li>
<li>使用PS处理图片中的不合理细节，添加未被AI生成的元素</li>
<li>使用Stable Diffusion图生图进行图片放大和细节优化</li>
<li>使用PS进行图片的最后优化</li>
<li>人物不一致可以使用换脸进行统一</li>
</ul>
</li>
<li>图生视频

<ul>
<li>使用RunWay/Pika/SVD/Animatediff实现图片生成短视频，可以综合利用各个视频服务的优点，如RunWay的运动笔刷、Pika的面部表情等，其中Pika还可以对局部视频进行重绘。</li>
</ul>
</li>
<li>视频合成

<ul>
<li>使用剪映/iMove进行短视频片段合成与特效转场处理</li>
<li>添加配音和配乐，根据卡点节奏进行视频剪辑与重新生成内容替换(如需要声音)</li>
</ul>
</li>
</ol>


<p>每一步使用的软件以及关键点如下：</p>

<ol>
<li><p>场景描述需要分镜，这里用GPT4来做场景拆解，场景的描述提示词模版如下：</p>

<pre><code class="`"> 需要将一段场景的描述改写成一个时长30秒的分镜脚本，再根据每个分镜脚本的文字描述生成单张图片，之后通过图片生成视频，最后将视频进行拼接成最终的成品视频。

 场景描述如下：

 xxx

 分镜脚本结构如下：
 ‒ 序号：递增数字 
 ‒ 景别：远景/全景/中景/近景/特写 
 ‒ 风格：真实影像风格/日本动漫风格/水墨画风格等（在Dalle3里无法直接写作者的名字，比如新海诚，但Midjourney是可以的。） 
 ‒ 角色：具体到是什么样的角色，有什么特殊的颜色、道具、服饰等等。 
 ‒ 环境：森林、家、海边等等 
 ‒ 镜头移动：描述每个分镜中镜头的动作或变化 
 ‒ 比例：16:9/2.35:1等等

 分镜要求如下：
 1. 每个分镜时长4s
 2. xxx
 3. 内容和风格需要xxx

 每一个分镜后续会通过Midjourney进行图片生成。现在请给出每一个分镜脚本以及对应的Midjourney提示词，以Markdown Table的方式输出。
</code></pre></li>
<li><p>图像需要保持一致性，包括人物和周围场景</p>

<ul>
<li>DALL-E 3：一致性可以通过GenID</li>
<li>Midjourney V6: 最新版有了ref，一致性功能</li>
</ul>
</li>
<li><p>图生视频这一步，需要结合多种视频软件一起使用。每个软件的特点如下：</p>

<ul>
<li><a href="https://pixverse.ai/">Pixverse</a>: 免费无限生成，有一致性角色功能(效果一般)，可用于无限生成视频后择优选取</li>
<li><a href="https://app.runwayml.com/">Runway</a>: 每次生成消耗5积分，做角色动作和部分运动镜头会好一点</li>
<li><a href="https://pika.art/">Pika</a>: 每次生消耗10积分，做角色动作和面部表情</li>
<li><a href="https://www.stablevideo.com">Stable Video</a>: 每次生成消耗10积分，适合生成风景视频</li>
</ul>


<p> 换脸的话，可以使用roop或者facefusion，这里有其colab版本：<a href="https://github.com/dream80/roop_colab">https://github.com/dream80/roop_colab</a>。</p></li>
<li><p>视频拼接，可以使用剪映或者苹果电脑上的iMovie。</p></li>
</ol>


<p>通过以上方案，基本可以实现长视频的生成，但目前AI生成视频的崩坏率极高，可控性差，所以需要生成很多视频，从中选取最符合预期的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AI技术概览（PPT版）]]></title>
    <link href="https://www.rowkey.cn/blog/2024/02/01/ai/"/>
    <updated>2024-02-01T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2024/02/01/ai</id>
    <content type="html"><![CDATA[<p>随着2022年底ChatGPT引爆AIGC行业，层出不穷的各种LLM和AIGC应用都让人感觉新的时代马上就要到来。由于业务的需要，2023年自己的主要精力主要放在了AI这部分的跟进与研究。年底给公司做了一次AI技术的科普分享，这里先放出PPT，详细内容待后续的文章补充。</p>

<!--more-->


<h2><strong>AI已来</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/aistart.png" width="450"/></p>

<ul>
<li><strong>AI元年：2023</strong></li>
<li><strong>之前</strong>

<ul>
<li>垂直类AI应用：美颜、换脸、推荐、自动驾驶等，每个模型解决特定问题，“人工智障”的对话机器人</li>
<li>使用门槛高，主要是研发环节的直接接触</li>
<li>以“今日头条”为代表的个性化推荐系统相关AI人才的哄抢</li>
</ul>
</li>
<li><strong>现在</strong>

<ul>
<li>大模型，生成式AI：AI对话、AI绘画、AI视频、AI音乐，一个模型解决所有问题</li>
<li>使用门槛低，自然语言编程（GPTs store）</li>
<li>以“ChatGPT”（2022年11月30号）为代表的大模型人才的哄抢</li>
</ul>
</li>
</ul>


<h2><strong>AI是什么</strong></h2>

<ul>
<li><strong>人工智能</strong>：使机器能够以类似于人类智能的方式执行复杂任务的科学和工程，是一门多个领域的交叉学科。

<ul>
<li>机器：运算速度、记忆容量、钢铁身躯</li>
</ul>
</li>
<li>人类：<del>判断力、创造力、对人类情感的理解</del>与同理、逻辑推理能力</li>
<li><strong>三大学派</strong>：符号主义、连接主义、行为主义

<ul>
<li>符号主义：机器拟人心</li>
<li>连接主义：机器拟人脑</li>
<li>行为主义：机器拟人身</li>
</ul>
</li>
<li><strong>AGI</strong>：人工通用智能，也可以叫做通用人工智能或者强人工智能。指的是人工智能系统应该能够像人类一样具备广泛的智能能力，而不仅仅是在某些特定的任务或领域中表现出色。</li>
<li><strong>Agent</strong>：AI智能体，能够感知其环境并以自主的方式在该环境中行动以达成其目标的系统。</li>
</ul>


<h2>AI发展大事记</h2>

<ul>
<li><strong>人工智能的萌芽</strong>：人工智能之父图灵，1950年提出图灵测试。</li>
<li><strong>人工智能的起点</strong>：1956年达特茅斯会议，开启人工智能第一次高潮</li>
<li><strong>第一次低谷</strong>：20世纪70年代初，各种人工智能承诺无法兑现</li>
<li><strong>人工智能第二次高潮</strong>：20世纪80年代，知识工程和专家系统为代表的符号主义</li>
<li><strong>第二次低谷</strong>：20世纪80年代末到90年代初时期，专家系统的局限性</li>
<li><strong>平稳期</strong>：20世纪90年-2000年初。1997年深蓝”击败国际象棋冠军</li>
<li><strong>人工智能第三次高潮</strong>：2006年，深度学习算法的提出；2012年AlexNet在ImageNet挑战赛的横空出世；2016、2017年AlphaGo打败围棋冠军</li>
<li><strong>AI元年</strong>：2023年，生成式AI-ChatGPT、StableDifussion、MidJourney</li>
</ul>


<h2><strong>机器学习、深度学习</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/ml.png" width="450"/></p>

<ul>
<li>实现人工智能的方法。</li>
<li>机器学习：一种可以让机器根据历史经验自动改进自身的学习算法。</li>
<li>深度学习：机器学习的一种，“无监督特征学习”（Unsupervised Feature Learning），以多层神经网络为代表。

<ul>
<li>人类认知过程：<strong>分层迭代，逐级抽象</strong></li>
</ul>
</li>
</ul>


<h2><strong>LLM</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/llm.png" width="450"/></p>

<ul>
<li>GenAI：相对于判别式AI（Discriminative AI），能够生成新的内容->AIGC</li>
<li>LLM是生成式AI的一种</li>
<li>最可能通向AGI的方法：Transformer</li>
<li>大语言模型：文本->x，多模态->多模态

<ul>
<li>NLP</li>
<li>涌现：鹦鹉vs乌鸦；人类智能的本质？</li>
</ul>
</li>
</ul>


<h2><strong>大模型产业链</strong></h2>

<p><img src="https://www.rowkey.cn/post_images/ai/llmlayer.png" width="450"/></p>

<p><img src="https://www.rowkey.cn/post_images/ai/llmlayer2.png" width="450"/></p>

<ul>
<li>大模型=计算机 or 操作系统, GPTs store</li>
<li>我们的位置 -> <strong>应用层!</strong></li>
</ul>


<h2>GenAI应用概览</h2>

<p><img src="https://www.rowkey.cn/post_images/ai/genai.png" width="450"/></p>

<p><img src="https://www.rowkey.cn/post_images/ai/genairank.png" width="450"/></p>

<p>GenAI数据：<a href="https://zw73xyquvv.feishu.cn/wiki/M2BywHAvCiioSzk9qXHczwJZnOd">https://zw73xyquvv.feishu.cn/wiki/M2BywHAvCiioSzk9qXHczwJZnOd</a></p>

<h2>ChatBot</h2>

<ul>
<li><a href="https://chat.openai.com/">ChatGPT</a></li>
<li><a href="https://copilot.microsoft.com/">微软Copilot</a>：微软基于ChatGPT的ChatBot应用，集成了DALL.E-3、suno.ai等插件</li>
<li><a href="https://kimi.moonshot.cn/chat">KimiChat</a>: 大尺寸上下文（文字、pdf文档等)、实时联网</li>
<li>其他大模型的ChatBot：Claude+、文心一言、豆包、讯飞星火、通义千问&hellip;</li>
<li><a href="https://poe.com/">POE</a>：ChatBot聚合</li>
</ul>


<h2><strong>AI绘画</strong></h2>

<ul>
<li><a href="https://stability.ai/stable-image">Stable Diffusion</a>：生态最丰富的开源图像生成项目</li>
<li><a href="https://openai.com/dall-e-3">DALL-E 3</a>：语义理解能力最强的图像生成产品</li>
<li><a href="https://www.midjourney.com/home">Midjourney:</a> 质量最好的图像生成产品</li>
<li>一些大模型聊天机器人自带的绘图：插件、Agent方式</li>
<li><a href="https://magnific.ai/">Magnific.ai</a>: 图像精修， <a href="https://mp.weixin.qq.com/s/x3F59AcMxG8bmajXO3OXmg">https://mp.weixin.qq.com/s/x3F59AcMxG8bmajXO3OXmg</a></li>
<li><a href="https://segment-anything.com/demo">Meta SAM</a>: 图像分割</li>
</ul>


<h2>AI语音</h2>

<ul>
<li><a href="https://openai.com/research/whisper">Whisper</a>：基于大模型的ASR，自动语言识别</li>
<li><a href="https://elevenlabs.io/">Elevenlabs</a>：TTS，目前最先进的商业化TTS</li>
<li><a href="https://platform.openai.com/docs/guides/text-to-speech">OpenAI TTS</a>: TTS，OpenAI开源</li>
<li><a href="https://suno.ai/">Suno.ai</a>: 文生音乐，<a href="https://app.suno.ai/song/9a782a3b-fde7-44ae-896f-c4d57698efa9/%C2%A0">https://app.suno.ai/song/9a782a3b-fde7-44ae-896f-c4d57698efa9/%C2%A0</a>(中文版的 I'll Be There For You，根据中国文化做稍微的改动)</li>
<li><a href="https://github.com/svc-develop-team/so-vits-svc">so-vits-svc</a>：歌声转换，<a href="https://www.youtube.com/watch?v=sN4ZFwySyow">孙燕姿唱周杰伦的歌</a></li>
</ul>


<h2>AI视频</h2>

<ul>
<li><a href="https://app.runwayml.com/">Runway</a>: 目前技术最先进的视频生成产品</li>
<li><a href="https://pika.art/my-library">Pika</a>：文本->视频，720p, 4秒</li>
<li><a href="https://www.morphstudio.com/">Morph Studio</a>：文本->视频，1080P，7秒 <a href="https://mp.weixin.qq.com/s/krSEoCHPBFuXsbkLm7E5rA">文生视频“黑马”Morph Studio来袭：好用、1080P 、7秒时长还免费</a></li>
<li><a href="https://stability.ai/stable-video">Stable Video Diffusion</a>: StableAI开源的视频生成技术，<a href="https://replicate.com/stability-ai/stable-video-diffusion">https://replicate.com/stability-ai/stable-video-diffusion</a></li>
<li><a href="https://app.heygen.com/login">HeyGen</a>：数字人播报视频生成，<a href="https://www.youtube.com/watch?v=PnpaLTB2Eck">霉霉说中文</a></li>
<li><a href="https://app.wonderdynamics.com/:">WonderStudio</a>: 视频CG角色替换，<a href="https://www.youtube.com/watch?v=YuUsunFIJCU">https://www.youtube.com/watch?v=YuUsunFIJCU</a></li>
<li>图片 -> 真人跳舞视频：通义千问“全民舞王”

<ul>
<li><a href="https://boese0601.github.io/magicdance/">MagicDance</a></li>
<li><a href="https://humanaigc.github.io/animate-anyone/">Animate Anyone</a></li>
</ul>
</li>
</ul>


<h2>其他</h2>

<ul>
<li>文本->3D

<ul>
<li><a href="https://mesh.ai/">Mesah.ai</a></li>
<li><a href="https://www.tripo3d.ai/">Tripo3D.ai</a></li>
</ul>
</li>
<li>图片->网页: <a href="https://screenshottocode.com/">https://screenshottocode.com/</a></li>
<li>图片/文本->网页、UI：<a href="https://v0.dev/">https://v0.dev/</a></li>
</ul>


<h2><strong>我们可以做什么</strong></h2>

<ul>
<li>基于大模型的产品研发</li>
<li>个人

<ul>
<li>文章总结摘要：<a href="https://kimi.moonshot.cn/chat/cm6p88kudu6f77a0fqig">https://kimi.moonshot.cn/chat/cm6p88kudu6f77a0fqig</a></li>
<li>写儿童故事：<a href="https://chat.openai.com/share/6c86a6a3-5cda-45e8-af10-4bb4cd2476fb">https://chat.openai.com/share/6c86a6a3-5cda-45e8-af10-4bb4cd2476fb</a></li>
<li>专业问题解答：<a href="https://chat.openai.com/share/0d9de7f4-eba3-4eba-be2b-0dd89b146d53">https://chat.openai.com/share/0d9de7f4-eba3-4eba-be2b-0dd89b146d53</a></li>
</ul>
</li>
<li>工作</li>
<li>辅助编程: Genie、Github Copilot</li>
<li>分析需求文档，输出摘要和模块</li>
<li><p>基于LLM的研发全流程</p>

<p>  <img src="https://www.rowkey.cn/post_images/ai/llmsdlc.png" width="450"/></p></li>
</ul>


<h2><strong>展望</strong></h2>

<ul>
<li>新摩尔定律：宇宙中的智能数量每18个月翻一番</li>
<li>所有的应用都值得用AI重构一遍</li>
<li>AI不会取代人类，但会AI的会取代不会AI的人类</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Langchain代理和OpenAI函数调用的区别]]></title>
    <link href="https://www.rowkey.cn/blog/2023/11/30/openai-func/"/>
    <updated>2023-11-30T19:29:34+08:00</updated>
    <id>https://www.rowkey.cn/blog/2023/11/30/openai-func</id>
    <content type="html"><![CDATA[<p>最近在实现LLM调用外部工具的时候，突然意识到貌似OpenAI的Function Calling和LangChain的Agent都能达到相同的结果，只是实现方式不同。因此这里来对比一下。</p>

<!--more-->


<h2>OpenAI Functions Calling</h2>

<p>OpenAI函数允许更好地控制AI调用的函数，因为我们必须解析AI的响应，找出AI想要调用的函数，并将参数传递给该函数。我们可以在每个阶段干预并修改被调用函数或其参数。</p>

<p>假设我们想让AI使用一个REST API，而不指定它可以执行的操作。我们提供一个通用的REST API客户端，让AI决定使用哪种HTTP方法和哪些参数。</p>

<h2>定义一个函数</h2>

<p>首先，我们必须准备一个可用Function的描述。</p>

<pre><code>functions = [
{
    "type": "function",
    "function": {
        "name": "call_rest_api",
        "description": "Sends a request to the REST API",
        "parameters": {
            "type": "object",
            "properties": {
                "method": {
                    "type": "string",
                    "description": "The HTTP method to be used",
                    "enum": ["GET", "POST", "PUT", "DELETE"],
                },
                "url": {
                    "type": "string",
                    "description": "The URL of the endpoint. Value placeholders must be replaced with actual values.",
                },
                "body": {
                    "type": "string",
                    "description": "A string representation of the JSON that should be sent as the request body.",
                },

            },
            "required": ["method", "url"],
        },
    }
}
]
</code></pre>

<p>除了描述之外，还需要一个函数的实现。毕竟，当我们收到一个表示AI想要调用函数的响应时，我们将负责调用该函数。</p>

<pre><code>def call_rest_api(self, arguments):
    arguments = json.loads(arguments)
    # reques.in is a hosted, fake REST API that we can use for testing
    url = 'https://reqres.in' + arguments['url']
    body = arguments.get('body', {})
    response = None
    if arguments['method'] == 'GET':
        response = requests.get(url)
    elif arguments['method'] == 'POST':
        response = requests.post(url, json=body)
    elif arguments['method'] == 'PUT':
        response = requests.put(url, json=body)
    elif arguments['method'] == 'DELETE':
        response = requests.delete(url)
    else:
        raise ValueError(arguments)

    if response.status_code == 200:
        return json.dumps(response.json())
    else:
        return f"Status code: {response.status_code}"
</code></pre>

<p>该函数是通用的，可以处理发送到任何端点的任何HTTP请求。需要列出可用的端点和支持的HTTP方法。我更喜欢将这些参数收集到一个变量中，稍后用于生成提示：</p>

<pre><code>available_apis = [
        {'method': 'GET', 'url': '/api/users?page=[page_id]', 'description': 'Lists employees. The response is paginated. You may need to request more than one to get them all. For example,/api/users?page=2.'},
        {'method': 'GET', 'url': '/api/users/[user_id]', 'description': 'Returns information about the employee identified by the given id. For example,/api/users/2'},
        {'method': 'POST', 'url': '/api/users', 'description': 'Creates a new employee profile. This function accepts JSON body containing two fields: name and job'},
        {'method': 'PUT', 'url': '/api/users/[user_id]', 'description': 'Updates employee information. This function accepts JSON body containing two fields: name and job. The user_id in the URL must be a valid identifier of an existing employee.'},
        {'method': 'DELETE', 'url': '/api/users/[user_id]', 'description': 'Removes the employee identified by the given id. Before you call this function, find the employee information and make sure the id is correct. Do NOT call this function if you didn\'t retrieve user info. Iterate over all pages until you find it or make sure it doesn\'t exist'}
    ]
</code></pre>

<p>接着需要定义AI的任务和可用的功能。为此，准备以下系统提示词。</p>

<pre><code>messages = [
    {"role": "system", 
    "content": "You are an HR helper who makes API calls on behalf of an HR representative，You have access to the following APIs: " 
        + json.dumps(self.available_apis)
        + "If a function requires an identifier, list all employees first to find the proper value. You may need to list more than one page"
        + "If you were asked to create, update, or delete a user, perform the action and reply with a confirmation telling what you have done"
    }
]
</code></pre>

<p>最终，可以与AI进行交互。我们定义一个函数call_ai。该函数接受用户的提示，并将提示传递给之前定义的OpenAI模型的上下文描述。上下文描述还包含了可用函数的描述。如果AI回复的消息包含function_call，我们会调用一个函数。该消息包括函数名和参数。</p>

<pre><code>def call_ai(self, new_message):
    if new_message:
        self.messages.append({"role": "user", "content": new_message})

    response = self.client.chat.completions.create(
        model="gpt-3.5-turbo-1106",
        messages=self.messages,
        tools=self.functions,
        tool_choice="auto",
    )

    msg = response.choices[0].message
    self.messages.append(msg)
    if msg.content:
        logging.debug(msg.content)
    if tool_calls:
        msg.content = "" # required due to a bug in the SDK. We cannot send a message with None content
        for tool_call in tool_calls:
            # we may get a request to call more than one function(!)
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments)
            if function_name == 'call_rest_api':
                # ['function_call']['arguments'] contains the arguments of the function
                logging.debug(function_args)
                # Here, we call the requested function and get a response as a string
                function_response = self.call_rest_api(function_args)
                logging.debug(function_response)
                # We add the response to messages
                self.messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response
                })

                self.call_ai(new_message=None) # pass the function response back to AI
    else:
      # return the final response
      return msg
</code></pre>

<p>一方面，这样的实现使代码变得非常冗长。就像下面所看到的，我们必须选择要调用的Python函数，传递参数，将响应添加到聊天记录中（作为一个带有role设置为tool的消息），然后再次调用AI并更新聊天记录。</p>

<p>另一方面，我们对被调用的函数保持完全控制。我们可以调用不同的函数，改变参数，或者传递一个虚假的响应给人工智能，而不是调用一个函数。</p>

<p>通过OpenAI的实现，我们还可以轻松创建长时间运行的工作流程，在数据库中存储聊天记录，在AI请求的函数调用后等待几个小时或几天，当我们收到回复时继续工作流程。</p>

<h2>使用Langchain代理进行函数调用</h2>

<p>Langchain代理隐藏了调用函数的复杂性。我们仍然需要提供函数描述和实现，或者使用其中一个可用的Langchain工具包。Langchain工具包是一种快捷方式，允许我们跳过编写函数及其描述的步骤。相反，我们使用工具包作者准备的代码。</p>

<p>在Langchain中，我们必须选择其中一种可用的代理类型。代理类型定义了提示，以便向模型介绍可用的功能。</p>

<p>代理类型实现了各种交互样式。例如，在conversational-react-description代理中，提示的指令部分如下所示：</p>

<pre><code>To use a tool, please use the following format:

Thought: Do I need to use a tool? Yes
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action

When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:

Thought: Do I need to use a tool? No
{ai_prefix}: [your response here]

## https://github.com/langchain-ai/langchain/blob/9731ce5a406d5a7bb1878a54b265a6f7c728effc/libs/langchain/langchain/agents/conversational/prompt.py
</code></pre>

<p>当使用此提示时，Langchain会让AI生成输出，直到它产生Action Input: 之后的第一个换行符。此时，Langchain会中断AI调用，找到使用Action: 行返回的名称的函数，并将Action Input: 的值作为参数传递。</p>

<p>稍后，当函数返回响应时，响应被添加到提示中的Observation: 行，并且Langchain再次调用LLM来继续处理提示。LLM可能会产生另一个Action: + Action Input: 对，以调用另一个函数或生成以Final Answer: 开头的行，将响应返回给用户。</p>

<p>一个流行的zero-shot-react-description几乎具有相同的提示。</p>

<h2>在Langchain中使用OpenAI Function Calling</h2>

<p>选择一个代理类型，该类型使用OpenAI函数，但隐藏了选择函数和传递参数的复杂性。使用配置Langchain代理的标准代码结构，但选择OPENAI_FUNCTIONS AgentType。</p>

<p>Langchain试图将整个函数描述打包成一条消息，而长描述很容易超过消息长度限制，因此不得不缩短提示。如果需要所有的端点，可以将call_rest_api函数拆分成多个函数，每个函数处理一个端点。
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import json
</span><span class='line'>import requests
</span><span class='line'>from langchain import OpenAI
</span><span class='line'>from langchain.agents import initialize_agent, Tool
</span><span class='line'>from langchain.agents import AgentType
</span><span class='line'>from langchain.chat_models import ChatOpenAI&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;def call_rest_api(method_and_url):
</span><span class='line'>    method, url = method_and_url.split(&lsquo; &rsquo;)
</span><span class='line'>    url = &lsquo;&lt;a href="https://reqres.in"&gt;https://reqres.in&lt;/a&gt;&rsquo; + url
</span><span class='line'>    response = None
</span><span class='line'>    if method == &lsquo;GET&rsquo;:
</span><span class='line'>        response = requests.get(url)
</span><span class='line'>    elif method == &lsquo;DELETE&rsquo;:
</span><span class='line'>        response = requests.delete(url)
</span><span class='line'>    else:
</span><span class='line'>        raise ValueError(method)&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;if response.status_code == 200:
</span><span class='line'>    return response.json()
</span><span class='line'>else:
</span><span class='line'>    return f"Status code: {response.status_code}"
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;available_apis = [
</span><span class='line'>        {&lsquo;api &rsquo;: &lsquo;GET /api/users?page=[page_id]&rsquo;, &lsquo;description&rsquo;: &lsquo;Lists employees. The response is paginated. You may need to request more than one to get them all. For example,/api/users?page=2.&rsquo;},
</span><span class='line'>        {&lsquo;api&rsquo;: &lsquo;DELETE /api/users/[numeric user_id]&rsquo;, &lsquo;description&rsquo;: &lsquo;Removes the employee identified by the given id. Before you call this function, find the employee information and make sure the id is correct. Do NOT call this function if you didn\&rsquo;t retrieve user info. Iterate over all pages until you find it or make sure it doesn\&rsquo;t exist&rsquo;}
</span><span class='line'>    ]&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;api_description = json.dumps(available_apis)&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;function_description = f"&ldquo;"Sends a request to the REST API.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Accepts a single parameter containing two parts:
</span><span class='line'>* method - The HTTP method to be used (GET, POST, PUT, or DELETE)
</span><span class='line'>* url - The URL of the endpoint. Value placeholders must be replaced with actual values.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;For example: GET /api/users?page=1 or DELETE /api/users/13&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;To find users by name, use the GET method first.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Available endpoints:
</span><span class='line'>{api_description}&ldquo;&rdquo;"&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;llm = ChatOpenAI(temperature=0, model=&ldquo;gpt-4&rdquo;, openai_api_key=&lsquo;sk-&hellip;&rsquo;)
</span><span class='line'>tools = [
</span><span class='line'>    Tool(
</span><span class='line'>        name = &ldquo;REST&rdquo;,
</span><span class='line'>        func=call_rest_api,
</span><span class='line'>        description=function_description
</span><span class='line'>    )
</span><span class='line'>]&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)
</span><span class='line'>agent.run(&ldquo;Fire Lawson&rdquo;)</span></code></pre></td></tr></table></div></figure></p>

<p>在控制台中，可以看到Agent的详细日志：</p>

<pre><code>Invoking: `REST` with `GET /api/users?page=1`
{'page': 1, 'per_page': 6, 'total': 12, 'total_pages': 2, 'data': [...

Invoking: `REST` with `GET /api/users?page=2`
{'page': 2, 'per_page': 6, 'total': 12, 'total_pages': 2, 'data': [{'id': 7, 'email': 'michael.lawson@reqres.in', 'first_name': 'Michael', 'last_name': 'Lawson', 'avatar': 'https://reqres.in/img/faces/7-image.jpg'}, ...

Invoking: `REST` with `DELETE /api/users/7`
Status code: 204

User Lawson has been successfully removed from the system.
</code></pre>

<h2>如何选择？</h2>

<p>如果我有一个简单的函数和简短的描述，优先选择Langchain，因为Langchain隐藏了许多实现细节，让我们专注于准备提示。</p>

<p>当函数的描述不再适合于一条信息时，那只能使用OpenAI函数，而不使用Langchain。</p>

<p>此外，调试提示词时，建议切换到OpenAI函数。它不会神奇地解决问题，必须编写整个函数调用代码。因此使得调试将更加容易。</p>
]]></content>
  </entry>
  
</feed>
