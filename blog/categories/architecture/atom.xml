<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: architecture | 后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/blog/categories/architecture/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2018-09-03T18:30:56+08:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[响应式微服务架构-分布式系统设计原则]]></title>
    <link href="http://www.rowkey.me/blog/2018/06/07/reactive-microservice/"/>
    <updated>2018-06-07T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/06/07/reactive-microservice</id>
    <content type="html"><![CDATA[<p>O’Reilly的电子书《Reactive Microservices Architecture》讲述了微服务/分布式系统的一些设计原则，本文是笔者阅读完此书后的理解。书籍地址：<a href="https://info.lightbend.com/COLL-20XX-Reactive-Microservices-Architecture-RES-LP.html">https://info.lightbend.com/COLL-20XX-Reactive-Microservices-Architecture-RES-LP.html</a>。</p>

<!--more-->


<p>微服务相比传统的单体应用能够带来快速的响应，以小的系统产生大的影响。而随着网络加速、磁盘成本降低、RAM成本降低、多核技术的发展、云架构技术的爆发，微服务不再受这些客观条件的限制，已经开始大规模的应用。</p>

<p>与SOA架构，微服务和它都具有相同的初衷：解耦、隔离、组合、集成、分散以及自主，但是SOA经常被误解和误用，尤其是使用ESB来支持对多个单体系统的协议（复杂、低效、不稳定）调用，使得系统变得非常复杂。而随着这些年硬件以及软件架构理念的发展，所有的系统基本都已经变成分布式架构，也带来了很多新的挑战。也就需要新的思路和理念来面对这些问题，其中本书所讲述的响应式原则（Reactive principles）即一种解决分布式系统的思路。响应式原则也并非一个新的东西，Erlang中的Actor模型即一种响应式设计。微服务是响应式原则的一个架构设计，其借鉴了SOA架构中好的理念，并使用了现代的基础服务设施（云服务、自动化工具等）。</p>

<h2>响应式微服务定义</h2>

<p>使用微服务架构最关键的一个原则就是将系统划分成一个个相互隔离、无依赖的子系统，这些子系统通过定义良好的协议进行通信。其中隔离是实现弹性、可伸缩系统的前提，并且需要在服务间建立异步通信边界，因此要在以下两方面进行解耦：</p>

<ul>
<li>时间：允许并发。</li>
<li>空间：允许分布式和移动性，即服务能够随时移动。</li>
</ul>


<p>此外，微服务还需要消除共享状态从而最小化相互协作、联结的成本，要尽量达到“不共享任何东西”。</p>

<h3>隔离任何东西</h3>

<p>隔离是微服务架构中最重要的特性。不仅仅是微服务带来的很多优势的基础，也是对设计和架构影响最大的方面。如康威定律所说，它还对组织架构有非常大的影响，</p>

<pre><code>系统的结构是对团队组织架构的反映。
</code></pre>

<p>失败隔离是一种与“舱壁”（船舱的隔板）相关的设计模式：隔离错误、失败以防止其蔓延至所有服务，导致更大面积的失败。</p>

<p>“舱壁”这种模式已经在轮船上使用了几个世纪：创建一个个密封不漏水的空间以防止船的外壳破损或者其他泄漏。这些空间是完全互相隔离的，这样即使一个隔离区充满了水，也不会蔓延流到其他隔离空间中，从而使得船整体仍然能够运作。</p>

<p>弹性（从失败中恢复的能力）即依赖于这种舱壁和失败隔离的设计，并且需要打破同步通信机制。由此，微服务一般是在边界之间使用异步消息传输，从而使得正常的业务逻辑避免对捕获错误、错误处理的依赖。</p>

<p>进一步的，服务之间的隔离使得“持续交付”变得很容易，能够随时地部署服务而无需担心影响正常的业务。而且隔离的单个服务很容易监控、调试、测试和部署，非常便于扩展。</p>

<h3>自主地行动</h3>

<p>上面所讲的隔离是自主性的前提。只有当服务之间是完全隔离的，那么才可能实现完全的自主，包括独立的决策、独立的行动以及与其他服务协调合作来解决问题。</p>

<p>一个自主的服务仅仅保证其对外公布的协议/API的正确性即可。如此，不仅能够让我们更好地了解协作的这些系统以及对他们的建模，也能够在面对冲突、失败状况时，只在一个服务内进行排查、修复即可。</p>

<p>使用自主服务能够给服务编排、工作流管理以及服务合作上带来很大灵活性，同时也带来可扩展性、可用性、运行时管理等优势。但其付出的代价就是需要花心思在定义良好的可组合的API设计上，这个是有一定挑战性的。</p>

<h3>只做一件事，并且做好</h3>

<p>如Unix编程哲学所说：程序应该只做一件事，并且做好它。然后让他们一起工作完成任务。这也类似于面向对象编程语言中软件开发单一职责原则（SRP）的描述。</p>

<p>而在微服务中一个很大的问题就是如何正确地确定服务的大小。比如怎样的粒度才能被认为是“微”（micro）？多少行代码还能被认为是微服务。但这里“micro”其实是和职责范围有关的，就如Unix的SRP原则：只做一件事并且做好。</p>

<p>每一个服务都应该只有一个存在的原因，提供了一组相关的功能，业务和职责不会糅杂在一起。所有服务组织在一起整体上能够便于扩展、具有弹性、易理解和维护。</p>

<h3>拥有自己的私有状态</h3>

<p>微服务中有一个很关键的部分就是状态（state），很多微服务也都是有状态的实体，包括对状态和行为的封装。而在“无状态”的设计理念下，很多服务都把自己的状态下沉到一个大的共享数据库中，这也是很多传统的Web框架的做法。如此就造成了在扩展性、可用性以及数据集成上很难做好把控。而本质上，一个有着共享数据库的微服务架构本质还是一个单体应用。</p>

<p>合理的方式是一个服务既然具有单一职责，那么就应该拥有自己的状态和持久化机制，建模成一个边界上下文，有自己的域名和语言。这些也都是DDD（Domain-Drivern Design）里面的技术。微服务受DDD影响很大，其中很多微服务的上下文的概念都来自于DDD。</p>

<p>当访问一个服务时，也只能是客气的请求其状态而并不能强制其一定具有状态。如此，每个服务都能够通过事件溯源(Event Sourcing)和CQRS（Command Query Responsibility Segreation）自定义自己的状态表示和实现（RDBMS、NoSQL、Time-Series、EventLog）。</p>

<p>去中心化的数据管理和持久化（多语言持久化）能够带来很多优势。数据的存储媒介可以根据服务自己的需要选择，服务包括其数据都可以看做一个单独的单元。同时并不允许一个服务直接去访问另一个服务的数据库，如果要访问只能通过API（通过指定规范、策略和Code Review来保证）。</p>

<p>Event Log是一种消息的存储方式。我们可以以消息进入服务的形式存储（发送到服务的Commnds），即命令溯源(Command Sourcing)。我们也可以忽略命令，让命令先执行对服务产生一些作用，如果触发了状态变更，那么我们捕获此次变动并用事件溯源（Event Sourcing）将此次Event存储到EventLog中。</p>

<p>消息有序存储，能够提供服务所有的交互历史。同时消息也保存了服务的事务，也就能够对这些事务日志进行查询、审计、重放从而用于弹性伸缩、调试以及冗余等。</p>

<p>命令溯源和事件溯源是不同的语义。重放命令意味着会重放其带来的副作用。而重放事件则是执行状态的改变。需要根据具体场景的不同选择使用哪种溯源技术。</p>

<p>使用EventLog可以避免&#8221;对象关系不匹配&#8221;的问题（ORM中经常出现）。而由于其自身天然适合异步消息传输，因此绝大多数情况下，Event Log是微服务中最佳的持久化模型。</p>

<h3>拥抱异步消息传输</h3>

<p>微服务之间的通信的最佳机制就是消息传输。如上文所说，服务之间的异步边界能够在时间和空间两方面进行解耦，能够提升整体系统的性能。</p>

<p>异步非阻塞执行以及IO都是对资源的高效操作，能够最小化访问共享资源时的阻塞消耗（扩展性、低延迟以及高吞吐的最大障碍）。简单的例子：如果要发起对10个服务的访问，其中每一个请求需要耗时100ms，那么如果使用同步模式，则完成所有请求则需要10*100=1000ms。而如果使用异步模式，同时发起10个线程，则一共就需要100ms。</p>

<p>异步消息传输还能够让我们注重网络编程的限制，而不是假装这些限制不存在，尤其是在失败场景下。还能够让我们更关注工作流以及服务间的数据流、协议、交互是怎样进行的。</p>

<p>然而目前微服务的默认通信协议以REST为主，其本质是同步通信机制，比较适用于可控的服务调用或者紧耦合的服务调用上。</p>

<p>此外，使用异步消息传输的另一个需求在于对消息的持续流处理（可能是无界的）。也是我们从“data at rest”到&#8221;data in motion&#8221;的理念的改变。之前的数据是离线被使用的，而现在的数据是被在线处理的。应用对数据变更的响应需要达到实时级别：当变动发生，需要实时进行持续的查询、聚合并反馈给最终的应用。这个理念的形成经历了三个主要阶段：</p>

<ol>
<li><p>&ldquo;data at rest&rdquo;: 将大量数据存储在HDFS类似的数据存储媒介中，然后使用离线批处理技术去处理这些数据，一般会有数个小时的延迟。</p></li>
<li><p>意识到了“data in motion”正变得越来越重要：在数秒内捕获数据、处理数据并反馈给运行中的系统。Lambda即此时出现的一种架构: 加速层用来做实时在线计算；批处理层用来做复杂的离线处理。加速层实时处理的结果后续被批处理层的结果合并。这个模型解决了某些场景需要数据即时响应的问题，但其架构的复杂使得不容易维护。</p></li>
<li><p>“data in motion”: 全面拥抱移动数据的概念。传统的面向批处理的架构都在逐渐向纯流处理的架构转变。这种模型作为通信协议和持久化方案（通过Event Logging）也能够给微服务带来“data in motion”和流处理的能力。</p></li>
</ol>


<h3>保持移动，但可寻址</h3>

<p>如上述所讲，异步消息传输带来了对时间和空间的解耦。其中，对于空间的解耦也被称为“位置透明”：在多核或者多结点上的微服务在运行时无须改变结点即可以动态扩展的能力。这也决定了系统的弹性和移动性。要实现这些需要依赖云计算带来的一些特性和其“按需使用”模型。</p>

<p>而可寻址则是说服务的地址需要是稳定的，从而可以无限地引用此服务，而无论服务目前是否可以被定位到。当服务在运行中、已经停止、被挂起、升级中、已经崩溃等等情形下，地址都应该是可用的，任意客户端能够随时发送消息给一个地址。实际中，这些消息有可能进入队列排队、重提交、代理、日志记录或者进入死信队列。此外，地址需要是虚拟的，可以代表一组实例提供的服务。</p>

<ul>
<li>在无状态的服务间做负载均衡：如果服务是无状态的，那么请求被哪一个服务实例处理都是没任何问题的。也有很多种的路由算法供使用，如：轮训、广播或者基于度量信息。</li>
<li>在有状态的服务之间构建Active-Passive的冗余设计：如果一个服务是有状态的，那么可以使用sticky路由算法（同一个客户端的请求都会发送给同一个服务实例）。冗余一个passive实例是为了在主实例挂的时候接管上面的请求。因此，服务的每一个状态变动都需要同步到passive实例上。</li>
<li>有状态的服务的重定位：将一个服务实例从一个位置移动到另一个位置可以提高引用的本地性（让数据和计算靠近）和资源利用率。</li>
</ul>


<p>使用虚拟地址能够让服务消费方无须关心服务目前是如何配置操作的，只要知道地址即可。</p>

<h2>微服务系统实现</h2>

<p>一个微服务并非真正的“微服务”，一系列微服务通过通信、合作才能够解决问题，才能组成一个完整的业务系统。实现一个服务是相对简单的，困难的是其他基础设施的实现：服务发现、协作、安全、冗余、数据一致性、容错、部署以及与其他系统的集成。</p>

<h3>系统需要利用现实</h3>

<p>微服务架构带来的一个很大优势就在于它提供了一套工具，能够利用现实，模仿真实的世界来创建系统，包括真实世界的限制和机会。</p>

<p>首先根据“康威定律”，微服务的部署是和现实中工程组织/部门如何工作是相适应的。此外，还需要注意的是现实不是一致的，任何事情都是相对的，即使是时间和“现在”这个概念。</p>

<p>信息的传播速度不可能比光快，甚至大部分是很慢的，这也意味着信息通信是有延迟的。信息都是来自过去的，我们稍微思考一下可以知道信息承载的都是我们观察到的东西。而我们观察/学习到的事实至少都是很短时间之前发生的，也就是说我们总是在看过去，“现在”只是旁观者的视角。</p>

<p>每一个微服务都可以看做一个安全的小岛，提供了确定性和强一致性，上面的时间和“目前”都是绝对的。但是当离开一个微服务的边界时，就进入了一片充满非确定性的大海-分布式系统的世界。如很多人所说，构建分布式系统是困难的。但现实世界同时也提供了如何解决诸如弹性、可伸缩、隔离性等分布式问题的解决思路。因此，即使构建分布式系统是困难的，但是我们也不应该退化为单体应用，而是学习如何使用一系列的设计原则、抽象概念和工具来管理它。</p>

<p>正如Pat Helland在《Data on the Outside versus Data on the Inside.”》对&#8221;data on the inside&#8221;和“data on the outside”的对比所说：内部的数据就是我们本地的“目前”，而外部数据-事件即是来自过去的信息，服务之间的命令则是“对未来的希望”。</p>

<h3>服务发现</h3>

<p>服务发现要解决的问题就是如何定位一系列的服务从而可以使用地址去调用。其中最简单的手段就是将地址和端口信息硬编码在所有服务中或者外置在服务的配置文件中。这种方式的问题在于其是一种静态部署模型，与微服务的初衷是相矛盾的。</p>

<p>服务需要保持解耦和移动，而系统需要是弹性和动态的。因此可以通过使用控制反转（Inversion of Control）模式引入一个间接层来解决此问题。也就是说每一个服务都上报自己的信息（位置、如何访问）给一个统一的平台。这个平台被称作“服务发现”，是微服务平台的一个基础部分。这样，一旦服务的信息被存储了，服务就可以使用“服务注册中心”来查找调用服务的信息，这种模式被称作“Client-Side服务发现”。另一种策略是将信息存储、维护在一个负载均衡器（AWS的ELB)或者直接维护在服务提供方的地址中-“Server-Side服务发现”。</p>

<p>可以选择CP特性的数据库作为服务信息的存储，能够保证信息的一致性。但是这种数据库是牺牲了一定程度的可用性来达到强一致性的，并且依赖一些额外的基础设施，而很多时候强一致性并非那么需要。因此，更好的选择是使用AP特性的点对点的技术来存储，比如使用CRDTs（Conflict-Free Replicated Data Types ）与Epidemic Gossip可以实现信息的最终一致性传播，能够有更好的弹性，也不需要额外的基础设施。</p>

<h3>API管理</h3>

<p>API管理解决的问题在于如何将服务的协议和API统一管理起来，以方便服务的调用。包括协议和数据版本的升级和后退等。解决此问题可以通过引入一个负责序列化编码、协议维护以及数据传输的层，甚至直接将服务版本化。这在DDD中被称作&#8221;Anti-Corruption&#8221;层，可以加入到服务本身或者在API网关中实现。</p>

<p>假如一个客户端需要调用10个服务（每一个都有不同的API）来完成一个任务，那么对于这个客户端来说是非常繁琐的。相比起让客户端直接去调用服务，更好的方式是让客户端通过API网关服务来调用。API网关负责接受客户端的请求，然后路由请求到相应的服务（如果有必要需要转换协议），组装响应并将其返回给客户端。这样，做为客户端和服务之间的一层其就能够简化client-to-service协议。但这里如果是中心化的则很难达到高可用和可扩展性，所以使用去中心化技术（比如服务发现）实现API网关则是更好的选择。</p>

<p><img src="//post_images/rx-ms/gw.png" alt="" /></p>

<p>但需要注意的是API网关，包括所有的核心出服务并不是一定要自建的，理想地它应该是底层平台的一部分。</p>

<h3>管理通信模式</h3>

<p>在一个由数个微服务组成的系统中，使用点对点的通信就能完成服务间的通信工作。但是当服务数目越来越多，如果还是让他们之间直接调用，那么很快整个系统会变得混乱不堪。解决此问题需要一个机制能够解耦发送者和接受者，并且能够按照某种定义好的原则路由数据。</p>

<p>发布订阅机制是一种解决方案：发布者发布信息到某个topic中，订阅者监听此topic以监听消息。可以使用可扩展消息系统（Apache Kafka、Amazon Kinesis）或者NoSQL数据库（AP特性数据库，如Cassendra和Riak）来实现。</p>

<p>在SOA架构中，ESB承担的即这种角色。微服务中我们肯定不会使用它来桥接单体应用，但是可以将它做为一个发布系统用来广播任务和数据或者做为系统间的通信总线（通过Spark Streaming收集数据到Spark中）。</p>

<p>发布订阅协议有时候也是有不足的。比如无法提供允许程序员自定义路由规则的高级路由特性或者数据的转化、丰富、分隔以及合并等功能（可以使用Akka Streams或者Apache Camel）。</p>

<h3>集成</h3>

<p>系统与外界或者系统之间的通信都是必需的。当与一个外部系统通信时，尤其当外部系统无法把控时，那么就会有很大的失败风险（系统超载、业务失败）。因此即使协议协商得再好，也不能信赖外部服务，需要做好各种预防措施以保证自身服务的安全。</p>

<p>首先要达成一个良好的协议从而可以最小化一个系统突发超载造成服务不可用的风险，比如要避免发起的请求超过服务提供方的承载能力。也要尽量避免使用同步通信机制，否则就把自身服务的可用性放在了依赖的第三方服务的控制中。</p>

<p>避免级联失败需要服务足够解耦和隔离。使用异步通信机制是一个最佳的方案。此外，还需要通过背压（back-pressure，接收方根据自己的接受状况调节接受速率，通过反向的响应来控制发送方的发送速率）来达成数据流速度的一致性，以防止响应快速的系统压垮其中较慢的部分。而越来越多的工具和库都在开始拥抱“响应式流”（Reactive Streams）规范（Akka Stream、RxJava、Spark Streaming、Cassandra drivers），这些技术使用异步背压实时流来桥接系统，从而在总体上提高系统的可靠性、性能以及互操作性。</p>

<p>如何管理调用服务时候的失败也是微服务中一个关键的问题。捕获到错误后，先重试，而如果错误一直发生，那么就隔离服务一段时间直到服务恢复-“断路器”模式（Netflix和Akka中都有实现）。</p>

<p>面对可扩展性、高吞吐以及可用性的要求，系统集成的实现从传统的依赖于中心化服务如RDBMS/ESB逐渐变为现在采用去中心化策略（HTTP REST、ZeroMQ）或者订阅发布系统（Kakka、Amazon Kinesis）。而最近事件流平台（Event Streaming Platforms）正成为系统集成选型的趋势，其理念来自于Fast Data和实时数据管理。</p>

<p>如上文所述，服务之间使用异步通信机制能够得到很多的好处。但是如果是客户端（浏览器、APP）与服务之间的通信，使用REST经常是更好的选择。但是并非所有的地方都非得使用同步通信机制，需要根据不同的场景做不同的评估。很多情况下，开发者出于习惯都会倾向于使用同步方案，而不是根据真正的需要作出能够简化操作、提升操作性的选择。这里给出几个通常会使用同步方案建模但其本质是异步行为的事例：</p>

<ul>
<li>查询一个商品是否有货，如果此商品比较热门被卖光了，用户要得到通知。</li>
<li>如果一个餐馆的特价菜单改动了，用户要立刻知道。</li>
<li>用户对于一个网站的评论需要实时对话。</li>
<li>广告系统根据用户在页面上的行为输出不同的响应。</li>
</ul>


<p>对于上述实例，我们需要分别进行分析去理解怎样才是符合客户端和服务通信的最自然的方式。同时也经常需要根据数据的完整性约束来寻找可以弱化一致性保证（有序）的可能，目的就是找到最少的协调约束条件给用户以直观的语义：找到利用现实的最佳策略。</p>

<h3>安全管理</h3>

<p>安全管理主要是对服务的认证授权管理，限制某些service只允许某些服务访问。</p>

<ul>
<li>TLS Client Certificates也被称为相互验证、双路验证。它给每一个service都分配一个单独的私钥和证书，从而能够很好地保证服务间的认证访问。不仅仅服务要验证客户端的身份，客户端也要验证服务的身份。因此，其不仅能防止数据被窃听，而且即使在不安全的网络中也能防止对数据的拦截和转发。基于SSL之上的通信不仅安全，其也是一个公开、易于理解的标准。但是其非常复杂，无法得到底层平台的足够支持。同样的，HTTPS Basic Authentication也是双路验证，但其对SSL证书的管理也很复杂，请求也不能被反向代理缓存。</li>
<li>Asymmetric Request Signing：每一个服务都需要使用自己的私钥给自己发送的请求进行签名，同时每一个服务的公钥都要上报给“服务发现”服务。此方案的缺点在于一旦网络不可靠，那么则很难防止数据窃听或者请求重放攻击。</li>
<li>Hash Message Authentication Code (HMAC) ： 基于共享密钥来对请求进行一定规则的签名。这个方案比较简单，但是由于每一对需要通信的服务都需要唯一的一个共享密钥，整个系统则需要所有服务排列数目的共享密钥数量，实现起来比较麻烦。</li>
</ul>


<h3>最小化数据耦合</h3>

<p>微服务架构中，完成一个任务需要多个服务的协同，因此最小化服务之间的状态协作成本，有助于提升微服务系统的整体性能。</p>

<p>需要做的是要从业务的视角去分析数据以理解数据间的关系、担保和完整性约束。然后对数据进行反范式设计并在系统内定义一致性边界。如此，可以在边界内部实现强一致性。接着，需要使用这些边界来驱动微服务的设计和范围。如果设计的服务之间有很多数据依赖和关系，那么就需要去减少甚至是消除这些数据的耦合，从而避免对服务状态的协同。</p>

<h3>最小化协作成本</h3>

<p>如上节所述，已经最小化数据耦合了，但仍然还是会有业务场景需要多个服务协作完成。这个的确是无法避免的，但到了目前这一步，需要做的是可以根据需要逐渐的添加协作，而不是一开始各种耦合再逐渐去消除（比较麻烦和困难）。</p>

<p>这里提供几种可扩展、弹性伸缩的方式来协同数据改变，以达到Composability（对数据的变动无须停止数据所在的服务，也无须等待某些条件）。</p>

<ul>
<li>Apology-Oriented Programming: 基于请求原谅比请求权限容易的想法。如果你不能响应协作，那么就做出一个合理的猜测，赌一个条件已经满足，后续如果错了，那么就道歉并做补偿。这种做法和现实是非常相似的。比如航班的超售，如果起飞的时候没有座位那么就去做一些补偿措施。</li>
<li>事件驱动架构（Event-Driven Architecture ）：基于异步消息传输和事件溯源。需要区分命令和事件，命令表示一个将要产生副作用的操作意图（对未来的希望），而事件表示已经发生的事实。使用CQRS模式进行查询，将写入方（持久化事件日志）与读取方（将数据存入RDBMS或者NoSQL数据库中）分离。这里使用事件日志做状态管理和持久化具有很多好处：简化审计、调试、冗余、容错，并且允许重放过去任意时间点的事件流。</li>
<li>ACID2.0：由Pat Helland创造，定义了一组原则，目的是实现可扩展、弹性的协议以及API设计。A是Associative，表示分组消息不会产生影响，可以批量处理。C是Commutative，表示消息的顺序不重要。I是Idempotent，表示消息重复不会产生影响。D是Distributed，没有实质的意义，猜测是为了凑ACID这个首字母缩写。</li>
</ul>


<p>CRDTs是一个囊括了上面这些东西的工具，可以实现最终一致性、据有丰富的数据结构（counters、sets、maps、graphs），并且不需要协作就可以收敛聚合。其更新操作的顺序前后也并不影响最终的合并结果，能够自动安全的进行合并。虽然CRDTs最近才出现在业界视野中，但其实它已经在生产环境使用了很多年。已经有一些生产级别的库可以直接使用（Akka、Riak）。</p>

<p>然而，很多业务场景并不允许最终一致性。这时可以使用因果一致性（causal consistency）。因果关系很容易被大家理解。而且因果一致性模型能够实现可扩展性和可用性。其一般使用逻辑时间，在很多NoSQL数据库、事件日志以及分布式事件流产品中都可用。</p>

<p>分布式事务是一个经常使用的方式用来协调分布式系统的变动，但其本质需要约束并发执行，保证同一时间只有一个用户在操作。因此其成本非常昂贵，会使得系统变慢、无法扩展。<a href="http://bit.ly/22hhl6F">Saga模式</a>是分布式事务之外的一个能够实现可扩展、弹性伸缩的选择。它的理论基础在于一个长时间运行的业务事务大多时候都是由多个事务步骤组成的，而事务步骤的总体一致性能够通过将这些步骤分组成一个总体的分布式事务来实现。该技术将每一个阶段的事务与一个可补偿回滚的事务配对，如果一个阶段的事务失败了，那么总体的分布式事务就可以回滚（反向顺序）。</p>

<p><img src="//post_images/rx-ms/saga.png" alt="" /></p>

<h3>总结</h3>

<p>当设计一个响应式微服务时，需要坚持隔离、单一职责、自主、独占状态、异步消息传输和移动等特质。微服务需要协作才能形成一个系统去发挥作用。一个能够提供基础服务和响应式原则模式的复杂微服务平台是有必要的。</p>

<p><img src="http://www.rowkey.me/post_images/book-all.png" width="400"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[微服务的十个反模式和陷阱]]></title>
    <link href="http://www.rowkey.me/blog/2018/06/02/microservice-pitfall/"/>
    <updated>2018-06-02T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/06/02/microservice-pitfall</id>
    <content type="html"><![CDATA[<p>O’Reilly的电子书《Microservices AntiPatterns and Pitfalls》讲述了在微服务设计实现时十种最常见的反模式和陷阱。本文基于此书，将这十个点列出。书籍地址：<a href="https://www.oreilly.com/programming/free/microservices-antipatterns-and-pitfalls.csp">https://www.oreilly.com/programming/free/microservices-antipatterns-and-pitfalls.csp</a>，更全的反模式和陷阱可见作者的视频：<a href="http://oreil.ly/29GVuDG">http://oreil.ly/29GVuDG</a></p>

<!--more-->


<h2>数据驱动迁移反模式-Data-Driven Migration</h2>

<p><img src="//post_images/ms-anti/data-driven-1.png" alt="" /></p>

<p>如上图所示，此种反模式的问题在于微服务的粒度没有最终确定之前就做了数据迁移，如此当不断的调整服务粒度时，那么数据库就免不了频繁迁移，带来极大的成本。更好的方式如下图所示：</p>

<p><img src="//post_images/ms-anti/data-driven-2.png" alt="" /></p>

<p>即先分离功能，数据库先保持之前的单体，等到服务粒度最终确定之后，再分离数据库。</p>

<h2>超时反模式-The Timeout</h2>

<p>微服务架构是由一系列分离的服务组成的，这些服务之间通过一些远程协议进行互相之间的通信。其中牵扯到了服务的可用性和响应性问题。如下图所示：</p>

<p><img src="//post_images/ms-anti/availability-res.png" alt="" /></p>

<ul>
<li>可用性：服务消费方能够连接服务方，并可以向其发送请求。</li>
<li>响应性：服务方能够在消费方期望时间内给予请求响应。</li>
</ul>


<p>为了防止服务的不可用和无法响应，通常的做法就是设置一个调用超时。此种做法表面上看是没问题的，但是试想一下如下情景：发起一个购买100个商品的请求，请求成功返回一个确认号。如果当请求超时但是请求在服务端已经成功执行了，此时这个交易实际是完成的，但是消费方没有拿到确认号，如果重试请求，那么服务方需要一个复杂的机制判断这是否一次重复提交。</p>

<p>一种解决此问题的方案是设置一个较长的超时时间，如一个服务的通常响应耗时需要2s，最大耗时需要5s，那么超时时间可以设置为10s。但这样的问题就是如果服务不可用，所有消费方都得等待10s，这个是非常损耗性能的。</p>

<p>解决超时反模式的方案就是使用“断路器模式”。就类似于房屋中的电源断路器，当断路器关闭，电流可以通过，当断路器打开，那么电流中断一直到断路器关闭。断路器模式就是说当检测到服务方无法响应时就打开，后续的请求都会被拒绝掉。一旦服务方可响应了，那么断路器关闭，恢复请求。其工作模式如下图所示：</p>

<p><img src="//post_images/ms-anti/circuit-breaker.png" alt="" /></p>

<p>断路器会持续地监测远程服务，确保其是可响应的。只要服务可响应，那么断路器会一直关闭，允许请求通过。如果服务突然不可响应，那么断路器打开，拒绝后续的请求。而后续如果断路器又检测到服务恢复了，那么断路器会自动关闭，请求也就恢复了。此种方案与超时时间相比，最大的优势就是一旦服务不可响应，那么断路器模式可以让请求立刻返回而不是需要等待一定的时间。</p>

<p>Hystrix的Netflix是此种断路器模式的一种开源实现。此外，Akka中也包含了一个断路器实现：Akka CircuitBreaker类。</p>

<p>关于“断路器模式”的详细信息可见：<a href="https://martinfowler.com/bliki/CircuitBreaker.html">https://martinfowler.com/bliki/CircuitBreaker.html</a>。</p>

<h2>共享反模式-I Was Taught to Share</h2>

<p>微服务被普遍认为是一种不共享任何东西的架构。但实际上只能是尽可能地少共享，毕竟在某些层面代码被多个服务共享也能带来一定好处。例如，与单独部署一套安全服务（认证和授权）其他所有服务都通过远程访问此服务相比，把安全相关的功能封装成jar包（security.jar），然后其他服务都集成此jar包，就能够避免每次都要发起对安全服务的访问，从而提高性能和可靠性。但后面的方案带来的问题就是依赖噩梦：每一个服务都依赖多个自定义的jar包。如此不仅打破了服务之间的边界上下文，同时也引入了诸如总体可靠性、变更控制、易测试性、部署等问题。</p>

<p>在一个使用面向对象编程语言的单体应用中，使用abstract类和接口实现代码复用和共享是一个良好的实践。但当从单体切换到微服务架构时，对于很多自定义的共享类和工具类（日期、字符串、计算）的处理要考虑到微服务间共享的东西越少越有利于保持服务间的边界上下文，从而更利于快速测试和部署。以下是几种推荐的方式，也是解决“共享反模式”的方案：</p>

<ol>
<li><p>共享项目</p>

<p> <img src="//post_images/ms-anti/share-project.png" alt="" /></p>

<p> 将共享的代码作为一个项目在编译期与各个服务集成。此种方式便于变更和开发软件，但是最大的问题在于很难发觉哪一个共享模块被修改以及修改的原因，也无法确定自己的服务是否需要这些变更。尤其是在服务发布前期发现某一个共享模块发生了变动的话需要再一次的测试才能走后续流程。</p></li>
<li><p>共享库</p>

<p> <img src="//post_images/ms-anti/share-library.png" alt="" /></p>

<p> 此种方式即将共享的代码作为类库集成到服务中。如此每次共享的库有改动，服务都需要重新打包、测试、重启。但相比起第一种，其有版本标记，能够更好地控制服务的部署和开发，服务开发者可以自己控制何时将共享库的改动集成进来。</p>

<p> 更进一步的，如果采用此种方案，一定要避免把所有共享的代码都打包进一个jar包中如common.jar。否则会很难确定何时要把库的变动集成到服务中。更好的做法是将共享代码分成几个单独上下文的库，如：security.jar、dateutils.jar、persistence.jar等，如此会比较容易的确定何时去集成共享库的变动。</p></li>
<li><p>冗余</p>

<p> <img src="//post_images/ms-anti/replica.png" alt="" /></p>

<p> 此种方案违反DRY原则，在每一服务中都冗余一份共享代码，能够避免依赖共享也能够保持边界上下文。但是一旦共享的代码有变动，那么所有服务都需要改动。因此，此种方案适用于共享模块非常稳定，极小可能变动的情况。</p></li>
<li><p>服务合并</p>

<p> <img src="//post_images/ms-anti/consolidation.png" alt="" /></p>

<p> 当多个服务共享的代码变动比较频繁时可以采用此种方案合并成一个服务，如此就避免了多了服务频繁的测试和部署，也避免了依赖共享库。</p></li>
</ol>


<h2>可达性报告反模式-Reach-in Reporting</h2>

<p>微服务中各个服务以及其相应的数据都是包含在一个单独的边界上下文中的，也就是说数据是隔离到多个数据库中的。因此，这也会使得收集微服务的各种数据生成报告变得相对困难。一般来说有四种方案解决这个问题。其中，前三种都是从各个微服务中拉取数据，是这里所说的反模式，被称作“Reach-in Reporting”。</p>

<ol>
<li><p>数据库拉取模式</p>

<p> <img src="//post_images/ms-anti/database-pull.png" alt="" /></p>

<p> 报告服务直接从各个服务的数据库中拉取数据从而生成各种报告。此种方式简单迅速，但是会让报告服务和业务服务相互依赖，是一种数据库共享集成风格（通过共享的数据库将多个应用耦合在一起）。如此一旦数据库有改动，所有相关服务都要改动，也就打破了微服务中极为重要的边界上下文。</p></li>
<li><p>HTTP拉取模式</p>

<p> <img src="//post_images/ms-anti/http-pull.png" alt="" /></p>

<p> 与数据库拉取模式相比，此种方式不再是直接去访问服务的数据库，而是通过HTTP接口去请求服务的数据。此种方式能够保持服务的边界上下文，但是性能比较慢，而且HTTP请求无法很好的承载大数据。</p></li>
<li><p>批量拉取模式</p>

<p> <img src="//post_images/ms-anti/batch-pull.png" alt="" /></p>

<p> 此种方式会有一个单独的报告数据库/数据仓库来存储各个服务的聚合数据。会通过一个批量任务（离线或者基于增量实时）将服务更新的数据导入到报告数据库/数据仓库中。与数据库拉取模式一样，此种方式这也是一种数据库共享集成风格，会打破服务的边界上下文。</p></li>
<li><p>异步事件推送模式</p>

<p> <img src="//post_images/ms-anti/event.png" alt="" /></p>

<p> 此种方式即解决“Reach-in Reporting&#8221;反模式的方案。每个服务都把自己的发生的事件异步推送到一个数据捕获服务，后续数据捕获服务会将数据解析存储到报告数据库中。此种方式实现起来较复杂，需要在服务和数据捕获服务之间制定一种协议用于异步传输事件数据。但其能够保持服务的边界上下文，同时也能保证数据的时效性。</p></li>
</ol>


<h2>沙粒陷阱-Grains of Sand</h2>

<p>微服务实现中最有挑战的问题在于如何拆分service，如何控制服务的粒度，而正确的服务粒度则决定了微服务是否能够成功实现。服务粒度也能够影响到性能、健壮性、可靠性、易测试性、部署等。</p>

<p>“沙粒陷阱”即把服务拆分的太细。其中的一个原因就是很多时候开发者会把一个class与一个服务等同。合理的，应该是一个服务组件(Service component)对应一个服务。一个服务组件具有清晰、简洁的角色、职责，具有一组定义好的操作。其一般通过多个模块(Java Class)实现。如果组件和模块是一对一的关系，那么不仅仅会造成服务粒度过细同时也是一种不好的编程实践：服务的实现都是通过一个Class，那么此Class会非常大并且承担太多的责任，不利于测试和维护。</p>

<p>更进一步的，服务的粒度并不应该受其中实现类的数目影响：有些服务可能只需要一个类就可以实现，而有些服务会需要多个类来实现。</p>

<p>为了避免“沙粒陷阱”，可以通过以下三种测试来判断服务粒度是否合理：</p>

<ol>
<li><p>分析服务范围和功能</p>

<p> 要明确服务用来干什么？有哪些操作？一般通过使用文档或者语言来描述服务的范围和功能就能够看出来服务是否做的工作太多。如果在描述中使用了“和”（“and”）或者“此外”（“in addition”）之类的词，很有可能就是此服务职责太多。</p>

<p> 服务的高内聚是一种良好的实践，其明确一个服务提供的操作之间必须要是有关联的。如对于一个顾客服务，有以下操作：</p>

<ul>
<li>添加顾客</li>
<li>更新顾客信息</li>
<li>获取顾客信息</li>
<li>通知顾客</li>
<li>记录顾客评论</li>
<li>获取顾客评论</li>
</ul>


<p> 其中的前三个操作都是对顾客的CRUD操作，是相关联的。而后三者则无关。为了实现服务的高内聚，合理的应该是把此服务拆分成三个服务：顾客维护、顾客通知、顾客评论。</p>

<p> 如此，以粗粒度的服务开始，然后逐渐拆分成细粒度的服务有利于对微服务的拆分。</p></li>
<li><p>分析数据库事务</p>

<p> 传统的关系型数据库都提供了ACID事务特性用于把多个更新操作打包成一个整体提交，要么都成功，要么都失败。而在微服务中，由于服务都是一个个分离的应用，很难实现ACID，一般实现BASE事务（basic availability、soft state、eventual consistence）即可。但是无法避免的，仍然会有一些场景是需要ACID的。因此，当你不断的需要在BASE和ACID事务做判断和取舍的时候，很有可能就是服务粒度过细。</p>

<p> 如果业务场景无法接受最终一致性，那么最好就是将服务粒度粗化一些，把多个更新操作放到一个服务中。</p></li>
<li><p>分析服务编排</p>

<p> 这里主要说的是服务之间的互相通信。由于对服务的调用都是一次远程调用，因此服务编排会非常大的影响微应用总体的性能。此外，它也会影响系统整体的健壮性和可靠性，越多的远程调用，那么越高的几率会有失败或者超时的请求出现。</p>

<p> 如果发现完成一次业务逻辑需要调用太多的远程服务，就说明服务的粒度可能太细了。这时候就需要将服务粗化。而合并细粒度服务还能够提高性能，提升总体的健壮性和可靠性。同时也减少了多个服务间的依赖，更利于测试和部署。</p>

<p> 此外，使用响应式编程技术异步并行调用远程服务也是一种提升性能和可靠性的方案。</p></li>
</ol>


<h2>无因的开发者陷阱-Developer Without a Cause</h2>

<p>此陷阱主要讲的是开发者或者架构师在做设计时很多时候是拍脑袋在做，没有任何合理的原因或者原因是错误的，也不会做取舍。而想要解决此问题，不仅仅是架构师，开发者也需要同时了解技术带来的好处以及缺陷，从中做权衡。</p>

<p>了解业务驱动是避免此陷阱的关键一步。每一个开发者和架构师都应该清楚的了解下面这些问题的答案：</p>

<ul>
<li>为什么要使用微服务？</li>
<li>最重要的业务驱动是什么？</li>
<li>架构中的哪一点是最为重要的？</li>
</ul>


<p>假如易部署性、性能、健壮性、可扩展性是系统最看重的特性，那么对于不同的业务侧重点，微服务的粒度需求也是不同的。细粒度的服务能够达到更好的易测试性和易部署性，而粗粒度的服务则有更好的性能、健壮性以及可靠性。</p>

<h2>追随流行陷阱-Jump on the Bandwagon</h2>

<p>微服务是目前非常流行的架构理念，越来越多的公司也都在紧跟这个潮流纷纷转型微服务架构，而不管到底自己是否真的需要。为了避免此陷阱，需要首先了解微服务的优点和缺点。</p>

<p>优点：</p>

<ul>
<li>易部署：容易部署是微服务的一个很大的优点。毕竟相比起一个庞大的单体应用，一个小并且职责单一的微服务的部署非常简单并且带来的风险也会小很多。而持续部署技术则进一步放大了这个优点。</li>
<li>易测试：职责单一、共享依赖少使得测试一个微服务是很容易的。而基于微服务做回归测试与单体大应用相比也是很容易的。</li>
<li>控制变更：每个服务的范围和边界上下文使得很容易控制服务的功能变动。</li>
<li>模块化：微服务就是一个高度模块化的架构风格。这种风格也是一种敏捷方式的表达，能够很快的响应变化。一个系统模块化程度越高，就越容易测试、部署和发布变更。一个服务粒度划分合理的微服务系统是所有架构中模块化程度最高的架构形式。</li>
<li>可扩展性：由于每一个服务都是一个职责单一的细粒度服务，因此此种架构风格是所有架构分隔中可扩展性最高的。其非常容易扩展某一个或者某几个功能从而满足整体系统的需求。而得益于服务的容器化特性以及各种运维监控工具，服务也能够自动化进行启动和关闭。</li>
</ul>


<p>缺点：</p>

<ul>
<li>组织变动：微服务需要组织在很多层面进行变动。研发团队需要包含UI、后端开发、规则处理、数据库处理建模等多种职位，从而使得一个小的团队能够具有实现微服务的所有技术栈。同时，传统的单体、分层应用架构的软件发布流程也需要更新为自动化、高效的部署流水线。</li>
<li>性能：由于服务都是隔离的，因此发起对服务的远程调用肯定是会影响性能的。服务编排、运行环境都是影响性能的很大因素。了解远程调用的延迟、需要与多少服务通信都是与性能相关的需要掌握的信息。</li>
<li>可靠性：和性能一样。服务的远程调用越多，那么失败的几率就越高，总体的可靠性就会越低。</li>
<li>DevOps：随着微服务架构而来的是成千上百的服务。手动管理这么多的服务是很不现实的。这就对于自动化运维部署、协作提出了很高的挑战。需要依赖非常多的操作工具和实践，是一个非常复杂的工作。目前差不多有12种类型的操作工具（监控工具、服务注册、发现工具、部署工具等）和框架在微服务架构中被使用，其中每一种又包含了很多具体的工具和产品供选择。对于这些工具和框架的选择一般都会需要将近数月的研究、测试、权衡分析才能做出最适合的技术选型。</li>
</ul>


<p>了解了微服务的优缺点后，下一步则需要根据实际的业务来分析微服务是不是解决这些问题的最佳方案。可以采取以下问题：</p>

<ul>
<li>业务和技术的目标是什么？</li>
<li>使用微服务是为了完成什么？</li>
<li>目前和可预知的痛点是什么？</li>
<li>应用的最关键的技术特性是什么？（性能、易部署性、易测试性、可扩展性）</li>
</ul>


<p>回答这些问题再结合微服务的优缺点能够让你明确现在是否是使用微服务的适当时机。</p>

<p>除了微服务以外，还有其他7种比较普遍使用的架构供选择：</p>

<ul>
<li>基于服务的架构（Service-Based）</li>
<li>面向服务的架构（Service-Oriented）</li>
<li>分层架构（Layered）</li>
<li>微内核架构（Microkernel）</li>
<li>基于空间的架构（Space-Based）</li>
<li>事件驱动架构（Event-Driven）</li>
<li>流水线架构（Pipeline）</li>
</ul>


<h2>静态合约陷阱-The Static Contract</h2>

<p>微服务的消费方和服务提供方之间会有一个合约/协议用来规定输入输出数据的格式、操作名称等等。一般情况下这个合约是不变的。但是如果没有使用版本号来管理服务接口，那么就会进入“静态合约”陷阱。</p>

<p>给合约打上版本标记不仅仅能够避免巨大的变动（服务提供方修改合约使得所有消费方也都得修改），还能够提供向后兼容性。这里有两种技术可以实现合约的版本号：</p>

<ul>
<li><p>在头部信息附加版本号</p>

<p>  <img src="//post_images/ms-anti/header-version.png" alt="" /></p>

<p>  如图，此种方式即在远程访问协议的头部添加版本信息。而如果远程协议使用的是REST，那么还可以使用vendor mime type（vnd）来指定合约的版本号。如下：</p>

<pre><code class="``">  POST /trade/buy
  Accept: application/vnd.svc.trade.v2+json
</code></pre>

<p>  服务接受到请求，能够通过正则等手段简单解析出其中的合约版本号再根据版本号做相应的处理。</p>

<p>  如果使用消息队列，那么可以将版本号放置在属性部分(Property section)。JMS的一个例子如下：</p>

<pre><code class="``">  String msg = createJSON("acct","12345","sedol","2046251","shares","1000");
  jsmContext.createProducer()
      .setProperty("version",2)
      .send(queue,msg);
</code></pre></li>
<li><p>在合约本身中附加版本号</p>

<p>  <img src="//post_images/ms-anti/schema-version.png" alt="" /></p>

<p>  此种方式版本号独立于远程访问协议，与头部信息版本号相比，这也是其最大的优点。但与此同时，其缺点比较多。首先要从请求信息主体中解析版本号，会出现很多解析的问题。其次，合约的模式可能会非常复杂，使得很难做数据转换。最后，服务还要引入对模式的验证逻辑。</p></li>
</ul>


<h2>我们到了吗陷阱-Are We There Yet</h2>

<p>微服务架构中，各个服务都是独立的个体，也就意味着所有客户端或者API层和服务之间的通信都是一次远程调用。如果对这些远程调用的耗时没有什么概念，那么就陷入了“Are We There Yet”陷阱。合理的做法需要去测试远程访问的平均延迟、长尾延迟（95%、99%、99.%之外的请求延迟）等指标。而很多时候即使有很好的平均延迟，但是较差的长尾延迟会造成非常大的破坏。</p>

<p>在生产环境或者准生产环境测试有助于去了解应用的真实性能。例如，一个业务请求需要调用四个服务，假设一个服务调用的延迟是100毫秒，那么加上业务请求本身的延迟，完成此次业务请求共需要500毫秒的延迟。这和单单从代码上去看得出的结论是不一样的。</p>

<p>了解目前所用协议的平均延迟是一方面，另一方面则需要对比其他远程协议的延迟，从而在合适的地方使用合适的协议。如：JMS、AMQP、MSMQ。</p>

<p><img src="//post_images/ms-anti/comparing-protocol.png" alt="" /></p>

<p>如图，AMQP协议的性能是最好的。那么结合业务场景，就可以选择REST作为客户端与服务间的通信协议，AMQP做为服务之间的通信协议以提高应用的性能。</p>

<p>当然，性能并非在选择远程协议时唯一考虑的因素。下一节中就会考虑利用消息队列的一些额外功能。</p>

<h2>REST使用陷阱-Give It a Rest</h2>

<p>REST现在是微服务中用的最多的通信协议。流行的开发框架如DropWizard、Spring Boot都提供了REST支持。但是如果只选择REST这一种协议，不去考虑其他诸如消息队列的优势，那么就陷入了“REST使用”陷阱。毕竟异步通信、广播、合并请求事务这些需求，REST是很难实现的。</p>

<p>消息队列标准目前包括平台特定和平台无关两种。前者包括Java平台中的JMS和C#平台的MSMQ，后者则是AMQP。对于平台特定的消息标准JMS，其规范了API，因此切换broker实现（ActiveMQ、HornetQ）时无需修改API，但由于底层通信协议是不同的，集成的客户端或者服务端jar包需要随着修改。对于平台无关的消息标准，其规范了协议实现标准，并没有规范API。使得不同平台之间都可以互相通信，而不管实际产品是什么。如一个使用了RabbitMQ的客户端可以很容易地与一个StormMQ通信（假设使用的协议相同）。也就是其独立于平台的特性使得RabbitMQ成为微服务架构中最流行的消息队列。</p>

<ol>
<li><p>异步请求</p>

<p> 异步通信是消息队列适用的场景之一。服务消费者发起请求后无需等待服务方响应能够提高总体的性能，同时调用方无需担心调用超时，也就无需使用断路器，从而提高了系统的可靠性。</p></li>
<li><p>广播</p>

<p> 将消息广播给多个service是消息队列的又一个适用场景。一个消息生产者向多个消息接受者发送消息，无需知道谁在接受消息以及如何处理它。</p></li>
<li><p>事务请求</p>

<p> 消息系统提供了对事务消息的支持：如果多个消息被发送到了在一个交易上下文的多个队列或者主题中时，那么直到消息发送者commit，服务才会真正的接受到相应的所有消息（在commit之前会一直保存在队列中）。</p>

<p> 因此对于服务消费者需要合并多个远程请求到一个事务中的场景可以选择事务消息。</p></li>
</ol>


<p><img src="http://www.rowkey.me/post_images/book-all.png" width="400"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[架构简明指南]]></title>
    <link href="http://www.rowkey.me/blog/2018/04/25/arch-usage/"/>
    <updated>2018-04-25T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/04/25/arch-usage</id>
    <content type="html"><![CDATA[<p>之前的<a href="http://www.rowkey.me/blog/2017/08/24/arch/">《谈谈架构》</a>讲述了架构的概念、原则等等，这里择出其中的设计原则部分供大家随手参考。</p>

<p>《Clean Architecture》一书中对于软件架构目的的解释：</p>

<blockquote><p>The goal of software architecture is to miminize the human resources required to build and maintain the required system.</p></blockquote>

<p>即：软件架构的目的就是将构建和维护系统需要的人力成本降到最低。</p>

<p>因此，可以得出架构设计的关键思维就是判断和取舍（程序设计的关键思维是逻辑和实现），即如何选择技术、组合技术使得需要的人力资源最少。</p>

<p>需要注意的一点是，脱离业务谈架构是不合理的，技术架构及其演进都是业务目标驱动的。</p>

<!--more-->


<h2>架构原则</h2>

<p><img src="//images/blog_images/arch-spec.png" alt="" /></p>

<ul>
<li><strong>避免过度设计</strong>：简单的架构就是最好的架构。最简单的方案最容易实现和维护，也可以避免浪费资源。但方案中需要包括扩展。</li>
<li><strong>冗余设计</strong>：对服务、数据库的做结点冗余，保证服务的高可用。通过数据库主从模式、应用集群来实现。</li>
<li><strong>多活数据中心</strong>：为了容灾，从根本上保障应用的高可用性。需要构建多活的数据中心，以防止一个数据中心由于不可控因素出现故障后，引起整个系统的不可用。</li>
<li><strong>无状态设计</strong>：API、接口等的设计不能有前后依赖关系，一个资源不受其他资源改动的影响。无状态的系统才能更好地进行扩展。如果非得有状态，则要么客户端管理状态，要么服务端用分布式缓存管理状态。</li>
<li><strong>可回滚</strong>：对于任何业务尤其是关键业务，都具有恢复机制。可以使用基于日志的WAL、基于事件的Event sourcing等来实现可回滚。</li>
<li><strong>可禁用/自我保护</strong>：具有限流机制，当上游的流量超过自身的负载能力时，能够拒绝溢出的请求。可以通过手动开关或者自动开关（监测异常流量行为），在应用前端挡住流量。限流算法包括：令牌桶（支持突发流量）、漏桶（匀速流量）、计数器以及信号量（限制并发访问的数量）。此外永远不要信赖第三方服务的可靠性，依赖于第三方的功能务必有服务降级措施以及熔断管理，如：对于每一个网络操作，都需要设置超时时间，超过这个时间就放弃或者返回兜底响应。</li>
<li><strong>问题可追踪</strong>：当系统出现问题时，能够定位请求的轨迹、每一步的请求信息等。分布式链路追踪系统即解决的此方面的问题。</li>
<li><strong>可监控</strong>：可监控是保障系统能够稳定运行的关键。包括对业务逻辑的监控、应用进程的监控以及应用依赖的CPU、硬盘等系统资源的监控。每一个系统都需要做好这几个层面的监控。</li>
<li><strong>故障隔离</strong>：将系统依赖的资源(线程、CPU)和服务隔离开来能够使得某个服务的故障不会影响其他服务的调用。通过线程池或者分散部署结点可以对故障进行隔离。此外，为不同的用户提供单独的访问通道，不仅仅能够做故障隔离，也有利于做用户权限控制。</li>
<li><strong>成熟可控的技术选型</strong>：使用市面上主流、成熟、文档、支持资源多的技术，选择合适的而非最火的技术实现系统。如果面对自研和开源技术的选择，需要考虑契合度：如果功能需求契合度很高，那么选择开源即可；如果开源技术是需求的子集或者超集，那么要衡量吃透这个开源技术的成本和自研的成本那个高。</li>
<li><strong>梯级存储</strong>：内存->SSD硬盘->传统硬盘->磁带，可以根据数据的重要性和生命周期对数据进行分级存储。</li>
<li><strong>缓存设计</strong>：隔离请求与后端逻辑、存储，是就近原则的一种机制。包括客户端缓存（预先下发资源）、Nginx缓存、本地缓存以及分布式缓存。</li>
<li><strong>异步设计</strong>：对于调用方不关注结果或者允许结果延时返回的接口，采用队列进行异步响应能够很大程度提高系统性能；调用其他服务的时候不去等待服务方返回结果直接返回，同样能够提升系统响应性能。异步队列也是解决分布式事务的常用手段。</li>
<li><strong>前瞻性设计</strong>：根据行业经验和预判，提前把可扩展性、后向兼容性设计好。</li>
<li><strong>水平扩展</strong>：相比起垂直扩展，能够通过堆机器解决问题是最优先考虑的问题，系统的负载能力也才能接近无限扩展。此外，基于<strong>云计算</strong>技术根据系统的负载自动调整容量能够在节省成本的同时保证服务的可用性。</li>
<li><strong>小步构建和发布</strong>：快速迭代项目，快速试错。不能有跨度时间过长的项目规划。</li>
<li><strong>自动化</strong>：打包、测试的自动化称为持续集成，部署的自动化称为持续部署。自动化机制是快速迭代和试错的基础保证。</li>
</ul>


<h2>架构六步思考法</h2>

<blockquote><p>笔者对美团总架构师夏华夏一次分享提出的架构六步思考法的理解。</p></blockquote>

<p><img src="http://www.rowkey.me/post_images/arch-six-think.png" width="450"/></p>

<p>这里尤其需要注意的一点是在面对问题时，首先要试图将未知问题转化为已知问题，而不是创造新问题。</p>

<h2>数据设计原则</h2>

<ul>
<li>注意存储效率

<ul>
<li>减少事务</li>
<li>减少联表查询</li>
<li>适当使用索引</li>
<li>考虑使用缓存</li>
</ul>
</li>
<li>避免依赖于数据库的运算功能(函数、存储器、触发器等)，将负载放在更容易扩展的业务应用端</li>
<li>数据统计场景中，实时性要求较高的数据统计可以用Redis；非实时数据则可以使用单独表，通过队列异步运算或者定时计算更新数据。此外，对于一致性要求较高的统计数据，需要依靠事务或者定时校对机制保证准确性。</li>
<li>索引区分度法则：辨识度超过20%的属性，如果有查询需求，就应该建立索引。</li>
<li>对于数值型数据，可以使用保序压缩方式在保证顺序不变的前提下减少字符串长度。如：进行36进制转化即一种保序压缩方式。</li>
<li>大量数据的去重计数如果允许误差可以选择基数估计算法（Hyperhyperlog、Loglogcount）或者布隆过滤器。</li>
</ul>


<h2>系统响应性能提升五板斧</h2>

<ul>
<li><strong>异步</strong>：队列缓冲、异步请求。</li>
<li><strong>并发</strong>：利用多CPU多线程执行业务逻辑。</li>
<li><strong>就近原则</strong>：缓存、梯度存储。</li>
<li><strong>减少IO</strong>：合并细粒度接口为粗粒度接口、频繁的覆盖操作可以只做最后一次操作。这里一个需要特别注意的地方: <strong>代码中尽量避免在循环中调用外部服务，更好的做法是使用粗粒度批量接口在循环外面只进行一次请求。</strong></li>
<li><strong>分区</strong>：频繁访问的数据集规模保持在合理的范围。</li>
</ul>


<h2>系统容量规划</h2>

<p>需要对系统/关键模块做好评估、量化，以防止超出容量时不至于压垮服务器，仍然能够服务于大部分用户。</p>

<p><img src="//post_images/capacity-plan.png" alt="" /></p>

<p>在容量预估中，机器数目的计算遵循DID原则：20倍设计、3倍实施、1.5倍部署。即需要部署1.5倍的可承载预估业务流量的机器数目。</p>

<h2>架构重构的原则</h2>

<p>一个系统的架构是随着业务而不断演化的，因此不可避免地会留下很多技术债。如果一味地不去管，那么总有一天技术债会爆发出来造成意想不到的破坏。因此很多时候对架构的重构是必须的。其需要遵循的原则如下：</p>

<ul>
<li>确定重构的目的和必要性：为了业务需要；有无其他备选方案</li>
<li>定义“重构完成”的界限</li>
<li>渐进式重构</li>
<li>确定当前的架构状态</li>
<li>不要忽略数据</li>
<li>管理好技术债务</li>
<li>远离那些虚荣的东西</li>
<li>做好面对压力的准备</li>
<li>了解业务</li>
<li>做好面对非技术因素的准备</li>
<li>能够掌握代码质量</li>
</ul>


<p><img src="http://www.rowkey.me/post_images/book-all.png" width="400"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浅析区块链]]></title>
    <link href="http://www.rowkey.me/blog/2018/03/15/blockchain/"/>
    <updated>2018-03-15T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/03/15/blockchain</id>
    <content type="html"><![CDATA[<p>从去年开始，区块链突然如火如荼起来，相关的新闻席卷微博、朋友圈、科技论坛、门户网站等各大媒体。业界大佬们更是频频发言，有宣称不做区块链就会被时代淘汰的，有说坚决不碰区块链的。国家队也是频频出手，管制、定性、做应用，央行更是默默地把区块链专利数量做到了世界前列。面对众多纷杂的信息、众多的技术分析文章，很容易让人脑袋嗡嗡，怕不懂，更怕懂了啥也都做不了。于是决定梳理一下相关的信息，看看这区块链到底是什么东西。</p>

<p>开篇之前，先抛出笔者的一个观点：<strong>区块链最合适的应用场景只有虚拟资产,除了虚拟资产的其他场景都是在蹭概念或者不是真正意义上的区块链，而且只要有人参与的业务流程都无法满足区块链设计的初衷。</strong></p>

<!--more-->


<h2>区块链是什么</h2>

<p>说到区块链，需要先了解其产生的背景，这样才能理解为何如此设计区块链。区块链的出现是和“暗网”相关的。所谓“暗网”与我们常见的“互联网”相比，只有通过特殊的软件才能够访问，并且在暗网上基本都是些黑市交易，无法见光，参与这些交易的人都不想暴露真实的位置、个人信息。应对这种交易需求，才出现了比特币。所以说，区块链一开始是为了解决匿名交易的问题出现的，也就是比特币。这也是区块链的第一个阶段，即一套账本体系和货币发行机制；后来基于区块链技术，出现了以太坊，在改进比特币区块的基础上加入了智能合约机制，称之为区块链2.0；以太坊之后，类似以太坊的一些扩展应用，能够对于每一个互联网中代表价值的信息和字节进行产权确认、计量和存储，能够扩展到几乎任何领域，这是区块链的第三个阶段，区块链将完成价值的交换。目前处在区块链2.0阶段。</p>

<p>其实从本质上看，区块链和Git类似，每个节点都有一份数据的存储，不同的是区块链没有中央服务器这么个概念，就是一个分布式无中心数据库，其有效的通过数学的方式在数据库没有管理员的情况下对内容达成一致，并且不通过正式工资或是分得股权就能奖励那些帮助使数据库变得更有价值的人们，最终能够实现无争议无抵赖的匿名交易。概括来看，其特点如下：</p>

<ul>
<li>去中心化：互联网本来的意义就是平等开放，所以有一种言论就是区块链是回归互联网本来意义的希望。这一点是区块链天然的优势，所有节点都存有数据的副本即实现了“去中心化”。</li>
<li>无法篡改: 得益于区块之间的链式结构，可以保证数据无法篡改或者篡改的成本远大于收益。</li>
<li>公开透明：每个节点保存的信息相同，能够消除信息不对称，实现信息透明。</li>
</ul>


<p>与传统的关系型数据库用一张表或者多张独立的表存储数据，“区块链”使用多个“数据表”并且多个“数据表”形成前后衔接的链式结构，以防止数据被篡改（修改任何一个区块就破坏了链式结构）。总体的结构如下所示：</p>

<p><img src="//post_images/blockchain/bc.jpg" alt="" /></p>

<p>其中每一个“数据表”在区块链中被称为“区块”。格式如下：</p>

<p><img src="//post_images/blockchain/block.jpg" alt="" /></p>

<p>这是区块链技术基本都具有的一些头部信息，包括4字节的版本号、32字节的上一个区块的哈希值、32字节的Merkle根、4字节的时间戳（当前时间）、4字节的难度目标以及4字节的随机数。</p>

<ul>
<li>版本号：用于跟踪软件/协议的更新。如果新版本的软件不兼容旧版本的软件，那么就认为是发生了“分叉”。</li>
<li>上一区块头哈希值：存储的是链上上一个区块的哈希值，也是区块链设计的精髓所在。</li>
<li>Merkle根：又叫做梅克尔根，是一种用于完整性证明的数据结构，为了能够在区块头中体现出交易而做的一个计算，同时也是为了解决交易记录进行Hash计算的效率问题。</li>
<li>时间戳：该区块产生的近似时间。这个时间虽然是节点生成的但是其是否有效需要其他节点的认可（允许有一定程度的误差）。时间戳使得交易有先后，是防范双重支付攻击的一个关键设计。</li>
<li>难度目标：该区块工作量证明的算法的难度系数。系数越大，目标哈希值的0越多，计算的难度呈指数增长。</li>
<li>Nonce: 用于工作量证明算法的计数器。</li>
</ul>


<p>区块体的信息主要是交易列表。交易的数据结构因平台的不同而不同。比特币中就是简单的交易信息，以太坊则会存放智能合约。这里需要提到的是比特币中使用UTXO（未花费的交易输出，Unspent Transaction Output）实现支付系统的账户模型，并没有余额、钱包的概念，交易列表中的关键信息也是一些UTXO的组成,如此计算账户的余额则需要通过遍历整个交易历史来最终计算出每个账户的余额。UTXO的示例如下图所示：</p>

<p><img src="//post_images/blockchain/utxo.png" alt="" /></p>

<p>可见除了coinbase这种交易之外，其他的交易都至少有一个交易的输入且必须引用一个输出，而一笔交易的输入可以引用之前多笔交易的输出。此外，任何一笔交易的交易输入总量必须等于交易输出总量（支出与找零）。其一般结构如下：</p>

<p><img src="//post_images/blockchain/utxo-struct.png" alt="" /></p>

<p>使用UTXO的优势如下：</p>

<ul>
<li>私密性比较强，理论上可以为每一笔输出设置一个地址。</li>
<li>无需维护余额等状态值。</li>
<li>UTXO是独立数据记录，可以通过并行极大的提升区块链交易验证速度。</li>
<li>无需关心事务问题，只需要关心输出脚本即可。</li>
<li>能够清理过期交易，回收存储空间。</li>
</ul>


<p>而以太坊则使用了传统所理解的账户模型，主要是因为UTXO无法支持图灵完备的智能合约实现。</p>

<p>此外，还需要说一下“块高度”的概念。区块链网络的创世块（第一个区块）的块高度为0，如此每增加一个区块高度就+1，如第一个图所示，如果最左侧的块为创世块，那么最后一个区块的块高度就是2。</p>

<h2>区块链典型流程</h2>

<p>以<strong>比特币</strong>为例，区块链的一个典型交易流程：</p>

<ul>
<li>新的交易向全网所有节点广播，交易信息包括发UTXO输入、UTXO输出等关键信息。这里一个交易并不需要抵达全部的节点。只要交易信息能够抵达足够多的节点，那么他们将很快被整合进一个区块中。</li>
<li>每一个节点都将收到的交易信息经过验证无误后（使用解锁加锁脚本自动化验证）纳入一个区块中（被打包到块之前这些交易被存储在内存池中）。</li>
<li>每一个节点都尝试根据最新的区块的信息找到一个具有足够难度的工作量证明。</li>
<li>当一个节点找到了一个工作量证明，就创造一个新的区块（将接收到的交易纳入其中），并向全网进行广播。</li>
<li>当且仅当包含在该区块中的所有交易都是有效的且之前未存在过的，其他节点才认同该区块的有效性。</li>
<li>其他节点表示他们接受该区块，而表示接受的方法，是在跟随该区块的末尾制造新的区块以延长该链条，将被接受区块的随机散列值做为新区快的Prev随机散列值。</li>
</ul>


<h2>区块链技术架构</h2>

<p>其实从本质来看，区块链不能算是一个新的技术，更应该看做是一个新的技术框架，是基于很多成熟的技术而成的，而且不仅仅是技术，还有金融学，货币学，博弈学等。其技术架构如下图所示：</p>

<p><img src="//post_images/blockchain/arch.jpg" alt="" /></p>

<p>其中，区块的链式结构、UTXO以及智能合约是比特币发明人“中本聪”的原创发明。</p>

<h2>存储</h2>

<p>区块链在每一个节点会存储数据，并且需要持久化存储，存储方式和传统的应用一样，包括数据库和文件系统。</p>

<p>对于存储方式的选择, 区块链中并没有做相关的规定，而比特币和以太坊都使用LevelDB做为持久化存储方式。</p>

<h2>通信机制</h2>

<p>区块的通信是基于P2P技术,即不区分客户端和服务端的网络，和P2P下载是类似的原理。在区块链中其功能点包括：</p>

<ul>
<li>把需要存储的数据广播到所有节点上进行储存，也就是多播。</li>
<li>查询整个网络集群中所有节点的最新数据，如果自己节点的数据与大部分节点的数据不一致，则更新自身的数据与大部分节点存储的数据一致。这个功能也是防止数据被篡改的一个很重要的机制，是区块链核心的一个原则“少数派服从多数派”。当然这个也会引起51%攻击的问题。但区块链使用其他的机制极大杜绝了这种风险，下文会提到。</li>
</ul>


<h2>安全机制</h2>

<p>区块链同样使用了很多成熟的安全技术来保障其特点。</p>

<ul>
<li>哈希算法：⽤来对⼀段数据进行计算，得出⼀个摘要信息，通俗点说就是给一段数据⽣成⼀个固定大小的身份ID, 且其是不可逆的。区块链使用哈希做工作量证明、交易ID生成、区块之间的关联等。此外，区块头中的Merkle Root也是使用哈希算法做完整性证明的（比特币中使用double-SHA256哈希算法）。常用哈希算法包括MD5、SHA1、SHA256等。</li>
<li>数据加密：区块链使用了非对称加密算法。比特币中的钱包地址本质就是一对公钥私钥。此外，区块链利用公钥哈希加锁比特币的输入记录，阻止输出。</li>
<li>数字签名：同样基于非对称加密技术，用签名和公钥解锁自己的比特币输入记录，使用比特币。</li>
<li>零知识证明：所谓零知识证明即在不知道答案的情况下去验证给出的答案是否正确。这个过程完全靠机器验证，机器根据题目给出随机试验以验证答案是否正确。在某些区块链应用中如Zcash\ZCoin即使用了零知识证明来保证交易双方和交易金额的匿名性, 提供了绝佳的支付隐私。详细可见：<a href="https://mp.weixin.qq.com/s?__biz=MzIxMDY1ODQxMg==&amp;mid=2247486271&amp;idx=3&amp;sn=233f6c9b0f881d4a2fe4bb71c60ca2cc&amp;chksm=97607e3ca017f72a5393d46f0dd5985c07aa7aed8262c78cb0e8ae96c5f05727b0bde9a2a5b0&amp;mpshare=1&amp;scene=1&amp;srcid=0306YQQBdMN6j1B1IpuCgpCg%23rd">零知识证明（Zero-Knowledge Proof）原理详解</a>。</li>
</ul>


<p>此外，这里具体介绍一下是如何使用区块中的梅克尔树来做完整型证明的。每当产生一次交易，那么就与其他所有准备打包进区块的交易组成交易列表，通过Merkle Tree算法生成Merkle Root Hash，作为交易列表的摘要存到区块头中。比特币中使用的称之为二叉梅克尔树，而比如以太坊系统中使用的则是梅克尔-帕特里夏树。以二叉梅克尔树为例，流程可以概括为每相临的两条交易记录向上形成一个Hash值（如果仅有奇数个交易，则最后的交易会被复制一份以构成偶数个叶子节点），再与相邻的节点再往上形成Hash值，一直到树根形成所有交易记录的唯一Hash值，即Merkle根。如下图所示：</p>

<p><img src="//post_images/blockchain/merkle.jpg" alt="" /></p>

<p>如此，一方面可以在数据同步有问题的时候快速定位到出错的交易记录，另一方面在节点只是需要验证支付（不同于交易，如验证是否有人完成了对自己的一笔交易）的时候，仅下载链的区块头即可，实现“简化支付验证”（SPV），能够极大的节省传输数据量。SPV的流程如下：</p>

<ul>
<li>一个SPV节点会在节点间的通信链接上建立起布隆过滤器，限制只接受含有目标比特币地址的交易。</li>
<li>当节点探测到某交易符合布隆过滤器，它会以Merkle区块消息的形式向相邻节点索要包含区块头和一条连接目标交易与Merkle根的Merkle路径，如图中如果要验证交易1，那么则返回Hash2、Hash34即可。</li>
<li>SPV节点使用该路径找到与该交易相关的区块，验证对应区块中该交易的有无。</li>
</ul>


<h2>共识机制</h2>

<p>对于分布式系统来说，一个非常核心的问题就是如何让所有节点达成一致，也就是共识机制。在区块链出现之前，已经有了一些解决方案，这里称之为传统分布式一致性算法：</p>

<ul>
<li>Paxos算法：基于消息传递且具有高度容错特性，类似于议会投票的过程分为三种角色Proposer、Acceptor及Learner，主要就是Proposer发起投票，Acceptor进行投票的一个过程。具体可见：<a href="http://drmingdrmer.github.io/tech/distributed/2015/11/11/paxos-slide.html">可靠分布式系统基础Paxos的直观解释</a>。这里需要说明一点：Zookeeper使用的ZAB协议对Paxos做了一些改造，是一种类Paxos算法。</li>
<li>Raft算法：相比起Paxos算法，RAFT更加注重算法的落地性和可理解性，其核心思想是如果数个数据库初始状态一致，只要之后的进行的操作一致，就能保证之后的数据一致。分为Leader、Follower以及Candidate三种角色，基于Log进行数据同步。大体就是选举Leader，然后Leader生成Log，Follower进行同步的一个过程。详细可见:<a href="https://zhuanlan.zhihu.com/p/27207160">Raft协议详解</a>。</li>
</ul>


<p>对于不需要货币体系的联盟链或者私有链而言，所有的节点都是绝对信任的节点，考虑到对性能的要求，一般选择传统的一致性算法即可。但由于这些传统的方案仅仅是考虑到了节点会有网络故障或者宕机的问题，没有考虑到节点会作恶（篡改消息）的情况。因此，在比特币、以太坊这种区块链上并不适用。于是有了以下的分布式一致性算法：</p>

<ol>
<li><p>PBFT: 拜占庭容错，针对的是拜占庭将军问题而提出的一种一致性算法。分为三个阶段：预准备（pre-prepare）、准备(prepare)和确认(commit)。大体的流程就是节点之间互相转发消息，以其中相同的大多数作为最终答案。此算法的可靠度受制于结点的数量影响（N ≥ 3F + 1，总的结点数目必须大于有问题节点的数目的三倍），因此使用受限，在IBM的私有链Hyperledger中得到了使用。</p></li>
<li><p>PoW: Proof of Work,工作量证明。这个是比特币、莱特币等货币型区块链使用的共识机制。类似于现实中的毕业证、驾照等，来证明你具有某种能力。可以认为PoW彻底解决了分布式一致性的问题。其过程以比特币为例，如下：</p>

<ul>
<li>矿工在网络中拿到最新一个区块的头部信息，其中的Merkle根包含了交易记录的信息摘要；</li>
<li>将拿到的头部信息作为参数，将nonce值从零开始，去计算其双重SHA256值（<strong>SHA256(SHA256(区块头信息))</strong>）；</li>
<li>如果算出的答案不符合要求（前n位为0），则将nonce值增加一个单位，再算；</li>
<li>直到计算出符合难度目标的答案，就挖到一个区块（打包交易记录，其中优先记录手续费高的交易），即可将自己创建的区块广播出去，其他节点验证无误即保存到自己的区块链上。</li>
<li>如果同时有多个节点实现了工作量证明挖到了区块，那么整个网络集群采用少数服从多数原则，集群中大部分采用了哪个区块就选择此区块组成最新的账本，达到最终一致性。<strong>少数服从多数原则</strong>也是区块链防范攻击、保证数据安全性的一个核心的原则。</li>
<li>如果节点同步到了多个长度不同的区块链账本，那么选择其中最长的作为区块链账本，且在最长链之外挖矿，不会得到任何挖矿报酬。即“最长链规则”。</li>
</ul>


<p> 由最后两点可知，挖到一个区块时，并不能过早的高兴，一般说来后面再跟五个确认过的区块（加上自己的区块，叫做六次确认），才能确认自己创建的区块的确是有效的，记录的交易也才认为是有效的（此时交易接收方可以认为交易已经成功）。</p>

<p>这个思路牺牲了一部分一致性来保证区块链的健壮性，即使只有一个结点，区块链系统依旧可以运行。同时也保证了区块链的安全性，除非51%的结点被控制。但一方面如果想要控制这么多节点，不仅要具有很强的算力，还相当于重构一个区块链网络，另一方面区块链会给予实现工作量证明创建区块成功的节点以奖励（每一个区块的交易清单的第一条交易为“系统给区块创建者支付xx奖励”，被称做coinbase交易，此交易没有输入），在比特币中奖励包括一部分新造比特币（一开始一个区块奖励50个比特币，每隔21万个区块自动减半，4年时间比特币总量最终会稳定在2100万个），一部分是从区块所包含的交易中抽取的挖矿手续费。如此权衡收益和破坏的成本，基本可以杜绝这种51%攻击（博弈学的使用）等。</p>

<p>此外，还需要提到区块头中的难度目标这个值，此值与计算耗时是反比的，即此值越大，那么计算越容易。以比特币为例，为了控制每十分钟产生一个区块的速率，需要根据统计数据动态调整难度目标从而可以保证区块的生产速率。</p>

<p>比特币的PoW虽然很好的解决了分布式一致性问题，但其非常的耗费计算力，浪费电，并且这种纯粹靠CPU的计算会受到某些专用硬件的威胁，如ASIC芯片。而以太坊的POW算法叫做Ethash（最新版本为Dagger-Hashimoto），其特点是挖矿的效率基本与CPU无关，却和内存大小和内存带宽正相关，无法设计专用硬件来解答难题。</p></li>
<li><p>PoS: Proof of Stake，权益证明机制。是一种通过业务规则达成共识的方式。基本概念是产生区块的难度应该与用户在网络里所占的股权成比例。具体来说就是根据钱包里面货币的多少以及货币在钱包里存在的天数来合成一个单位（币天），然后根据币天的关系对计算机进行哈希计算降低（谁的钱包里的币天数越大谁拥有记账权的概率就越大）。如此，能够减少对计算资源的浪费，提高计算性能。但是它也是牺牲了一部分的共识，而且需要等待多个确认。与PoW类比于比力量大小，PoS就是比耐力大小。</p>

<p> PoS目前已经使用在以太坊中。</p></li>
<li><p>DPoS: Delegate Proof of Stake。是基于POS衍生出的更专业的解决方案，类似于董事会的投票机制，选举出n个记账节点，在节点中提案者提交的提案被这些记账节点投票决定谁是正确的。此机制性能比较高，但是其选出的delegate节点是能够作恶的。</p>

<p> EOS的底层框架石墨烯-<a href="https://github.com/cryptonomex/graphen">Graphene</a>使用DPoS做为共识机制。</p></li>
</ol>


<h2>上层应用</h2>

<ul>
<li>可编程合约/可编程资产：交易验证并不基于一个不变的模式，而是通过运行脚本语言来实现可编程资产以太坊。</li>
<li>激励机制：虚拟货币激励，比特币、以太币。</li>
<li>成员管理：为整个区块链网络提供身份管理、隐私、保密和可审计的服务。通过公钥基础设施和去中心化共识机制使得非许可的区块链变成许可制的区块链。多中心组网、私钥公钥生成等。</li>
</ul>


<p>这里需要提的是区块链中“地址”的含义。以比特币为例，地址本质上是一个私钥公钥对（ECDSA椭圆曲线算法），其存储和区块链和网络是没有关系的，可由用户的钱包软件生成并管理。而通常为了易于人们记忆，地址会在公钥的基础上做一个格式化转换。常用的格式包括：Base58Check（Base58+Checksum）、WIF压缩、130位和66位公钥。以最常用的Base58Check为例，可以概括为:<strong><em>Base58Check(RIPEMD160(SHA256(PubKey)))</em></strong>，其流程如下：</p>

<p><img src="//post_images/blockchain/bitcoin-address.png" alt="" /></p>

<p>而以太坊则是使用SECP256K1椭圆曲线算法生成公钥私钥对，再把公钥去掉04，剩下的进行KECCAK-256的哈希，得到长度64的16进制字串，丢掉前面24个，拿后40个，再加上&#8221;0x&#8221;，即为以太坊地址。</p>

<h2>性能问题</h2>

<p>目前区块链无法得到大规模应用的一个很大问题就是性能，比特币的每秒交易量只有3/秒，而以太坊也就30/秒。虽然EOS这个项目号称能达到几百万/S，然而分布式系统的本质让这个指标有点难以相信，而且这个数据也仅仅是建立在其几百个结点的基础上。</p>

<p>目前，提升区块链的方案主要有以下两种种：</p>

<ul>
<li>链外解决方案：即允许小型和频繁的交易发生在与主链并行并由主链背书的侧链实例上。只将比特币区块链用作大额交易的结算网络——小规模交易由区块链之外的支付中心处理（off-chain scaling，链外扩展）。</li>
<li>链上解决方案：直接修改区块链设计以支持高性能，如提高区块的容量、按照地址分片验证（以太坊）等。具体的可见：<a href="https://mp.weixin.qq.com/s?__biz=MzAwOTcyNzA0OQ==&amp;mid=2658972665&amp;idx=1&amp;sn=a3b8cc3538099530270910ae12267795">区块链性能提升：链上设计之道</a>。</li>
</ul>


<p>当然，如果使用私有链或者联盟链，其中的共识机制采取传统的分布式一致性算法或者高效的其他一致性算法也可以解决性能的问题。</p>

<h2>应用场景</h2>

<p>由于区块链本身的去中心化、不可篡改、安全等特性，需要第三方机构的应用场景都可以使用区块链技术。主流的应用场景如下：</p>

<ul>
<li>公正防伪</li>
<li>资产交易</li>
<li>信用体系</li>
<li>物品溯源</li>
<li>身份验证</li>
<li>文件存储</li>
<li>银行结算</li>
<li>版权控制</li>
</ul>


<h2>技术平台</h2>

<p>区块链的技术平台总体上可以分为公有链、联盟链和私有链，其大体的对比如下：</p>

<table>
<thead>
<tr>
<th>. </th>
<th> 公有链 </th>
<th> 联盟链 </th>
<th> 私有链</th>
</tr>
</thead>
<tbody>
<tr>
<td>参与者 </td>
<td> 任何人自由进出 </td>
<td> 联盟成员 </td>
<td> 个体或公司内部</td>
</tr>
<tr>
<td>共识机制 </td>
<td> PoW/PoW/DPoS  </td>
<td> 分布式一致性算法 </td>
<td> 分布式一致性算法</td>
</tr>
<tr>
<td>记账人 </td>
<td> 所有参与者 </td>
<td> 联盟成员协商确定 </td>
<td> 自定义</td>
</tr>
<tr>
<td>激励机制 </td>
<td> 需要 </td>
<td> 可选 </td>
<td> 不需要</td>
</tr>
<tr>
<td>中心化程度 </td>
<td> 去中心化 </td>
<td> 多中心化 </td>
<td> （多）中心化</td>
</tr>
<tr>
<td>特点 </td>
<td> 信用的自建立 </td>
<td> 效率和成本优化 </td>
<td> 透明和可追溯</td>
</tr>
<tr>
<td>承载能力（交易数/s） </td>
<td> 3-20万/s </td>
<td> 1000-1万/s </td>
<td> 1000-10万/s</td>
</tr>
<tr>
<td>典型场景 </td>
<td> 虚拟货币 </td>
<td> 支付、结算 </td>
<td> 审计、发行</td>
</tr>
<tr>
<td>代表项目 </td>
<td> 比特币、以太坊 </td>
<td> Hyperledger、腾讯TrustSQL </td>
<td></td>
</tr>
</tbody>
</table>


<h3>比特币</h3>

<p>比特币(使用C++开发)早于区块链走入人们的视野，并且很长时间内许多人都把比特币和区块链看做同一个东西。</p>

<p><img src="//post_images/blockchain/bitcoin.png" alt="" /></p>

<p>如图，是比特币的架构，可以看出比特币是基于区块链技术的副产品，是基于区块链的第一个应用，后来其他技术平台基本都是在比特币的基础上开发出来的。区块链可以类比为我们平时使用的JavaEE技术，比特币则是基于JavaEE开发的应用。无法基于比特币这个平台开发自己的应用。</p>

<h3>以太坊</h3>

<p><img src="//post_images/blockchain/ethereum.png" alt="" /></p>

<p>如上图所示，以太坊的架构由比特币演化而来，其诞生是为了解决比特币只适合加密数字货币场景，不具备图灵完备性，也缺乏保存实时状态的账户概念的问题，同时也是为了解决PoW机制带来的效率和资源浪费的问题。以太坊既是一个数字货币系统，也是一个智能合约的开发平台（类似AppStore这种应用开发平台，一个智能合约即一个应用）。可以把以太坊看做一个完全去中心化的电脑，使用此电脑需要用以太币支付费用（Gas）。</p>

<p>智能合约是以太坊最为核心的一个概念：提供了一个功能更强大的合约编程环境。一个合约类似一个合同，一旦写好即无法修改。每个节点都执行软件的一部分。类比于数据库中的触发器和存储过程，智能合约在区块链中是一个沙箱中的脚本（无法调用外部API），用于执行业务逻辑，也可以用于各种检查。开发智能合约使用的是Solidity语言。其是在Javascript语言基础上做的修改。合约代码会编译成字节码发布到以太坊网络，在EVM(Ethereum Virtual Machine)中执行。开发智能合约主要用到两个框架：</p>

<ul>
<li>Truffle Framework：Truffle提供了一整套部署测试的工具，可以方便和web3.js（以太坊提供的NodeJS SDK）结合使用。</li>
<li>dapphub: 提供了很多实用的合约，比如数学运算、权限验证等。</li>
</ul>


<p>其实比特币的交易也可以看做智能合约，只不过在比特币中就是⼀对锁定与解锁脚本（基于逆波兰表示法的基于堆栈的执行语言），受限只能实现转账交易。</p>

<p>使用以太坊发行数字代币（符合ERC20标准的智能合约）是非常简单的事情，官网提供了配套的代码和工具：<a href="https://www.ethereum.org/token">https://www.ethereum.org/token</a>，也可以参照这个指引：<a href="https://learnblockchain.cn/2018/01/12/create_token/index.html">一步步教你创建自己的数字货币（代币）进行ICO</a>。</p>

<p>这里还要说明一下ETC和ETH的区别。2016年6月区块链业界最大的众筹项目TheDAO遭到黑客攻击,导致300多万以太币资产被分离出TheDAO资产池。鉴于区块链的去中心、匿名的特征，资金根本无法追回，于是以太坊的发明人V神决定从块高度1760000开始把任何与The DAO和child DAO相关的交易认做无效交易，把以太坊做了一次分叉（区块链软件升级，但由于去中心化的问题并不能保证所有软件版本都升级上来），以此阻止攻击者在27天之后提走被盗的以太币。但此次分叉由于设计缺陷问题后来进行了回滚，最终是在区块高度1920000进行了一次分叉。而另外一些人由于不认同这种解决办法，而继续使用旧版本的以太坊软件，于是以太坊便发生了硬分叉（区块链软件升级，老版本不能够识别新的数据），原来的以太坊被叫做了ETC（以太经典）。至于这次攻击能够成功的原因主要是因为智能合约的逻辑有问题，具体的原因分析可见：<a href="http://ethfans.org/posts/114">从技术角度剖析针对THE DAO的攻击手法
</a>。</p>

<h3>EOS</h3>

<p>Enterprise Operation System，是由和V神齐名的BM大神发起的区块链项目，从名字上看其目的就是构建一个商业操作系统。由于其是一个ICO项目，且被某比特币大V进行了投资，因此受到的议论比较多。EOS的设计针对的是区块链性能太低满足不了很多应用场景以及在以太坊上进行操作需要支付费用等问题。</p>

<p>EOS号称自己能够达到每秒百万级的处理量，且具有高度自治，并能够为开发dApp的开发者提供底层模块，降低开发门槛。EOS也不收取任何费用，并能够通过并行链和DPOS的方式解决延迟和数据吞吐量的难题。</p>

<p>在EOS上编写智能合约支持C/C++/WebAssembly以及RESTFul接口(比较简单)。</p>

<h3>NEO</h3>

<p>小蚁区块链，开源，使用dBFT（delegated BFT，授权拜占庭容错机制）做为其共识机制。市值国内第一，全球第七，支持C#、Java、GO、Python、js等开发区块链应用。其目的是利用区块链技术和数字身份进行资产数字化，利用智能合约对数字资产进行自动化管理，实现“智能经济”。</p>

<p>目前，NEO提供了配套设施搭建私有链。</p>

<h3>联盟链和私有链</h3>

<p>市面上有一些联盟链和私有链技术平台，可以基于此做一些区块链应用开发。如下：</p>

<ul>
<li>腾讯TrustSQL: 腾讯主导的可信数据库区块链平台，<a href="https://trustsql.qq.com/">https://trustsql.qq.com/</a>。</li>
<li>百度区块链开放平台：百度主导的区块链平台，<a href="https://chain.baidu.com/">https://chain.baidu.com/</a>。</li>
<li>IBM HyperLedger，也被称作超级账本，又叫fabric，是一个面向商业的区块链系统开发框架（开发用的半成品基础设施）。</li>
</ul>


<h2>ICO</h2>

<p>提到区块链，ICO是不得不提的一个概念，类比于IPO，ICO是首次发币代售，提供了一种平等、低门槛的方式让普通民众参与到经济活动中，目前能够进行ICO的平台(能够方便发代币)主要是以太坊和比特股(Bitshares)。这种东西本意是好的，可以降低公司融资的成本，好的项目不会再看风投脸色，好的Idea也不会再胎死腹中，用户ICO获得的Token还可以带来实际的经济效益。但是由于缺乏IPO一样的管制，已经彻底沦为了收割智商的工具。</p>

<p>如上文所说，其实基于以太坊发行虚拟货币是非常简单的，如果你文采够好随便写个白皮书，洋洋洒洒描绘一个去中心化的蓝图，再找几个所谓业界大神站个台，好了，剩下的就等着数钱吧。当然，不排除有真心想做出一个项目的，但绝大多数都是些空气项目，发起人不过是发了个空气币，然后卷钱跑路。</p>

<p>说到ICO，虚拟货币交易所也是关键的角色，在这里可以流通法币和各种虚拟货币。有点令人不解的是，去中心化的区块链虚拟货币竟然需要一个中心化的“交易所”。黑客们攻击不了区块链，攻击一个中心化的交易所还是有许多路可寻的。最近频频发生的虚拟货币交易所被攻击的事情也算是对这种模式的一种讽刺。</p>

<h2>开发参考</h2>

<p>如果想实现自己的区块链平台或者了解区块链的实现，可以通过比特币、以太坊的代码学习，也可以参考以下资料:</p>

<ul>
<li><a href="https://www.ibm.com/developerworks/library/j-chaincode-for-java-developers/index.html">面向Java开发人员的区块链代码</a></li>
<li><a href="http://www.spring4all.com/article/811">用Java创建你的第一个区块链-part1</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653549361&amp;idx=1&amp;sn=019f54713891cf33ef3bef3b24773a96&amp;chksm=813a62a9b64debbfdd24a8507bb974048a4456e5b0a2d5f685fb3bdf40366a25764c5df8afec&amp;mpshare=1&amp;scene=1&amp;srcid=0226W0WdpzjJ9Qo6F3FJstO6%23rd">只用200行Go代码写一个自己的区块链！</a></li>
</ul>


<h2>小结</h2>

<p>区块链技术的出现以一种全新的思路解决了分布式一致性的问题，技术+博弈学+金融学的使用巧妙的构建了一个安全健壮的系统。这些思路给开发者在平时的学习工作中会有很多的思考和提示。而随着比特币价格的水涨船高和各种资本的追捧，区块链目前是被过度炒作的，大部分应用都是联盟量和私有链，已经违背了区块链设计的初衷。虽然的确是有应用场景，但笔者认为这和共享分布式数据库没有本质上的区别。此外，虽然区块链上的数据是无法篡改的，但是如果数据上链有人工参与的环节，那么这一步如何防止篡改呢？这也是我开篇观点产生的原因。</p>

<p>至于能用区块链做什么？在笔者看来，去研究区块链技术平台只有大公司、政府能做并推广起来，不过最后也只不过是“联盟链”、“私有链”。而对于创业公司或者个人来说，基于公有链、联盟链做之上的应用则更为合适，比如在以太坊/EOS上做一个养宠物的游戏^_^。</p>

<h2>参考资料</h2>

<ul>
<li><a href="http://8btc.com/topic-mastering-bitcoin.html">精通比特币</a></li>
<li><a href="http://www.8btc.com/wiki/bitcoin-a-peer-to-peer-electronic-cash-system">比特币白皮书:一种点对点的电子现金系统</a></li>
<li><a href="http://dataconomy.com/2015/10/wtf-is-the-blockchain-a-guide-for-total-beginners/">WTF IS THE BLOCKCHAIN? A GUIDE FOR TOTAL BEGINNERS</a></li>
<li><a href="http://blog.csdn.net/jeffrey__zhou/article/details/56672948">区块链共识机制浅谈</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3MzEzMDI1OQ==&amp;mid=2651818777&amp;idx=1&amp;sn=8cf64236f13e1196b28a2603744d4c0f&amp;chksm=f0dcdd65c7ab5473a239b47939d7586229122788c49fbac295c77627b4693a06b1ce8d73afdc&amp;mpshare=1&amp;scene=1&amp;srcid=0829NWygcU8u98YzRZ8TmQlN%23rd">白话区块链技术栈与应用</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIzNzU4MTg5NQ==&amp;mid=2247484492&amp;idx=1&amp;sn=b37844e8ab32b5ce516ee92149f243d6&amp;chksm=e8c72764dfb0ae727b2a50da75ef1ded417ad3c303c47f61c666f8dd39e631f114ab350f2544&amp;mpshare=1&amp;scene=1&amp;srcid=0217E8nz8lHzcB3sBvSBAics%23rd">比特币的潜在激励</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247487013&amp;idx=1&amp;sn=4675dd398a3458af9ba519557675e406&amp;chksm=e929332ade5eba3c142a36f89677d71bf1e1395967ace0b9e4ff3d18c6cffd604420709967fe&amp;mpshare=1&amp;scene=1&amp;srcid=03126HIJoomFmy2JpebnHa5m%23rd">如何用架构师思维解读区块链技术？</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何快速尝出毒酒？- 用bit解决问题]]></title>
    <link href="http://www.rowkey.me/blog/2018/01/04/king-rec-pois-wine/"/>
    <updated>2018-01-04T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/01/04/king-rec-pois-wine</id>
    <content type="html"><![CDATA[<h2>问题</h2>

<p>国王有一百桶酒，比自己的生命还重要。结果有一天其中一桶被投了慢性毒药，喝了以后半个小时以后就会死掉。国王大怒，命令玩忽职守的侍卫去试毒。酒不能被混合，一个侍卫可以喝多桶酒，一桶酒也可以由多个侍卫喝，怎么样才能用最少的侍卫、在最短的时间知道哪桶是毒酒。侍卫可以理解为线程，即怎么样用最少的线程用最快的速度完成这个工作。</p>

<!--more-->


<h2>方案</h2>

<p>此问题是我在面试时经常用的一道题目，主要考察的是候选人能不能以计算机的思维考虑问题。</p>

<p>最简单的方案肯定是找100个人，每个人试一桶酒，那么用时30分钟，就可以判断出哪一桶就有毒。</p>

<p>再进一步的，可以使用分段法，把酒分成n份，先找n个侍卫试酒，可以定位出哪一段的酒有毒，再接着分段试酒。但这种方案，分段数目越少，试出毒酒的平均耗时就越长。</p>

<p>如果用计算机的思维来分析这个问题，那么首先考虑如何存储这100桶酒。100桶酒可以用二进制7个bit来表示（2<sup>7</sup>>100）。对应那一桶毒酒，其二进制表示中为1的位置如果能够可以定位出来，就可以定位出此桶毒酒。可以找7个侍卫编号1-7。对于每一桶酒的二进制表示（不足七位前面用0表示），从第一位到第七位，如果是1，则对应编号的侍卫喝此桶酒。这样，每个侍卫喝掉对应的酒。30分钟后，侍卫按照编号1-7，死掉的置为1，活着的置为0，如此，侍卫的一个序列如0000111就表示第七桶酒为毒酒。</p>

<h2>总结</h2>

<p>上述最后一种方案提现了在计算机中使用bit来解决问题的思路。当需要节省存储的时候，使用bit来做经常会有出其不易的效果。就比如最近很火的电影《天才枪手》中，主角们记忆选择题的答案A、B、C、D，完全可以使用位编码来表示四种答案:00-A 01-B 10-C 11-D，四个bit转换为一个十六进制数字，如此就可以节省一半的存储，记忆起来也会简单很多。此外，我们处理大数据去重/计数使用的Bitmap、BloomFilter，也都是一种使用bit节省存储的思路。</p>
]]></content>
  </entry>
  
</feed>
