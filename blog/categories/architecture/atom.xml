<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: architecture | 后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/blog/categories/architecture/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2018-06-04T16:29:19+08:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[微服务的十个反模式和陷阱]]></title>
    <link href="http://www.rowkey.me/blog/2018/06/02/microservice-pitfall/"/>
    <updated>2018-06-02T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/06/02/microservice-pitfall</id>
    <content type="html"><![CDATA[<p>O’Reilly的电子书《Microservices AntiPatterns and Pitfalls》讲述了在微服务设计实现时十种最常见的反模式和陷阱。本文基于此书，将这十个点列出。书籍地址：<a href="https://www.oreilly.com/programming/free/microservices-antipatterns-and-pitfalls.csp">https://www.oreilly.com/programming/free/microservices-antipatterns-and-pitfalls.csp</a>，更全的反模式和陷阱可见作者的视频：<a href="http://oreil.ly/29GVuDG">http://oreil.ly/29GVuDG</a></p>

<!--more-->


<h2>数据驱动迁移反模式-Data-Driven Migration</h2>

<p><img src="//post_images/ms-anti/data-driven-1.png" alt="" /></p>

<p>如上图所示，此种反模式的问题在于微服务的粒度没有最终确定之前就做了数据迁移，如此当不断的调整服务粒度时，那么数据库就免不了频繁迁移，带来极大的成本。更好的方式如下图所示：</p>

<p><img src="//post_images/ms-anti/data-driven-2.png" alt="" /></p>

<p>即先分离功能，数据库先保持之前的单体，等到服务粒度最终确认之后，再分离数据库。</p>

<h2>超时反模式-The Timeout</h2>

<p>微服务架构是由一些列分离的服务组成的，这些服务之间通过一些远程协议进行互相之间的通信。这也牵扯到了服务的可用性和响应性。如下图所示：</p>

<p><img src="//post_images/ms-anti/availability-res.png" alt="" /></p>

<ul>
<li>可用性：服务消费方能够连接服务方，并可以向其发送请求。</li>
<li>响应性：服务方能够在消费方期望时间内给予请求响应。</li>
</ul>


<p>为了防止服务的不可用和无法响应，通常的做法就是设置一个调用超时。此种做法表面上看是没问题的，但是试想一下如下情景：发起一个购买100个商品的请求，请求成功返回一个确认号。如果当请求超时但是请求在服务端已经成功执行了，此时这个交易实际是完成的，但是消费方没有拿到确认号，如果重试请求，那么服务方需要一个复杂的机制判断这是否一次重复提交。</p>

<p>一种解决此问题的方案是设置一个较长的超时时间，如一个服务的通常响应耗时需要2s，最大耗时需要5s，那么超时时间可以设置为10s。但这样的问题就是如果服务不可用，所有消费方都得等待10s，这个是非常损耗性能的。</p>

<p>解决超时反模式的方案就是使用“断路器模式”。就类似于房屋中的电源断路器，当断路器关闭，电流可以通过，当断路器打开，那么电流中断一直到断路器关闭。断路器模式就是说当检测到服务方无法响应时就打开，后续的请求都会被拒绝掉。一旦服务方可响应了，那么断路器关闭，请求恢复。其工作模式如下图所示：</p>

<p><img src="//post_images/ms-anti/circuit-breaker.png" alt="" /></p>

<p>断路器会持续地监测远程服务，确保其是可响应的。只要服务可响应，那么断路器会一直关闭，允许请求通过。如果服务突然不可响应，那么断路器打开，拒绝后续的请求。而后续如果断路器又检测到服务恢复了，那么断路器会自动关闭，请求也就恢复了。此种方案与超时时间相比，最大的优势就是一旦服务不可响应，那么断路器模式可以让请求立刻返回而不是需要等待一定的时间。</p>

<p>Hystrix的Netflix是此种断路器模式的一种开源实现。此外，Akka中也包含了一个断路器实现：Akka CircuitBreaker类。</p>

<p>关于“断路器模式”的详细信息可见：<a href="https://martinfowler.com/bliki/CircuitBreaker.html">https://martinfowler.com/bliki/CircuitBreaker.html</a>。</p>

<h2>共享反模式-I Was Taught to Share</h2>

<p>微服务被普遍认为就是一种不共享任何东西的架构。但实际上只能是尽可能地少共享，毕竟在某些层面代码还是会被多个服务共享的。例如，与单独部署一套安全服务（验证和认证）其他所有服务都通过远程访问此服务相比，把安全相关的功能封装成jar包（security.jar），然后其他服务都集成此jar包，如此就能够避免每次都要发起对安全服务的访问，从而提高性能和可靠性。但后面的方案带来的问题就是依赖噩梦：每一个服务都依赖多个自定义的jar包。如此不仅打破了服务之间的边界上下文，同时也引入了诸如总体可靠性、变更控制、易测试性、部署等问题。</p>

<p>在一个使用面向对象编程语言的单体应用中，使用abstract类和接口实现代码复用和共享是一个良好的实践。但当从单体切换到微服务架构时，对于很多自定义的共享类和工具类（日期、字符串、计算）的处理要考虑到微服务间共享的东西越少越有利于保持服务间的边界上下文，从而更利于快速测试和部署。以下是几种推荐的方式，也是解决“共享反模式”的方案：</p>

<ol>
<li><p>共享项目</p>

<p> <img src="//post_images/ms-anti/share-project.png" alt="" /></p>

<p> 将共享的代码作为一个项目在编译期与各个服务集成。此种方式便于变更和开发软件，但是最大的问题在于很难发觉哪一个共享模块被修改以及修改的原因，也无法确定自己的服务是否需要这些变更。尤其是在服务发布前期发现某一个共享模块发生了变动的话需要再一次的测试才能走后续流程。</p></li>
<li><p>共享库</p>

<p> <img src="//post_images/ms-anti/share-library.png" alt="" /></p>

<p> 此种方式即将共享的代码作为类库集成到服务中。如此每次共享的库有改动，服务都需要重新打包、测试、重启。但相比起第一种，其由版本标记，能够更好地控制服务的部署和开发，服务开发者可以自己控制合适将共享库的改动集成进来。</p>

<p> 更进一步的，如果采用此种方案，一定要避免把所有共享的代码都打包进一个jar包中如common.jar。否则会很难确定何时要把库的变动集成到服务中。更好的做法是将共享代码分成几个单独上下文的库，如：security.jar、dateutils.jar、persistence.jar等，如此会比较容易的确定何时去集成共享库的变动。</p></li>
<li><p>冗余</p>

<p> <img src="//post_images/ms-anti/replica.png" alt="" /></p>

<p> 此种方案违反DRY原则，在每一服务中都冗余一份共享代码，如此能够避免依赖共享也能够保持边界上下文。但是一旦共享的代码有变动，那么所有服务都需要改动。因此，此种方案主要用于共享模块非常稳定，极小可能变动的情况。</p></li>
<li><p>服务合并</p>

<p> <img src="//post_images/ms-anti/consolidation.png" alt="" /></p>

<p> 当多个服务共性的代码变动比较频繁时可以采用此种方案合并成一个服务，如此就避免了多了服务频繁的测试和部署，也避免了依赖共享库。</p></li>
</ol>


<h2>可达性报告反模式-Reach-in Reporting</h2>

<p>微服务中各个服务以及其相应的数据都是包含在一个单独的边界上下文中的，也就是说数据是隔离到多个数据库中的。因此，这也会使得收集微服务的各种数据生成报告变得相对困难。一般来说有四种方案解决这个问题。其中，前三种是这里所说的“”都是从各个微服务中拉取数据，因此此反模式被称作“reach-in reporting”。</p>

<ol>
<li><p>数据库拉取模式</p>

<p> <img src="//post_images/ms-anti/database-pull.png" alt="" /></p>

<p> 报告服务直接总各个服务的数据库中拉取数据从而生成各种报告。此种方式简单迅速，但是会让报告服务和业务服务相互依赖，是一种数据库共享集成风格（通过共享的数据库将多个应用耦合在一起）。如此一旦数据库有改动，所有相关服务都要改动，也就打破了微服务中极为重要的边界上下文。</p></li>
<li><p>HTTP拉取模式</p>

<p> <img src="//post_images/ms-anti/http-pull.png" alt="" /></p>

<p> 与数据库拉取模式相比，此种方式不再是直接去访问服务的数据库，而是通过rest HTTP接口去请求服务的数据。此种方式能够保持服务的边界上下文，但是性能比较慢，而且HTTP请求无法很好的承载大数据。</p></li>
<li><p>批量拉取模式</p>

<p> <img src="//post_images/ms-anti/batch-pull.png" alt="" /></p>

<p> 此种方式会有一个单独的报告数据库/数据仓库来存储各个服务的聚合数据。会通过一个批量任务（离线或者基于增量实时）将服务更新的数据导入到报告数据库/数据仓库中。与数据库拉取模式一样，此种方式这也是一种数据库共享集成风格，会打破服务的边界上下文。</p></li>
<li><p>异步事件推送模式</p>

<p> <img src="//post_images/ms-anti/event.png" alt="" /></p>

<p> 此种方式即解决“Reach-in reporting&#8221;反模式的方案。每个服务都把自己的发生的事件异步推送给一个数据捕获服务中即可，后续数据捕获服务会将数据解析存储到报告数据库中。此种方式实现起来较复杂，需要在服务和数据捕获服务之间制定一种协议用于异步传输事件数据。但其能够保持服务的边界上下文，同时也能保证数据的时效性。</p></li>
</ol>


<h2>沙粒陷阱-Grains of Sand</h2>

<p>微服务实现中最有挑战的问题在于如何拆分service，如何控制服务的粒度，而正确的服务粒度则决定了微服务是否能够成功实现。服务粒度也能够影响到性能、健壮性、可靠性、易测试性、部署等。</p>

<p>“沙粒陷阱”即把服务拆分的太细。其中的一个原因就是很多时候开发者会把一个class与一个服务等同。合理的，应该是一个服务组件(Service component)对应一个服务。一个服务组件具有清晰、简洁的角色、职责，具有一组定义好的操作。其一般通过多个模块(Java Class)实现。如果组件和模块是一对一的关系，那么不仅仅会造成服务粒度过细同时也是一种不好的编程实践：服务的实现都是通过一个Class，那么此Class会非常大并且承担太多的责任，不利于测试和维护。</p>

<p>更进一步的，服务的粒度并不应该受其中实现类的数目影响：有些服务可能只需要一个类就可以实现，而有些服务会需要多个类来实现。</p>

<p>为了避免“沙粒陷阱”，可以通过以下三种测试来判断服务粒度是否合理：</p>

<ol>
<li><p>分析服务范围和功能</p>

<p> 主要是要明确服务用来干什么？有哪些操作？一般通过使用文档或者语言来描述服务的范围和功能就能够看出来服务是否做的太多。如果在描述中使用了“和”（“and”）或者“此外”（“in addition”）之类的词，很有可能就是此服务做的太多。</p>

<p> 服务的高内聚是一种良好的实践，其明确一个服务提供的操作之间须要是有关联的。如对于一个顾客服务，有以下操作：</p>

<ul>
<li>添加顾客</li>
<li>更新顾客信息</li>
<li>获取顾客信息</li>
<li>通知顾客</li>
<li>记录顾客评论</li>
<li>获取顾客评论</li>
</ul>


<p> 其中，对于前三个操作都是对顾客的CRUD操作，是相关联的。而后三者则无关。为了实现服务的高内聚，合理的应该是把此服务拆分成三个服务：顾客维护、顾客通知、顾客评论。</p>

<p> 如此，一开始以粗粒度的服务开始，然后逐渐拆分成细粒度的服务能够有利于对微服务的拆分。</p></li>
<li><p>分析数据库事务</p>

<p> 传统的关系型数据库都提供了ACID事务特性用于把多个更新操作打包成一个整体提交，要么都成功，要么都失败。而在微服务中，由于服务都是一个个分离的应用，是很难实现ACID的，一般都是实现BASE事务（basic avalability、soft state、eventual consistence）即可。但是无法避免的，仍然会有一些场景是需要ACID的。因此，当你不断的需要在BASE和ACID事务做判断、取舍的时候，很有可能就是服务粒度过细。</p>

<p> 如果业务常见无法接受最终一致性，那么最好就是讲服务粒度粗化一些，把多个更新操作放到一个服务中。</p></li>
<li><p>分析服务编排</p>

<p> 这里主要说的是服务之间的互相通信。由于对服务的调用都是一次远程调用，因此服务编排会非常大的影响微应用总体的性能。此外，它也会影响系统整体的健壮性和可靠性，越多的远程调用，那么越高的几率会有失败或者超时的请求出现。</p>

<p> 如果发现完成一次业务逻辑需要调用太多的远程服务，就说明服务的粒度可能太细了。这时候就需要将服务粗化。而合并细粒度服务还能够提高性能，提升总体的健壮性和可靠性，并且减少了了多个服务间的依赖，更利于测试、部署。</p>

<p> 此外，使用响应式编程技术异步并行调用远程服务也是一种提升性能和可靠性的方案。</p></li>
</ol>


<h2>无因的开发者陷阱-Developer Without a Cause</h2>

<p>此陷阱主要讲的是开发者或者架构师在做设计时很多时候是拍脑袋在做，没有任何合理的原因或者原因是错误的，也不会做取舍。而想要解决此问题，不仅仅是架构师，开发者也需要同时了解技术带来的好处以及折中。</p>

<p>了解业务驱动是避免此陷阱的关键一步。每一个开发者和架构师都应该清楚的了解下面这些问题的答案：</p>

<ul>
<li>问什么要使用微服务？</li>
<li>最重要的业务驱动是什么？</li>
<li>架构中的哪一点是最为重要的？</li>
</ul>


<p>假如易部署性、性能、健壮性、可扩展性是系统最看重的特性，那么对于不同的业务侧重点，微服务的粒度需求也是不同的。细粒度的服务能够达到更好的易测试性和易部署性，而粗粒度的服务则能够有更好的性能、健壮性以及可靠性。</p>

<h2>追随流行陷阱-Jump on the Bandwagon</h2>

<p>微服务是目前非常流行的架构理念，越来越多的公司也都在紧跟这个潮流纷纷转型微服务架构，而不管到底自己是否真的需要。为了避免此陷阱，需要首先了解微服务的优点和缺点。</p>

<p>优点：</p>

<ul>
<li>易部署：容易部署是微服务的一个很大的优点。毕竟相比起一个庞大的单体应用，一个小并且职责单一的微服务的部署非常简单并且带来的风险小很多。而持续部署技术则进一步放大了这个有点。</li>
<li>易测试：一个职责单一、共享依赖少是的测试一个微服务也是很容易的。而基于微服务做回顾测试与单体大应用相比也是很容易的。</li>
<li>控制变更：每个服务的范围和边界上下文使得很容易控制服务的功能变动。</li>
<li>模块化：微服务就是一个高度模块化的架构风格。这种风格也是一种敏捷方式的表达，能够很快的响应变化。一个系统模块化程度越高，那就越容易测试、部署和发布变更。一个服务粒度划分隔离的微服务系统是所有架构中模块化程度最高的架构形式。</li>
<li>可扩展性：由于每一个服务都是一个职责单一的细粒度服务，因此此种架构风格是所有架构分隔中可扩展性最高的。其非常容易扩展某一个或者某几个功能从而满足整体系统的需求。而得益于服务的容器化特性以及各种运维监控工具，服务能够自动化进行启动和关闭。</li>
</ul>


<p>缺点：</p>

<ul>
<li>组织变动：微服务需要组织在很多层面进行变动。研发团队需要包含UI、后端开发、规则处理、数据库处理建模等职位，从而使得一个小的团队能够具有实现微服务的所有技术。同时，传统的单体、分层应用架构的软件发布流程也需要更新为自动化、高效的部署流水线。</li>
<li>性能：由于服务都是隔离的，因此发起对服务的远程调用肯定是会影响性能的。服务编排、运行环境都是影响性能的很大因素。了解远程调用的延迟、需要与多少服务通信都了解性能需要掌握的信息。</li>
<li>可靠性：和性能一样。服务的远程调用阅读，那么失败的几率就越高，总体的可靠性就会越低。</li>
<li>DevOps：随着微服务架构而来的会是成千上百的服务。手动管理这么多的服务是很不现实的。这就对于自动化运维部署、协作提出了很高的挑战。需要使用非常多的操作相关的工具和实践，是一个非常复杂的工作。目前差不多有12种操作工具和框架使用在微服务架构中，其中每一种又包含了很多具体的工具和产品供选择。例如，有监控工具、服务注册、发现工具、部署工具等等。对于这些工具和框架的选择一般都会需要将近数月的研究、测试、权衡分析才能选出最适合的技术选型。</li>
</ul>


<p>了解了微服务的优缺点后，下一步则需要根据实际的业务来分析微服务是不是解决这些问题的最佳方案。可以采取以下问题：</p>

<ul>
<li>业务和技术的目标是什么？</li>
<li>使用微服务是为了完成什么？</li>
<li>目前和可预知的痛点是什么？</li>
<li>应用的最关键的技术特性是什么？（性能、易部署性、易测试性、可扩展性）</li>
</ul>


<p>回答这些问题再结合微服务的优缺点能够让你明确现在是否是使用微服务的适当时机。</p>

<p>除了微服务以外，还有其他7种比较普遍使用的架构供选择：</p>

<ul>
<li>基于服务的架构（Service-Baased）</li>
<li>面向服务的架构（Service-Oriened）</li>
<li>分层架构（Layered）</li>
<li>微内核架构（Microkernel）</li>
<li>基于空间的架构（Space-Based）</li>
<li>事件驱动架构（Event-Driven）</li>
<li>流水线架构（Pipeline）</li>
</ul>


<h2>静态合约陷阱-Static Contract</h2>

<p>微服务的消费方和服务提供方之间会有一个合约/协议用来规定输出输出数据的格式、操作名称等等。一般情况下这个合约是不变的。但是如果你没有使用版本号来管理服务接口，那么很容进入“静态合约”陷阱。</p>

<p>给合约打上版本标记不仅仅能够避免巨大的变动（服务提供方修改合约使得所有消费方也都得修改），还能够提供向后兼容性。这里有两种技术可以实现合约的版本号：</p>

<ul>
<li><p>在头部信息附加版本号</p>

<p>  <img src="//post_images/ms-anti/header-version.png" alt="" /></p>

<p>  如图，此种方式即在远程访问协议的头部添加版本信息。而如果远程协议使用的是REST，那么还可以使用vendor mime type（vnd）来指定合约的版本号。如下：</p>

<pre><code class="``">  POST /trade/buy
  Accept: application/vnd.svc.trade.v2+json
</code></pre>

<p>  服务接受到请求，能够通过正则等手段简单解析出其中的合约版本号再根据版本号做相应的处理。</p>

<p>  而如果使用消息队列，那么可以将版本号放置在属性部分(Property section)。JMS的一个例子如下：</p>

<pre><code class="``">  String msg = createJSON("acct","12345","sedol","2046251","shares","1000");
  jsmContext.createProducer()
      .setProperty("version",2)
      .send(queue,msg);
</code></pre></li>
<li><p>在合约本身中附加版本号</p>

<p>  <img src="//post_images/ms-anti/schema-version.png" alt="" /></p>

<p>  此种方式版本号独立于远程访问协议，与头部信息版本号相比，这也是其最大的优点。但与此同时，其缺点比较多。首先要从请求信息主体中解析版本号，会出现很多解析的问题。其次，合约的模式可能会非常复杂，使得很难做数据转换。最后，服务要引入对模式的验证逻辑。</p></li>
</ul>


<h2>我们到了吗陷阱-Are We There Yet</h2>

<p>微服务架构中，各个服务都是独立的个体，也就意味着所有客户端或者API层和服务之间的通信都是一次远程调用。如果对这些远程调用的耗时没有什么概念，那么就陷入了“Are We There Yet”陷阱。合理的做法需要去测试注入长尾延迟（95%、99%、99.%之外的请求延迟）、平均延迟等指标。很多时候即使是有很好的平均延迟，但是较差的长尾延迟会造成很大的破坏。</p>

<p>在生产环境或者准生产环境有助于去了解应用的真实性能。例如，一个业务请求需要调用四个服务，假设一个服务调用的延迟是100毫秒，那么加上业务请求本身的延迟，完成此次业务请求共需要500毫秒的延迟。</p>

<p>了解目前所用协议的平均延迟是一方面，另一方面则需要对比其他远程协议的延迟，从而在合适的地方使用合适的协议。如：JMS、AMQP、MSMQ。</p>

<p><img src="//post_images/ms-anti/comparing-protocol.png" alt="" /></p>

<p>如图，AMQP协议的性能是最好的。那么结合业务场景，就可以选择REST作为客户端与服务间的通信协议，AMQP做为服务之间的通信协议以提高应用的性能。</p>

<p>当然，性能并非在选择远程协议时唯一考虑的因素。下一节中也会考虑利用消息队列的一些额外功能。</p>

<h2>REST使用陷阱-Give It a Rest</h2>

<p>REST现在是微服务中用的最多的通信协议，包括服务之间的通信。而流行的开发框架如DropWizard、Spring Boot都提供了REST支持。但是如果只选择REST这一种协议，不去考虑其他诸如消息队列的优势，那么久陷入了“REST使用”陷阱。毕竟异步通信、广播、合并请求到一个事务这些需求，REST是很难满足的。</p>

<p>消息队列标准目前包括平台特定和平台无关两种。前者包括Java平台中的JMS和C#平台的MSMQ，后者则是AMQP。对于平台特定的消息标准JMS，其规范了API，因此切换broker实现（ActiveMQ、HornetQ）时无需修改API，但由于底层通信协议是不同的，集成的客户端或者服务端jar包需要随着修改。对于平台无关的消息标准，其规范了协议实现标准，并没有规范API。使得不同平台之间都可以互相通信，而不管实际产品是什么。如一个使用了RabbitMQ的客户端可以很容易地与一个StormMQ通信（假设使用的协议相同）。也就是其独立于平台的特性使得RabbitMQ成为微服务架构中最流行的消息队列。</p>

<ol>
<li><p>异步请求</p>

<p> 异步通信是消息队列适用的场景之一。服务消费者发起请求后无需等待服务方响应能够提高总体的性能，同时调用方无需担心调用超时或者使用断路器，从而提高了系统的可靠性。</p></li>
<li><p>广播</p>

<p> 将消息广播给多个service是消息队列的又一个适用场景。一个消息生产者向多个消息接受者发送消息，无需知道谁在接受消息以及如何处理它。</p></li>
<li><p>事务请求</p>

<p> 消息系统提供了对事务消息的支持：如果多个消息被发送到了在一个交易上下文的多个队列或者主题中时，那么直到消息发送者commit，服务才会真正的接受到相应的所有消息（在commit之前会一直保存在队列中）。</p>

<p> 因此对于服务消费者需要合并多个远程请求到一个事务中的场景可以选择事务消息。</p></li>
</ol>


<p><img src="http://www.rowkey.me/post_images/book-all.png" width="400"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[架构简明指南]]></title>
    <link href="http://www.rowkey.me/blog/2018/04/25/arch-usage/"/>
    <updated>2018-04-25T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/04/25/arch-usage</id>
    <content type="html"><![CDATA[<p>之前的<a href="http://www.rowkey.me/blog/2017/08/24/arch/">《谈谈架构》</a>讲述了架构的概念、原则等等，这里择出其中的设计原则部分供大家随手参考。</p>

<p>《Clean Architecture》一书中对于软件架构目的的解释：</p>

<blockquote><p>The goal of software architecture is to miminize the human resources required to build and maintain the required system.</p></blockquote>

<p>即：软件架构的目的就是将构建和维护系统需要的人力成本降到最低。</p>

<p>因此，可以得出架构设计的关键思维就是判断和取舍（程序设计的关键思维是逻辑和实现），即如何选择技术、组合技术使得需要的人力资源最少。</p>

<!--more-->


<h2>架构原则</h2>

<p><img src="//images/blog_images/arch-spec.png" alt="" /></p>

<ul>
<li><strong>避免过度设计</strong>：最简单的方案最容易实现和维护，也可以避免浪费资源。但方案中需要包括扩展。</li>
<li><strong>冗余设计</strong>：对服务、数据库的做结点冗余，保证服务的高可用。通过数据库主从模式、应用集群来实现。</li>
<li><strong>多活数据中心</strong>：为了容灾，从根本上保障应用的高可用性。需要构建多活的数据中心，以防止一个数据中心由于不可控因素出现故障后，引起整个系统的不可用。</li>
<li><strong>无状态设计</strong>：API、接口等的设计不能有前后依赖关系，一个资源不受其他资源改动的影响。无状态的系统才能更好地进行扩展。如果非得有状态，则要么客户端管理状态，要么服务端用分布式缓存管理状态。</li>
<li><strong>可回滚</strong>：对于任何业务尤其是关键业务，都具有恢复机制。可以使用基于日志的WAL、基于事件的Event sourcing等来实现可回滚。</li>
<li><strong>可禁用/自我保护</strong>：具有限流机制，当上游的流量超过自身的负载能力时，能够拒绝溢出的请求。可以通过手动开关或者自动开关（监测异常流量行为），在应用前端挡住流量。</li>
<li><strong>问题可追踪</strong>：当系统出现问题时，能够定位请求的轨迹、每一步的请求信息等。分布式链路追踪系统即解决的此方面的问题。</li>
<li><strong>可监控</strong>：可监控是保障系统能够稳定运行的关键。包括对业务逻辑的监控、应用进程的监控以及应用依赖的CPU、硬盘等系统资源的监控。每一个系统都需要做好这几个层面的监控。</li>
<li><strong>故障隔离</strong>：将系统依赖的资源(线程、CPU)和服务隔离开来能够使得某个服务的故障不会影响其他服务的调用。通过线程池或者分散部署结点可以对故障进行隔离。</li>
<li><strong>成熟可控的技术选型</strong>：使用市面上主流、成熟、文档、支持资源多的技术，选择合适的而非最火的技术实现系统。</li>
<li><strong>梯级存储</strong>：内存->SSD硬盘->传统硬盘->磁带，可以根据数据的重要性和生命周期对数据进行分级存储。</li>
<li><strong>缓存设计</strong>：隔离请求与后端逻辑、存储，是就近原则的一种机制。包括客户端缓存（预先下发资源）、Nginx缓存、本地缓存以及分布式缓存。</li>
<li><strong>异步设计</strong>：对于调用方不关注结果或者允许结果延时返回的接口，采用队列进行异步响应能够很大程度提高系统性能；调用其他服务的时候不去等待服务方返回结果直接返回，同样能够提升系统响应性能。异步队列也是解决分布式事务的常用手段。</li>
<li><strong>前瞻性设计</strong>：根据行业经验和预判，提前把可扩展性、后向兼容性设计好。</li>
<li><strong>水平扩展</strong>：相比起垂直扩展，能够通过堆机器解决问题是最优先考虑的问题，系统的负载能力也才能接近无限扩展。此外，基于<strong>云计算</strong>技术根据系统的负载自动调整容量能够在节省成本的同时保证服务的可用性。</li>
<li><strong>小步构建和发布</strong>：快速迭代项目，快速试错。不能有跨度时间过长的项目规划。</li>
<li><strong>自动化</strong>：打包、测试的自动化称为持续集成，部署的自动化称为持续部署。自动化机制是快速迭代和试错的基础保证。</li>
</ul>


<h2>架构六步思考法</h2>

<blockquote><p>笔者对美团总架构师夏华夏一次分享提出的架构六步思考法的理解。</p></blockquote>

<p><img src="http://www.rowkey.me/post_images/arch-six-think.png" width="450"/></p>

<h2>数据设计原则</h2>

<ul>
<li>注意存储效率

<ul>
<li>减少事务</li>
<li>减少联表查询</li>
<li>适当使用索引</li>
<li>考虑使用缓存</li>
</ul>
</li>
<li>避免依赖于数据库的运算功能(函数、存储器、触发器等)，将负载放在更容易扩展的业务应用端</li>
<li>数据统计场景中，实时性要求较高的数据统计可以用Redis；非实时数据则可以使用单独表，通过队列异步运算或者定时计算更新数据。此外，对于一致性要求较高的统计数据，需要依靠事务或者定时校对机制保证准确性。</li>
</ul>


<h2>系统响应性能提升五板斧</h2>

<ul>
<li><strong>异步</strong>：队列缓冲、异步请求。</li>
<li><strong>并发</strong>：利用多CPU多线程执行业务逻辑。</li>
<li><strong>就近原则</strong>：缓存、梯度存储。</li>
<li><strong>减少IO</strong>：合并细粒度接口为粗粒度接口、频繁的覆盖操作可以只做最后一次操作。这里一个需要特别注意的地方: <strong>代码中尽量避免在循环中调用外部服务，更好的做法是使用粗粒度批量接口在循环外面只进行一次请求。</strong></li>
<li><strong>分区</strong>：频繁访问的数据集规模保持在合理的范围。</li>
</ul>


<p><img src="http://www.rowkey.me/post_images/book-all.png" width="400"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浅析区块链]]></title>
    <link href="http://www.rowkey.me/blog/2018/03/15/blockchain/"/>
    <updated>2018-03-15T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/03/15/blockchain</id>
    <content type="html"><![CDATA[<p>从去年开始，区块链突然如火如荼起来，相关的新闻席卷微博、朋友圈、科技论坛、门户网站等各大媒体。业界大佬们更是频频发言，有宣称不做区块链就会被时代淘汰的，有说坚决不碰区块链的。国家队也是频频出手，管制、定性、做应用，央行更是默默地把区块链专利数量做到了世界前列。面对众多纷杂的信息、众多的技术分析文章，很容易让人脑袋嗡嗡，怕不懂，更怕懂了啥也都做不了。于是决定梳理一下相关的信息，看看这区块链到底是什么东西。</p>

<p>开篇之前，先抛出笔者的一个观点：<strong>区块链最合适的应用场景只有虚拟资产,除了虚拟资产的其他场景都是在蹭概念或者不是真正意义上的区块链，而且只要有人参与的业务流程都无法满足区块链设计的初衷。</strong></p>

<!--more-->


<h2>区块链是什么</h2>

<p>说到区块链，需要先了解其产生的背景，这样才能理解为何如此设计区块链。区块链的出现是和“暗网”相关的。所谓“暗网”与我们常见的“互联网”相比，只有通过特殊的软件才能够访问，并且在暗网上基本都是些黑市交易，无法见光，参与这些交易的人都不想暴露真实的位置、个人信息。应对这种交易需求，才出现了比特币。所以说，区块链一开始是为了解决匿名交易的问题出现的，也就是比特币。这也是区块链的第一个阶段，即一套账本体系和货币发行机制；后来基于区块链技术，出现了以太坊，在改进比特币区块的基础上加入了智能合约机制，称之为区块链2.0；以太坊之后，类似以太坊的一些扩展应用，能够对于每一个互联网中代表价值的信息和字节进行产权确认、计量和存储，能够扩展到几乎任何领域，这是区块链的第三个阶段，区块链将完成价值的交换。目前处在区块链2.0阶段。</p>

<p>其实从本质上看，区块链和Git类似，每个节点都有一份数据的存储，不同的是区块链没有中央服务器这么个概念，就是一个分布式无中心数据库，其有效的通过数学的方式在数据库没有管理员的情况下对内容达成一致，并且不通过正式工资或是分得股权就能奖励那些帮助使数据库变得更有价值的人们，最终能够实现无争议无抵赖的匿名交易。概括来看，其特点如下：</p>

<ul>
<li>去中心化：互联网本来的意义就是平等开放，所以有一种言论就是区块链是回归互联网本来意义的希望。这一点是区块链天然的优势，所有节点都存有数据的副本即实现了“去中心化”。</li>
<li>无法篡改: 得益于区块之间的链式结构，可以保证数据无法篡改或者篡改的成本远大于收益。</li>
<li>公开透明：每个节点保存的信息相同，能够消除信息不对称，实现信息透明。</li>
</ul>


<p>与传统的关系型数据库用一张表或者多张独立的表存储数据，“区块链”使用多个“数据表”并且多个“数据表”形成前后衔接的链式结构，以防止数据被篡改（修改任何一个区块就破坏了链式结构）。总体的结构如下所示：</p>

<p><img src="//post_images/blockchain/bc.jpg" alt="" /></p>

<p>其中每一个“数据表”在区块链中被称为“区块”。格式如下：</p>

<p><img src="//post_images/blockchain/block.jpg" alt="" /></p>

<p>这是区块链技术基本都具有的一些头部信息，包括4字节的版本号、32字节的上一个区块的哈希值、32字节的Merkle根、4字节的时间戳（当前时间）、4字节的难度目标以及4字节的随机数。</p>

<ul>
<li>版本号：用于跟踪软件/协议的更新。如果新版本的软件不兼容旧版本的软件，那么就认为是发生了“分叉”。</li>
<li>上一区块头哈希值：存储的是链上上一个区块的哈希值，也是区块链设计的精髓所在。</li>
<li>Merkle根：又叫做梅克尔根，是一种用于完整性证明的数据结构，为了能够在区块头中体现出交易而做的一个计算，同时也是为了解决交易记录进行Hash计算的效率问题。</li>
<li>时间戳：该区块产生的近似时间。这个时间虽然是节点生成的但是其是否有效需要其他节点的认可（允许有一定程度的误差）。时间戳使得交易有先后，是防范双重支付攻击的一个关键设计。</li>
<li>难度目标：该区块工作量证明的算法的难度系数。系数越大，目标哈希值的0越多，计算的难度呈指数增长。</li>
<li>Nonce: 用于工作量证明算法的计数器。</li>
</ul>


<p>区块体的信息主要是交易列表。交易的数据结构因平台的不同而不同。比特币中就是简单的交易信息，以太坊则会存放智能合约。这里需要提到的是比特币中使用UTXO（未花费的交易输出，Unspent Transaction Output）实现支付系统的账户模型，并没有余额、钱包的概念，交易列表中的关键信息也是一些UTXO的组成,如此计算账户的余额则需要通过遍历整个交易历史来最终计算出每个账户的余额。UTXO的示例如下图所示：</p>

<p><img src="//post_images/blockchain/utxo.png" alt="" /></p>

<p>可见除了coinbase这种交易之外，其他的交易都至少有一个交易的输入且必须引用一个输出，而一笔交易的输入可以引用之前多笔交易的输出。此外，任何一笔交易的交易输入总量必须等于交易输出总量（支出与找零）。其一般结构如下：</p>

<p><img src="//post_images/blockchain/utxo-struct.png" alt="" /></p>

<p>使用UTXO的优势如下：</p>

<ul>
<li>私密性比较强，理论上可以为每一笔输出设置一个地址。</li>
<li>无需维护余额等状态值。</li>
<li>UTXO是独立数据记录，可以通过并行极大的提升区块链交易验证速度。</li>
<li>无需关心事务问题，只需要关心输出脚本即可。</li>
<li>能够清理过期交易，回收存储空间。</li>
</ul>


<p>而以太坊则使用了传统所理解的账户模型，主要是因为UTXO无法支持图灵完备的智能合约实现。</p>

<p>此外，还需要说一下“块高度”的概念。区块链网络的创世块（第一个区块）的块高度为0，如此每增加一个区块高度就+1，如第一个图所示，如果最左侧的块为创世块，那么最后一个区块的块高度就是2。</p>

<h2>区块链典型流程</h2>

<p>以<strong>比特币</strong>为例，区块链的一个典型交易流程：</p>

<ul>
<li>新的交易向全网所有节点广播，交易信息包括发UTXO输入、UTXO输出等关键信息。这里一个交易并不需要抵达全部的节点。只要交易信息能够抵达足够多的节点，那么他们将很快被整合进一个区块中。</li>
<li>每一个节点都将收到的交易信息经过验证无误后（使用解锁加锁脚本自动化验证）纳入一个区块中（被打包到块之前这些交易被存储在内存池中）。</li>
<li>每一个节点都尝试根据最新的区块的信息找到一个具有足够难度的工作量证明。</li>
<li>当一个节点找到了一个工作量证明，就创造一个新的区块（将接收到的交易纳入其中），并向全网进行广播。</li>
<li>当且仅当包含在该区块中的所有交易都是有效的且之前未存在过的，其他节点才认同该区块的有效性。</li>
<li>其他节点表示他们接受该区块，而表示接受的方法，是在跟随该区块的末尾制造新的区块以延长该链条，将被接受区块的随机散列值做为新区快的Prev随机散列值。</li>
</ul>


<h2>区块链技术架构</h2>

<p>其实从本质来看，区块链不能算是一个新的技术，更应该看做是一个新的技术框架，是基于很多成熟的技术而成的，而且不仅仅是技术，还有金融学，货币学，博弈学等。其技术架构如下图所示：</p>

<p><img src="//post_images/blockchain/arch.jpg" alt="" /></p>

<p>其中，区块的链式结构、UTXO以及智能合约是比特币发明人“中本聪”的原创发明。</p>

<h2>存储</h2>

<p>区块链在每一个节点会存储数据，并且需要持久化存储，存储方式和传统的应用一样，包括数据库和文件系统。</p>

<p>对于存储方式的选择, 区块链中并没有做相关的规定，而比特币和以太坊都使用LevelDB做为持久化存储方式。</p>

<h2>通信机制</h2>

<p>区块的通信是基于P2P技术,即不区分客户端和服务端的网络，和P2P下载是类似的原理。在区块链中其功能点包括：</p>

<ul>
<li>把需要存储的数据广播到所有节点上进行储存，也就是多播。</li>
<li>查询整个网络集群中所有节点的最新数据，如果自己节点的数据与大部分节点的数据不一致，则更新自身的数据与大部分节点存储的数据一致。这个功能也是防止数据被篡改的一个很重要的机制，是区块链核心的一个原则“少数派服从多数派”。当然这个也会引起51%攻击的问题。但区块链使用其他的机制极大杜绝了这种风险，下文会提到。</li>
</ul>


<h2>安全机制</h2>

<p>区块链同样使用了很多成熟的安全技术来保障其特点。</p>

<ul>
<li>哈希算法：⽤来对⼀段数据进行计算，得出⼀个摘要信息，通俗点说就是给一段数据⽣成⼀个固定大小的身份ID, 且其是不可逆的。区块链使用哈希做工作量证明、交易ID生成、区块之间的关联等。此外，区块头中的Merkle Root也是使用哈希算法做完整性证明的（比特币中使用double-SHA256哈希算法）。常用哈希算法包括MD5、SHA1、SHA256等。</li>
<li>数据加密：区块链使用了非对称加密算法。比特币中的钱包地址本质就是一对公钥私钥。此外，区块链利用公钥哈希加锁比特币的输入记录，阻止输出。</li>
<li>数字签名：同样基于非对称加密技术，用签名和公钥解锁自己的比特币输入记录，使用比特币。</li>
<li>零知识证明：所谓零知识证明即在不知道答案的情况下去验证给出的答案是否正确。这个过程完全靠机器验证，机器根据题目给出随机试验以验证答案是否正确。在某些区块链应用中如Zcash\ZCoin即使用了零知识证明来保证交易双方和交易金额的匿名性, 提供了绝佳的支付隐私。详细可见：<a href="https://mp.weixin.qq.com/s?__biz=MzIxMDY1ODQxMg==&amp;mid=2247486271&amp;idx=3&amp;sn=233f6c9b0f881d4a2fe4bb71c60ca2cc&amp;chksm=97607e3ca017f72a5393d46f0dd5985c07aa7aed8262c78cb0e8ae96c5f05727b0bde9a2a5b0&amp;mpshare=1&amp;scene=1&amp;srcid=0306YQQBdMN6j1B1IpuCgpCg%23rd">零知识证明（Zero-Knowledge Proof）原理详解</a>。</li>
</ul>


<p>此外，这里具体介绍一下是如何使用区块中的梅克尔树来做完整型证明的。每当产生一次交易，那么就与其他所有准备打包进区块的交易组成交易列表，通过Merkle Tree算法生成Merkle Root Hash，作为交易列表的摘要存到区块头中。比特币中使用的称之为二叉梅克尔树，而比如以太坊系统中使用的则是梅克尔-帕特里夏树。以二叉梅克尔树为例，流程可以概括为每相临的两条交易记录向上形成一个Hash值（如果仅有奇数个交易，则最后的交易会被复制一份以构成偶数个叶子节点），再与相邻的节点再往上形成Hash值，一直到树根形成所有交易记录的唯一Hash值，即Merkle根。如下图所示：</p>

<p><img src="//post_images/blockchain/merkle.jpg" alt="" /></p>

<p>如此，一方面可以在数据同步有问题的时候快速定位到出错的交易记录，另一方面在节点只是需要验证支付（不同于交易，如验证是否有人完成了对自己的一笔交易）的时候，仅下载链的区块头即可，实现“简化支付验证”（SPV），能够极大的节省传输数据量。SPV的流程如下：</p>

<ul>
<li>一个SPV节点会在节点间的通信链接上建立起布隆过滤器，限制只接受含有目标比特币地址的交易。</li>
<li>当节点探测到某交易符合布隆过滤器，它会以Merkle区块消息的形式向相邻节点索要包含区块头和一条连接目标交易与Merkle根的Merkle路径，如图中如果要验证交易1，那么则返回Hash2、Hash34即可。</li>
<li>SPV节点使用该路径找到与该交易相关的区块，验证对应区块中该交易的有无。</li>
</ul>


<h2>共识机制</h2>

<p>对于分布式系统来说，一个非常核心的问题就是如何让所有节点达成一致，也就是共识机制。在区块链出现之前，已经有了一些解决方案，这里称之为传统分布式一致性算法：</p>

<ul>
<li>Paxos算法：基于消息传递且具有高度容错特性，类似于议会投票的过程分为三种角色Proposer、Acceptor及Learner，主要就是Proposer发起投票，Acceptor进行投票的一个过程。具体可见：<a href="http://drmingdrmer.github.io/tech/distributed/2015/11/11/paxos-slide.html">可靠分布式系统基础Paxos的直观解释</a>。这里需要说明一点：Zookeeper使用的ZAB协议对Paxos做了一些改造，是一种类Paxos算法。</li>
<li>Raft算法：相比起Paxos算法，RAFT更加注重算法的落地性和可理解性，其核心思想是如果数个数据库初始状态一致，只要之后的进行的操作一致，就能保证之后的数据一致。分为Leader、Follower以及Candidate三种角色，基于Log进行数据同步。大体就是选举Leader，然后Leader生成Log，Follower进行同步的一个过程。详细可见:<a href="https://zhuanlan.zhihu.com/p/27207160">Raft协议详解</a>。</li>
</ul>


<p>对于不需要货币体系的联盟链或者私有链而言，所有的节点都是绝对信任的节点，考虑到对性能的要求，一般选择传统的一致性算法即可。但由于这些传统的方案仅仅是考虑到了节点会有网络故障或者宕机的问题，没有考虑到节点会作恶（篡改消息）的情况。因此，在比特币、以太坊这种区块链上并不适用。于是有了以下的分布式一致性算法：</p>

<ol>
<li><p>PBFT: 拜占庭容错，针对的是拜占庭将军问题而提出的一种一致性算法。分为三个阶段：预准备（pre-prepare）、准备(prepare)和确认(commit)。大体的流程就是节点之间互相转发消息，以其中相同的大多数作为最终答案。此算法的可靠度受制于结点的数量影响（N ≥ 3F + 1，总的结点数目必须大于有问题节点的数目的三倍），因此使用受限，在IBM的私有链Hyperledger中得到了使用。</p></li>
<li><p>PoW: Proof of Work,工作量证明。这个是比特币、莱特币等货币型区块链使用的共识机制。类似于现实中的毕业证、驾照等，来证明你具有某种能力。可以认为PoW彻底解决了分布式一致性的问题。其过程以比特币为例，如下：</p>

<ul>
<li>矿工在网络中拿到最新一个区块的头部信息，其中的Merkle根包含了交易记录的信息摘要；</li>
<li>将拿到的头部信息作为参数，将nonce值从零开始，去计算其双重SHA256值（<strong>SHA256(SHA256(区块头信息))</strong>）；</li>
<li>如果算出的答案不符合要求（前n位为0），则将nonce值增加一个单位，再算；</li>
<li>直到计算出符合难度目标的答案，就挖到一个区块（打包交易记录，其中优先记录手续费高的交易），即可将自己创建的区块广播出去，其他节点验证无误即保存到自己的区块链上。</li>
<li>如果同时有多个节点实现了工作量证明挖到了区块，那么整个网络集群采用少数服从多数原则，集群中大部分采用了哪个区块就选择此区块组成最新的账本，达到最终一致性。<strong>少数服从多数原则</strong>也是区块链防范攻击、保证数据安全性的一个核心的原则。</li>
<li>如果节点同步到了多个长度不同的区块链账本，那么选择其中最长的作为区块链账本，且在最长链之外挖矿，不会得到任何挖矿报酬。即“最长链规则”。</li>
</ul>


<p> 由最后两点可知，挖到一个区块时，并不能过早的高兴，一般说来后面再跟五个确认过的区块（加上自己的区块，叫做六次确认），才能确认自己创建的区块的确是有效的，记录的交易也才认为是有效的（此时交易接收方可以认为交易已经成功）。</p>

<p>这个思路牺牲了一部分一致性来保证区块链的健壮性，即使只有一个结点，区块链系统依旧可以运行。同时也保证了区块链的安全性，除非51%的结点被控制。但一方面如果想要控制这么多节点，不仅要具有很强的算力，还相当于重构一个区块链网络，另一方面区块链会给予实现工作量证明创建区块成功的节点以奖励（每一个区块的交易清单的第一条交易为“系统给区块创建者支付xx奖励”，被称做coinbase交易，此交易没有输入），在比特币中奖励包括一部分新造比特币（一开始一个区块奖励50个比特币，每隔21万个区块自动减半，4年时间比特币总量最终会稳定在2100万个），一部分是从区块所包含的交易中抽取的挖矿手续费。如此权衡收益和破坏的成本，基本可以杜绝这种51%攻击（博弈学的使用）等。</p>

<p>此外，还需要提到区块头中的难度目标这个值，此值与计算耗时是反比的，即此值越大，那么计算越容易。以比特币为例，为了控制每十分钟产生一个区块的速率，需要根据统计数据动态调整难度目标从而可以保证区块的生产速率。</p>

<p>比特币的PoW虽然很好的解决了分布式一致性问题，但其非常的耗费计算力，浪费电，并且这种纯粹靠CPU的计算会受到某些专用硬件的威胁，如ASIC芯片。而以太坊的POW算法叫做Ethash（最新版本为Dagger-Hashimoto），其特点是挖矿的效率基本与CPU无关，却和内存大小和内存带宽正相关，无法设计专用硬件来解答难题。</p></li>
<li><p>PoS: Proof of Stake，权益证明机制。是一种通过业务规则达成共识的方式。基本概念是产生区块的难度应该与用户在网络里所占的股权成比例。具体来说就是根据钱包里面货币的多少以及货币在钱包里存在的天数来合成一个单位（币天），然后根据币天的关系对计算机进行哈希计算降低（谁的钱包里的币天数越大谁拥有记账权的概率就越大）。如此，能够减少对计算资源的浪费，提高计算性能。但是它也是牺牲了一部分的共识，而且需要等待多个确认。与PoW类比于比力量大小，PoS就是比耐力大小。</p>

<p> PoS目前已经使用在以太坊中。</p></li>
<li><p>DPoS: Delegate Proof of Stake。是基于POS衍生出的更专业的解决方案，类似于董事会的投票机制，选举出n个记账节点，在节点中提案者提交的提案被这些记账节点投票决定谁是正确的。此机制性能比较高，但是其选出的delegate节点是能够作恶的。</p>

<p> EOS的底层框架石墨烯-<a href="https://github.com/cryptonomex/graphen">Graphene</a>使用DPoS做为共识机制。</p></li>
</ol>


<h2>上层应用</h2>

<ul>
<li>可编程合约/可编程资产：交易验证并不基于一个不变的模式，而是通过运行脚本语言来实现可编程资产以太坊。</li>
<li>激励机制：虚拟货币激励，比特币、以太币。</li>
<li>成员管理：为整个区块链网络提供身份管理、隐私、保密和可审计的服务。通过公钥基础设施和去中心化共识机制使得非许可的区块链变成许可制的区块链。多中心组网、私钥公钥生成等。</li>
</ul>


<p>这里需要提的是区块链中“地址”的含义。以比特币为例，地址本质上是一个私钥公钥对（ECDSA椭圆曲线算法），其存储和区块链和网络是没有关系的，可由用户的钱包软件生成并管理。而通常为了易于人们记忆，地址会在公钥的基础上做一个格式化转换。常用的格式包括：Base58Check（Base58+Checksum）、WIF压缩、130位和66位公钥。以最常用的Base58Check为例，可以概括为:<strong><em>Base58Check(RIPEMD160(SHA256(PubKey)))</em></strong>，其流程如下：</p>

<p><img src="//post_images/blockchain/bitcoin-address.png" alt="" /></p>

<p>而以太坊则是使用SECP256K1椭圆曲线算法生成公钥私钥对，再把公钥去掉04，剩下的进行KECCAK-256的哈希，得到长度64的16进制字串，丢掉前面24个，拿后40个，再加上&#8221;0x&#8221;，即为以太坊地址。</p>

<h2>性能问题</h2>

<p>目前区块链无法得到大规模应用的一个很大问题就是性能，比特币的每秒交易量只有3/秒，而以太坊也就30/秒。虽然EOS这个项目号称能达到几百万/S，然而分布式系统的本质让这个指标有点难以相信，而且这个数据也仅仅是建立在其几百个结点的基础上。</p>

<p>目前，提升区块链的方案主要有以下两种种：</p>

<ul>
<li>链外解决方案：即允许小型和频繁的交易发生在与主链并行并由主链背书的侧链实例上。只将比特币区块链用作大额交易的结算网络——小规模交易由区块链之外的支付中心处理（off-chain scaling，链外扩展）。</li>
<li>链上解决方案：直接修改区块链设计以支持高性能，如提高区块的容量、按照地址分片验证（以太坊）等。具体的可见：<a href="https://mp.weixin.qq.com/s?__biz=MzAwOTcyNzA0OQ==&amp;mid=2658972665&amp;idx=1&amp;sn=a3b8cc3538099530270910ae12267795">区块链性能提升：链上设计之道</a>。</li>
</ul>


<p>当然，如果使用私有链或者联盟链，其中的共识机制采取传统的分布式一致性算法或者高效的其他一致性算法也可以解决性能的问题。</p>

<h2>应用场景</h2>

<p>由于区块链本身的去中心化、不可篡改、安全等特性，需要第三方机构的应用场景都可以使用区块链技术。主流的应用场景如下：</p>

<ul>
<li>公正防伪</li>
<li>资产交易</li>
<li>信用体系</li>
<li>物品溯源</li>
<li>身份验证</li>
<li>文件存储</li>
<li>银行结算</li>
<li>版权控制</li>
</ul>


<h2>技术平台</h2>

<p>区块链的技术平台总体上可以分为公有链、联盟链和私有链，其大体的对比如下：</p>

<table>
<thead>
<tr>
<th>. </th>
<th> 公有链 </th>
<th> 联盟链 </th>
<th> 私有链</th>
</tr>
</thead>
<tbody>
<tr>
<td>参与者 </td>
<td> 任何人自由进出 </td>
<td> 联盟成员 </td>
<td> 个体或公司内部</td>
</tr>
<tr>
<td>共识机制 </td>
<td> PoW/PoW/DPoS  </td>
<td> 分布式一致性算法 </td>
<td> 分布式一致性算法</td>
</tr>
<tr>
<td>记账人 </td>
<td> 所有参与者 </td>
<td> 联盟成员协商确定 </td>
<td> 自定义</td>
</tr>
<tr>
<td>激励机制 </td>
<td> 需要 </td>
<td> 可选 </td>
<td> 不需要</td>
</tr>
<tr>
<td>中心化程度 </td>
<td> 去中心化 </td>
<td> 多中心化 </td>
<td> （多）中心化</td>
</tr>
<tr>
<td>特点 </td>
<td> 信用的自建立 </td>
<td> 效率和成本优化 </td>
<td> 透明和可追溯</td>
</tr>
<tr>
<td>承载能力（交易数/s） </td>
<td> 3-20万/s </td>
<td> 1000-1万/s </td>
<td> 1000-10万/s</td>
</tr>
<tr>
<td>典型场景 </td>
<td> 虚拟货币 </td>
<td> 支付、结算 </td>
<td> 审计、发行</td>
</tr>
<tr>
<td>代表项目 </td>
<td> 比特币、以太坊 </td>
<td> Hyperledger、腾讯TrustSQL </td>
<td></td>
</tr>
</tbody>
</table>


<h3>比特币</h3>

<p>比特币(使用C++开发)早于区块链走入人们的视野，并且很长时间内许多人都把比特币和区块链看做同一个东西。</p>

<p><img src="//post_images/blockchain/bitcoin.png" alt="" /></p>

<p>如图，是比特币的架构，可以看出比特币是基于区块链技术的副产品，是基于区块链的第一个应用，后来其他技术平台基本都是在比特币的基础上开发出来的。区块链可以类比为我们平时使用的JavaEE技术，比特币则是基于JavaEE开发的应用。无法基于比特币这个平台开发自己的应用。</p>

<h3>以太坊</h3>

<p><img src="//post_images/blockchain/ethereum.png" alt="" /></p>

<p>如上图所示，以太坊的架构由比特币演化而来，其诞生是为了解决比特币只适合加密数字货币场景，不具备图灵完备性，也缺乏保存实时状态的账户概念的问题，同时也是为了解决PoW机制带来的效率和资源浪费的问题。以太坊既是一个数字货币系统，也是一个智能合约的开发平台（类似AppStore这种应用开发平台，一个智能合约即一个应用）。可以把以太坊看做一个完全去中心化的电脑，使用此电脑需要用以太币支付费用（Gas）。</p>

<p>智能合约是以太坊最为核心的一个概念：提供了一个功能更强大的合约编程环境。一个合约类似一个合同，一旦写好即无法修改。每个节点都执行软件的一部分。类比于数据库中的触发器和存储过程，智能合约在区块链中是一个沙箱中的脚本（无法调用外部API），用于执行业务逻辑，也可以用于各种检查。开发智能合约使用的是Solidity语言。其是在Javascript语言基础上做的修改。合约代码会编译成字节码发布到以太坊网络，在EVM(Ethereum Virtual Machine)中执行。开发智能合约主要用到两个框架：</p>

<ul>
<li>Truffle Framework：Truffle提供了一整套部署测试的工具，可以方便和web3.js（以太坊提供的NodeJS SDK）结合使用。</li>
<li>dapphub: 提供了很多实用的合约，比如数学运算、权限验证等。</li>
</ul>


<p>其实比特币的交易也可以看做智能合约，只不过在比特币中就是⼀对锁定与解锁脚本（基于逆波兰表示法的基于堆栈的执行语言），受限只能实现转账交易。</p>

<p>使用以太坊发行数字代币（符合ERC20标准的智能合约）是非常简单的事情，官网提供了配套的代码和工具：<a href="https://www.ethereum.org/token">https://www.ethereum.org/token</a>，也可以参照这个指引：<a href="https://learnblockchain.cn/2018/01/12/create_token/index.html">一步步教你创建自己的数字货币（代币）进行ICO</a>。</p>

<p>这里还要说明一下ETC和ETH的区别。2016年6月区块链业界最大的众筹项目TheDAO遭到黑客攻击,导致300多万以太币资产被分离出TheDAO资产池。鉴于区块链的去中心、匿名的特征，资金根本无法追回，于是以太坊的发明人V神决定从块高度1760000开始把任何与The DAO和child DAO相关的交易认做无效交易，把以太坊做了一次分叉（区块链软件升级，但由于去中心化的问题并不能保证所有软件版本都升级上来），以此阻止攻击者在27天之后提走被盗的以太币。但此次分叉由于设计缺陷问题后来进行了回滚，最终是在区块高度1920000进行了一次分叉。而另外一些人由于不认同这种解决办法，而继续使用旧版本的以太坊软件，于是以太坊便发生了硬分叉（区块链软件升级，老版本不能够识别新的数据），原来的以太坊被叫做了ETC（以太经典）。至于这次攻击能够成功的原因主要是因为智能合约的逻辑有问题，具体的原因分析可见：<a href="http://ethfans.org/posts/114">从技术角度剖析针对THE DAO的攻击手法
</a>。</p>

<h3>EOS</h3>

<p>Enterprise Operation System，是由和V神齐名的BM大神发起的区块链项目，从名字上看其目的就是构建一个商业操作系统。由于其是一个ICO项目，且被某比特币大V进行了投资，因此受到的议论比较多。EOS的设计针对的是区块链性能太低满足不了很多应用场景以及在以太坊上进行操作需要支付费用等问题。</p>

<p>EOS号称自己能够达到每秒百万级的处理量，且具有高度自治，并能够为开发dApp的开发者提供底层模块，降低开发门槛。EOS也不收取任何费用，并能够通过并行链和DPOS的方式解决延迟和数据吞吐量的难题。</p>

<p>在EOS上编写智能合约支持C/C++/WebAssembly以及RESTFul接口(比较简单)。</p>

<h3>NEO</h3>

<p>小蚁区块链，开源，使用dBFT（delegated BFT，授权拜占庭容错机制）做为其共识机制。市值国内第一，全球第七，支持C#、Java、GO、Python、js等开发区块链应用。其目的是利用区块链技术和数字身份进行资产数字化，利用智能合约对数字资产进行自动化管理，实现“智能经济”。</p>

<p>目前，NEO提供了配套设施搭建私有链。</p>

<h3>联盟链和私有链</h3>

<p>市面上有一些联盟链和私有链技术平台，可以基于此做一些区块链应用开发。如下：</p>

<ul>
<li>腾讯TrustSQL: 腾讯主导的可信数据库区块链平台，<a href="https://trustsql.qq.com/">https://trustsql.qq.com/</a>。</li>
<li>百度区块链开放平台：百度主导的区块链平台，<a href="https://chain.baidu.com/">https://chain.baidu.com/</a>。</li>
<li>IBM HyperLedger，也被称作超级账本，又叫fabric，是一个面向商业的区块链系统开发框架（开发用的半成品基础设施）。</li>
</ul>


<h2>ICO</h2>

<p>提到区块链，ICO是不得不提的一个概念，类比于IPO，ICO是首次发币代售，提供了一种平等、低门槛的方式让普通民众参与到经济活动中，目前能够进行ICO的平台(能够方便发代币)主要是以太坊和比特股(Bitshares)。这种东西本意是好的，可以降低公司融资的成本，好的项目不会再看风投脸色，好的Idea也不会再胎死腹中，用户ICO获得的Token还可以带来实际的经济效益。但是由于缺乏IPO一样的管制，已经彻底沦为了收割智商的工具。</p>

<p>如上文所说，其实基于以太坊发行虚拟货币是非常简单的，如果你文采够好随便写个白皮书，洋洋洒洒描绘一个去中心化的蓝图，再找几个所谓业界大神站个台，好了，剩下的就等着数钱吧。当然，不排除有真心想做出一个项目的，但绝大多数都是些空气项目，发起人不过是发了个空气币，然后卷钱跑路。</p>

<p>说到ICO，虚拟货币交易所也是关键的角色，在这里可以流通法币和各种虚拟货币。有点令人不解的是，去中心化的区块链虚拟货币竟然需要一个中心化的“交易所”。黑客们攻击不了区块链，攻击一个中心化的交易所还是有许多路可寻的。最近频频发生的虚拟货币交易所被攻击的事情也算是对这种模式的一种讽刺。</p>

<h2>开发参考</h2>

<p>如果想实现自己的区块链平台或者了解区块链的实现，可以通过比特币、以太坊的代码学习，也可以参考以下资料:</p>

<ul>
<li><a href="https://www.ibm.com/developerworks/library/j-chaincode-for-java-developers/index.html">面向Java开发人员的区块链代码</a></li>
<li><a href="http://www.spring4all.com/article/811">用Java创建你的第一个区块链-part1</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653549361&amp;idx=1&amp;sn=019f54713891cf33ef3bef3b24773a96&amp;chksm=813a62a9b64debbfdd24a8507bb974048a4456e5b0a2d5f685fb3bdf40366a25764c5df8afec&amp;mpshare=1&amp;scene=1&amp;srcid=0226W0WdpzjJ9Qo6F3FJstO6%23rd">只用200行Go代码写一个自己的区块链！</a></li>
</ul>


<h2>小结</h2>

<p>区块链技术的出现以一种全新的思路解决了分布式一致性的问题，技术+博弈学+金融学的使用巧妙的构建了一个安全健壮的系统。这些思路给开发者在平时的学习工作中会有很多的思考和提示。而随着比特币价格的水涨船高和各种资本的追捧，区块链目前是被过度炒作的，大部分应用都是联盟量和私有链，已经违背了区块链设计的初衷。虽然的确是有应用场景，但笔者认为这和共享分布式数据库没有本质上的区别。此外，虽然区块链上的数据是无法篡改的，但是如果数据上链有人工参与的环节，那么这一步如何防止篡改呢？这也是我开篇观点产生的原因。</p>

<p>至于能用区块链做什么？在笔者看来，去研究区块链技术平台只有大公司、政府能做并推广起来，不过最后也只不过是“联盟链”、“私有链”。而对于创业公司或者个人来说，基于公有链、联盟链做之上的应用则更为合适，比如在以太坊/EOS上做一个养宠物的游戏^_^。</p>

<h2>参考资料</h2>

<ul>
<li><a href="http://8btc.com/topic-mastering-bitcoin.html">精通比特币</a></li>
<li><a href="http://www.8btc.com/wiki/bitcoin-a-peer-to-peer-electronic-cash-system">比特币白皮书:一种点对点的电子现金系统</a></li>
<li><a href="http://dataconomy.com/2015/10/wtf-is-the-blockchain-a-guide-for-total-beginners/">WTF IS THE BLOCKCHAIN? A GUIDE FOR TOTAL BEGINNERS</a></li>
<li><a href="http://blog.csdn.net/jeffrey__zhou/article/details/56672948">区块链共识机制浅谈</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3MzEzMDI1OQ==&amp;mid=2651818777&amp;idx=1&amp;sn=8cf64236f13e1196b28a2603744d4c0f&amp;chksm=f0dcdd65c7ab5473a239b47939d7586229122788c49fbac295c77627b4693a06b1ce8d73afdc&amp;mpshare=1&amp;scene=1&amp;srcid=0829NWygcU8u98YzRZ8TmQlN%23rd">白话区块链技术栈与应用</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIzNzU4MTg5NQ==&amp;mid=2247484492&amp;idx=1&amp;sn=b37844e8ab32b5ce516ee92149f243d6&amp;chksm=e8c72764dfb0ae727b2a50da75ef1ded417ad3c303c47f61c666f8dd39e631f114ab350f2544&amp;mpshare=1&amp;scene=1&amp;srcid=0217E8nz8lHzcB3sBvSBAics%23rd">比特币的潜在激励</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247487013&amp;idx=1&amp;sn=4675dd398a3458af9ba519557675e406&amp;chksm=e929332ade5eba3c142a36f89677d71bf1e1395967ace0b9e4ff3d18c6cffd604420709967fe&amp;mpshare=1&amp;scene=1&amp;srcid=03126HIJoomFmy2JpebnHa5m%23rd">如何用架构师思维解读区块链技术？</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何快速尝出毒酒？- 用bit解决问题]]></title>
    <link href="http://www.rowkey.me/blog/2018/01/04/king-rec-pois-wine/"/>
    <updated>2018-01-04T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/01/04/king-rec-pois-wine</id>
    <content type="html"><![CDATA[<h2>问题</h2>

<p>国王有一百桶酒，比自己的生命还重要。结果有一天其中一桶被投了慢性毒药，喝了以后半个小时以后就会死掉。国王大怒，命令玩忽职守的侍卫去试毒。酒不能被混合，一个侍卫可以喝多桶酒，一桶酒也可以由多个侍卫喝，怎么样才能用最少的侍卫、在最短的时间知道哪桶是毒酒。侍卫可以理解为线程，即怎么样用最少的线程用最快的速度完成这个工作。</p>

<!--more-->


<h2>方案</h2>

<p>此问题是我在面试时经常用的一道题目，主要考察的是候选人能不能以计算机的思维考虑问题。</p>

<p>最简单的方案肯定是找100个人，每个人试一桶酒，那么用时30分钟，就可以判断出哪一桶就有毒。</p>

<p>再进一步的，可以使用分段法，把酒分成n份，先找n个侍卫试酒，可以定位出哪一段的酒有毒，再接着分段试酒。但这种方案，分段数目越少，试出毒酒的平均耗时就越长。</p>

<p>如果用计算机的思维来分析这个问题，那么首先考虑如何存储这100桶酒。100桶酒可以用二进制7个bit来表示（2<sup>7</sup>>100）。对应那一桶毒酒，其二进制表示中为1的位置如果能够可以定位出来，就可以定位出此桶毒酒。可以找7个侍卫编号1-7。对于每一桶酒的二进制表示（不足七位前面用0表示），从第一位到第七位，如果是1，则对应编号的侍卫喝此桶酒。这样，每个侍卫喝掉对应的酒。30分钟后，侍卫按照编号1-7，死掉的置为1，活着的置为0，如此，侍卫的一个序列如0000111就表示第七桶酒为毒酒。</p>

<h2>总结</h2>

<p>上述最后一种方案提现了在计算机中使用bit来解决问题的思路。当需要节省存储的时候，使用bit来做经常会有出其不易的效果。就比如最近很火的电影《天才枪手》中，主角们记忆选择题的答案A、B、C、D，完全可以使用位编码来表示四种答案:00-A 01-B 10-C 11-D，四个bit转换为一个十六进制数字，如此就可以节省一半的存储，记忆起来也会简单很多。此外，我们处理大数据去重/计数使用的Bitmap、BloomFilter，也都是一种使用bit节省存储的思路。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何实现延时触发/定时器]]></title>
    <link href="http://www.rowkey.me/blog/2017/12/28/delay-trigger/"/>
    <updated>2017-12-28T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2017/12/28/delay-trigger</id>
    <content type="html"><![CDATA[<h2>问题</h2>

<p>微信公众平台后台有一个功能即定时群发消息，如明晚的20:00群发一条图文消息。那么这种延时触发的逻辑如何实现呢？</p>

<!--more-->


<h2>方案一</h2>

<p><strong>每隔一定的时间扫描所有超时的事件</strong></p>

<p>这是最容易想到的一种方案。此方案最关键的两点是轮训的频率以及如何高效地获取超时任务。</p>

<ul>
<li>如果可以允许一秒左右的误差，每隔一秒轮训一次即可。</li>
<li>采用红黑树或者最小堆存储触发任务，按照触发时间戳排序。如此，每次扫描能够很快地获取超时的任务。实践中，一个很简单的方案就是使用Redis的SortedSet存储触发任务，这样只需要使用zrangeByScore获取超时的任务，再使用zremrangeByScore即可删除已经触发的任务。</li>
</ul>


<p>此种方案的缺点在于即使频率到达一秒，也可能会有一秒的误差。此外，轮训的方式在很多情况下并没有可触发的任务，会浪费资源。</p>

<h2>方案二</h2>

<p><strong>阻塞线程等待时间超时</strong></p>

<p>此方案思路来自于Nginx中定时器的实现（和Java中的DelayQueue原理类似）。任务的存储和上面的方案类似，采用最小堆或者红黑树即可。然后选择最近要被触发的任务的时间距离作为阻塞调用epoll_wait的超时（也可以使用其他可以设置超时的阻塞调用）。阻塞超时后，依次获取最小触发时间戳的任务，超时则执行。</p>

<p>此种方案的最大优点在于不会有空的任务检查周期。</p>

<h2>方案三</h2>

<p><strong>采用环形队列</strong></p>

<p>此方案详细可以见58沈剑的文章<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651959961&amp;idx=1&amp;sn=afec02c8dc6db9445ce40821b5336736&amp;chksm=bd2d07458a5a8e5314560620c240b1c4cf3bbf801fc0ab524bd5e8aa8b8ef036cf755d7eb0f6">《1分钟实现“延迟消息”功能》</a>。大体的思路如下：</p>

<p>采用环形队列，3600个slot，每隔1秒扫描一个slot，检查当前slot里面的所有任务，检查其cycleNum是否为0, 为0则触发，否则cycleNum-1。添加定时事件时，根据扫描指针的当前slot的index和事件触发的时间，计算cycleNum和要放入的slot。</p>

<p>此种方案的本质是<strong>栅格化与预计算</strong>，相比起前两种方案，大大提升了每次获取可触发任务的效率。但同样存在每次查询任务有可能做无用功的问题。此外，需要特别处理添加任务和扫描任务的临界点的问题，否则也可能会有时间上的误差。</p>

<p><strong>PS: 这个方案原理是和时间轮(Netty中的HashedWheelTimer)一样的，多谢@imangry提示</strong></p>

<h2>方案四</h2>

<p><strong>延时消息队列</strong></p>

<p>目前，RabbitMQ、RocketMQ都支持延时消息队列，直接使用即可。但这种依赖消息队列的方案，如果要取消定时任务，则无法实现。其中，RabbitMQ的实现思路是基于TTL的，详细可见：<a href="http://www.cnblogs.com/haoxinyue/p/6613706.html">http://www.cnblogs.com/haoxinyue/p/6613706.html</a>。</p>
]]></content>
  </entry>
  
</feed>
