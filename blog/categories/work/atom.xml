<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: work | 后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/blog/categories/work/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2016-11-17T10:17:37+08:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[谈谈互联网后端基础设施]]></title>
    <link href="http://www.rowkey.me/blog/2016/08/27/server-basic-tech-stack/"/>
    <updated>2016-08-27T23:10:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/08/27/server-basic-tech-stack</id>
    <content type="html"><![CDATA[<p>对于一个互联网企业，后端服务是必不可少的一个组成部分。抛开业务应用来说，往下的基础服务设施做到哪些才能够保证业务的稳定可靠、易维护、高可用呢？纵观整个互联网技术体系再结合公司的目前状况，个人认为必不可少或者非常关键的后端基础技术/设施如下图所示：</p>

<p><a href="http://www.rowkey.me/images/blog_images/server_basic_stack/server-basic-tech-stack.png" target="_blank"><img src="http://www.rowkey.me/images/blog_images/server_basic_stack/server-basic-tech-stack.png"/></a></p>

<ul>
<li><a href="#Api%E7%BD%91%E5%85%B3">Api网关</a></li>
<li><a href="#%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8%E5%92%8C%E5%90%8E%E7%AB%AF%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6">业务应用和后端基础框架</a></li>
<li><a href="#%E7%BC%93%E5%AD%98%E3%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E3%80%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97">缓存、数据库、搜索引擎、消息队列</a></li>
<li><a href="#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8">文件存储</a></li>
<li><a href="#%E7%BB%9F%E4%B8%80%E8%AE%A4%E8%AF%81%E4%B8%AD%E5%BF%83">统一认证中心</a></li>
<li><a href="#%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E7%B3%BB%E7%BB%9F">单点登录系统</a></li>
<li><a href="#%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83">统一配置中心</a></li>
<li><a href="#%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E6%A1%86%E6%9E%B6">服务治理框架</a></li>
<li><a href="#%E7%BB%9F%E4%B8%80%E8%B0%83%E5%BA%A6%E4%B8%AD%E5%BF%83">统一调度中心</a></li>
<li><a href="#%E7%BB%9F%E4%B8%80%E6%97%A5%E5%BF%97%E6%9C%8D%E5%8A%A1">统一日志服务</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD">数据基础设施</a></li>
<li><a href="#%E6%95%85%E9%9A%9C%E7%9B%91%E6%8E%A7">故障监控</a></li>
</ul>


<p>这里的后端基础设施主要指的是应用在线上稳定运行需要依赖的关键组件/服务等。开发或者搭建好以上的后端基础设施，一般情况下是能够支撑很长一段时间内的业务的。此外，对于一个完整的架构来说，还有很多应用感知不到的系统基础服务，如负载均衡、自动化部署、系统安全等，并没有包含在本文的描述范围内。</p>

<!--more-->


<h2><a name='Api网关'></a>Api网关</h2>

<p>在移动app的开发过程中，通常后端提供的接口需要以下功能的支持：</p>

<ul>
<li>负载均衡</li>
<li>api访问权限控制</li>
<li>用户鉴权</li>
</ul>


<p>一般的做法，使用nginx做负载均衡，然后在每个业务应用里做api接口的访问权限控制和用户鉴权，更优化一点的方式则是把后两者做成公共类库供所有业务调用。但从总体上来看，这三种特性都属于业务的公共需求，更可取的方式则是集成到一起作为一个服务，既可以动态地修改权限控制和鉴权机制，也可以减少每个业务集成这些机制的成本。这种服务就是Api网关(<a href="http://blog.csdn.net/pzxwhc/article/details/49873623">http://blog.csdn.net/pzxwhc/article/details/49873623</a>)，可以选择自己实现，也可以使用开源软件实现，如<a href="https://getkong.org/">Kong</a>。如下图所示：</p>

<p><img src="//images/blog_images/server_basic_stack/api_gw.png" alt="api_gw.png" /></p>

<p>但是以上方案的一个问题是由于所有api请求都要经过网关，它很容易成为系统的性能瓶颈。因此，可以采取的方案是：去掉api网关，让业务应用直接对接统一认证中心，在基础框架层面保证每个api调用都需要先通过统一认证中心的认证，这里可以采取缓存认证结果的方式避免对统一认证中心产生过大的请求压力。</p>

<h2><a name='业务应用和后端基础框架'></a>业务应用和后端基础框架</h2>

<p>业务应用分为：在线业务应用和内部业务应用。</p>

<ul>
<li>在线业务应用：直接面向互联网用户的应用、接口等，典型的特点就是：请求量大、高并发、高可用、对故障的容忍度低。</li>
<li>内部业务应用：这个是面向公司内部的应用。比如，内部数据管理平台、广告投放平台等。相比起在线业务应用，其特点: 数据保密性高、压力小、并发量小、允许故障的发生。</li>
</ul>


<p>业务应用基于后端的基础框架开发，针对Java后端来说，应该有的几个框架如下：</p>

<ul>
<li>MVC框架：从十年前流行的Struts1、2到现在最为推崇的SpringMVC、Jersey以及国人开发的JFinal、阿里的WebX等等，这些框架尤其是后面流行的这些都是各有千秋的。选型的主要因素是看你的团队是否有一个对某框架能够做二次开发、定制的人在。很多时候，针对这些通用的框架，你是需要做一些特定的开发才能满足特定的需求的。比如，很多团队传递参数使用的都是UnderScore的命名法(下划线连接单词)，但是Java中确是使用LowCamel命名的。对于SpringMVC，可以通过注解的alias来指定，但这样需要对每一个参数都要指定alias有点效率太低，此外ModelAttribute也不支持别名，更好的方式是在框架层面统一对参数做Camel命名的转换达到目的。</li>
<li>IOC框架：ioc带来的好处无须多言。目前Java中最为流行的Spring自诞生就天然支持IOC。</li>
<li>ORM框架：MyBatis是目前最为流行的orm框架。此外，Spring ORM中提供的JdbcTemplate也很不错。当然，对于分库分表、主从分离这些需求，一般就需要实现自己的ORM框架来支持了，像阿里的tddl。此外，为了在服务层面统一解决分库分表、主从分离、主备切换、缓存、故障恢复等问题，很多公司都是有自己的数据库中间件的，比如阿里的Cobar、360的Atlas、网易的DDB，还有官方提供的<a href="http://downloads.mysql.com/archives/proxy/">MySQL Proxy</a>以及开源的<a href="https://github.com/MyCATApache/Mycat-Server">MyCat</a>、<a href="https://github.com/flike/kingshard">kingshard</a>和收费的<a href="http://www.onexsoft.com/?page_id=3391">oneproxy</a>。目前，线上有一定规模使用的应该是kingshard，当然如果不缺钱也可以上oneproxy。</li>
<li>缓存框架：缓存框架主要指的是对redis、memcached这些缓存服务器的操作统一封装，一般使用Spring的RedisTemplate即可，也可以使用jedis做自己的封装，支持客户端分布式方案、主从等。</li>
<li>JavaEE应用性能检测框架：对于线上的JavaEE应用，需要有一个统一的框架集成到每一个业务中检测每一个请求、方法调用、jdbc连接、redis连接等的耗时、状态等。<a href="http://www.oschina.net/p/jwebap">jwebap</a>是一个可以使用的性能检测工具，但由于其已经很多年没有更新，有可能的话建议基于此项目做二次开发。</li>
</ul>


<p>一般来说，以上几个框架即可以完成一个后端应用的雏形。</p>

<p>对于这些框架来说，最为关键的是根据团队技术构成选择最合适的，有能力开发自己的框架则更好。此外，这里需要提供一个后端应用的模板或生成工具(如maven的archetype)给团队成员使用，可以让大家在开发新的应用的时候，迅速的生成雏形应用，而无需再做一些框架搭建的重复性劳动。</p>

<h2><a name='缓存、数据库、搜索引擎、消息队列'></a>缓存、数据库、搜索引擎、消息队列</h2>

<p>缓存、数据库、搜索引擎、消息队列这四者都是应用依赖的后端基础服务，他们的性能直接影响到了应用的整体性能，有时候你代码写的再好也许就是因为这些服务导致应用性能无法提升上去。</p>

<h3>缓存</h3>

<p>如缓存五分钟法则所讲：如果一个数据频繁被访问，那么就应该放内存中。这里的缓存就是一种读写效率都非常高的存储方案，能够应对高并发的访问请求，通常情况下也不需要持久化的保证。但相对其他存储来说，缓存一般是基于内存的，成本比较昂贵，因此不能滥用。</p>

<p>缓存可以分为：本地缓存和分布式缓存。</p>

<ul>
<li>本地缓存：主要指的是内存中的缓存机制。在Java中，Google Guava中就提供了本地缓存的实现机制。当然使用java的ConncurrentHashMap你也可以实现自己的本地缓存方案。</li>
<li>分布式缓存：指的单独的缓存服务。几年前比较流行的是memcached，但其只是一个KV的存储，支持的数据结构太少。现在最为流行的就是Redis，能够支持丰富的数据结构，基于事件驱动的单线程非阻塞IO也能够应对高并发的场景。集群方案除了官方的redis cluster, 目前比较流行的还有豌豆荚的<a href="https://github.com/wandoulabs/codis">codis</a>、twitter的<a href="https://github.com/twitter/twemproxy">twemproxy</a>。</li>
</ul>


<p>对于缓存的使用，需要注意以下几点：</p>

<ul>
<li>缓存的失效机制：当给某一个key设置了有效期，那么缓存何时对此key进行删除呢？一般来说会有以下几种方式：

<ul>
<li>守护进程定时去扫描key，找到已经失效的key，然后删除</li>
<li>读取key的时候先去判断key是否失效，如果失效则删除并返回空。</li>
</ul>
</li>
<li>缓存的淘汰机制：是当缓存内存达到上限时如何删除缓存中的key。Redis提供了以下数据淘汰策略：

<ul>
<li>volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰</li>
<li>volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰</li>
<li>volatile-random：从已设置过期时间的数据集中任意选择数据淘汰</li>
<li>allkeys-lru：从数据集中挑选最近最少使用的数据淘汰</li>
<li>allkeys-random：从数据集中任意选择数据淘汰</li>
<li>no-enviction（驱逐）：禁止驱逐数据</li>
</ul>


<p>  对于其具体的实现机制，可以参考<a href="http://redisbook.com/">《Redis设计与实现》</a>一书</p></li>
<li>缓存的更新机制: 通常来说有四种方式：Cache aside, Read through, Write through, Write behind caching，具体的可见陈皓大神的这篇总结：<a href="http://coolshell.cn/articles/17416.html">缓存更新的套路</a>。</li>
<li>缓存的服务过载保护：缓存的服务过载指的是由于缓存失效，而引起后端服务的压力骤增，进一步产生雪崩效应。这个现象和缓存更新是相关的，采取何种策略在缓存失效的时候去更新缓存直接决定了服务过载的保护机制。通常的分为客户端和服务端的应对方案。前者的方案有：基于超时的简单模式、基于超时的常规模式、基于刷新的简单模式、基于刷新的常规模式、基于刷新的续费模式。后者的方案则是很常见的流量控制和服务降级。具体的可以看美团技术团队总结的这篇文章：<a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651745239&amp;idx=1&amp;sn=60490558770ade79fd9f1e88f9c7c0ac&amp;scene=1&amp;srcid=0617o5PapWXlKUP4OxSzA7KE#rd">Cache应用中的服务过载案例研究</a>。</li>
</ul>


<h3>数据库</h3>

<p>数据库是后端开发中非常常见的一个服务组件。对于数据库的选型，要根据业务的特点和数据结构的特点来决定。</p>

<p>从存储介质上，数据库可以分为：</p>

<ul>
<li>内存数据库： 数据主要存储在内存中，同时也可以采取措施对数据进行持久化到硬盘中。如Redis、H2DB的内存模式。对于这种数据库，由于内存成本昂贵，因此一定要做好存储的量化分析、容量预估，防止内存不足造成服务不可用。</li>
<li>硬盘数据库：数据存储在硬盘上的这种数据库是最为常见的。MySQL、Oracle、Postgresql、HBASE、H2DB、SqlLite等等都是硬盘数据库。此外，<a href="https://github.com/ideawu/ssdb">SSDB</a>是基于SSD硬盘的KV数据库，支持的数据接口很丰富，是Redis的另外一个选择。</li>
</ul>


<p>从存储数据类型、数据模式上，数据库可以分为：</p>

<ul>
<li>关系型数据库：MySQL、Oracle、Postgresql都是关系型数据库的，是采用关系模型(关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织)来组织数据的数据库。</li>
<li>非关系型数据库：非关系型数据库是相对关系型数据库来讲的。以键值对存储，且结构不固定，每一个元组可以有不一样的字段，每个元组可以根据需要增加一些自己的键值对，这样就不会局限于固定的结构，可以减少一些时间和空间的开销。但是，其没有关系型数据库那种严格的数据模式，并不适合复杂的查询以及需要强事务管理的业务。非关系型数据库又可以分为：

<ul>
<li>KV数据库：主要以(key,value)键值对存储数据的数据库。以Redis、RocksDB(levelDB)、SSDB为代表。</li>
<li>文档数据库：总体形式上也是键值对的形式，但是值里面又可以有各种数据结构：数组、键值对、字符串等等。以mongodb、couchdb为代表。</li>
<li>列数据库：也叫作稀疏大数据库，一般是用来存储海量数据的。相对于行数据库，这种数据库是以列为单位存储数据在介质上的。以Hbase、Cassendra为代表。</li>
</ul>
</li>
</ul>


<p>和数据库相关的一个很重要的就是数据库的索引。有一种说法是：“掌握了索引就等于掌握了数据库”。暂且不去评判此说法是否真的准确，但索引的确关系着数据库的读写性能。需要对数据库的索引原理做到足够的了解才能更好的使用各种数据库。通常来说，Mysql、Oracle、Mongodb这些都是使用的B树作为索引，是考虑到传统硬盘的特点后兼顾了读写性能以及范围查找需求的选择，而Hbase用得LSM则是为了提高写性能对读性能做了牺牲。</p>

<h3>搜索引擎</h3>

<p>搜索引擎也是后端应用中一个很关键的组件，尤其是对内容类、电商类的应用，通过关键词、关键字搜索内容、商品是一个很常见的用户场景。比较成熟的开源搜索引擎有Solr和Elasticsearch，很多中小型互联网公司搜索引擎都是基于这两个开源系统搭建的。它们都是基于Lucence来实现的，不同之处主要在于termIndex的存储、分布式架构的支持等等。</p>

<p>对于搜索引擎的使用，从系统熟悉、服务搭建、功能定制，需要花费较长时间。在这个过程中，需要注意以下问题：</p>

<ul>
<li>搜索引擎与公司现有数据系统的集成。现有的持久化、供搜索的数据的载体是什么, 如何让搜索引擎在全量和增量建索引过程中无缝集成原来的数据载体，才能发挥搜索引擎自身的实时性, 水平扩展性(性能与容量和机器数量成正比)等优势。</li>
<li>和数据库一样，对搜索引擎的索引机制也需要做到深入的了解。</li>
</ul>


<p>更为详细的对于搜索引擎的工程化实践可以参考有赞工程师的这篇文章：<a href="http://www.cnblogs.com/hsydj/p/5303050.html">有赞搜索引擎实践(工程篇)</a></p>

<p>另外，搜索引擎还可以用在数据的多维分析上，就是<a href="https://www.growingio.com/">GrowingIO</a>、<a href="https://mixpanel.com/">MixPanel</a>中的可以任意维度查询数据报表的功能。当然，<a href="http://druid.io/">druid</a>也许是一个更好的实现多维分析的方案，官方也有其与es的比较：<a href="http://druid.io/docs/latest/comparisons/druid-vs-elasticsearch.html">http://druid.io/docs/latest/comparisons/druid-vs-elasticsearch.html</a>。</p>

<h3>消息队列</h3>

<p>软件的组织结构，从开始的面向组件到SOA、SAAS是一个逐渐演变的过程。而到了今天微服务盛行的时代，你都不好意思说自己的系统只是单一的一个系统而没有解耦成一个个service。当然，小的系统的确没有拆分的必要性，但一个复杂的系统拆成一个个service做微服务架构确实是不得不做的事情。</p>

<p>那么问题就来了，service之间的通信如何来做呢？使用什么协议？通过什么方式调用？都是需要考虑的问题。</p>

<p>先抛开协议不谈，service之间的调用方式可以分为同步调用以及异步调用。同步调用的方式无需多说，那么异步调用是怎么进行的呢？一种很常见的方式就是使用消息队列，调用方把请求放到队列中即可返回，然后等待服务提供方去队列中去获取请求进行处理，然后把结果返回给调用方即可（可以通过回调）。</p>

<p>异步调用就是消息中间件一个非常常见的应用场景。此外，消息队列的应用场景还有以下：</p>

<ul>
<li>解耦：一个事务，只关心核心的流程，需要依赖其他系统但不那么重要的事情，有通知即可，无须等待结果。</li>
<li>最终一致性：指的是两个系统的状态保持一致，要么都成功，要么都失败，可以有一定的延迟，只要最终达到一致性即可。</li>
<li>广播：这是消息队列最基本的功能。生产者只需要发布消息，无须关心有哪些订阅者来消费消息。</li>
<li>错峰与流控：当上下游系统处理能力不同的时候就需要类似消息队列的方式做为缓冲区来隔开两个系统。</li>
</ul>


<p>目前主流的消息队列软件，主要有以下几种：</p>

<ul>
<li>ActiveMQ：Java中最为简单的消息队列，是对JMS的实现，没有规定消息的顺序、安全、重发等特性。</li>
<li>RabbitMQ：是对AMQP协议的实现，对于消息的顺序性、安全、重发等都做了很好的支持。比较适合不允许数据丢失、有事务需求的业务场景下的消息传输。</li>
<li>Kafka：是基于Log的消息队列，底层依赖于文件的顺序读取，是append-only的。适合对数据丢失不敏感、强调性能的一些海量日志传输场景中。是最近几年大数据领域很火的一个技术。</li>
<li>ZeroMQ：是一个网络编程的Pattern库，将常见的网络请求形式（分组管理，链接管理，发布订阅等）模式化、组件化，简而言之socket之上、MQ之下。对于MQ来说，网络传输只是它的一部分，更多需要处理的是消息存储、路由、Broker服务发现和查找、事务、消费模式（ack、重投等）、集群服务等。</li>
</ul>


<h2><a name='文件存储'></a>文件存储</h2>

<p>不管是业务应用、依赖的后端服务还是其他的各种服务，最终还是要依赖于底层文件存储的。通常来说，文件存储需要满足的特性有：可靠性、容灾性、稳定性，即要保证存储的数据不会轻易丢失，即使发生故障也能够有回滚方案，也要保证高可用率。在底层可以采用传统的RAID作为解决方案，再上一层，目前hadoop的hdfs则是最为普遍的分布式文件存储方案，当然还有NFS、Samba这种共享文件系统也提供了简单的分布式存储的特性。</p>

<p>此外，如果文件存储确实成为了应用的瓶颈或者必须提高文件存储的性能从而提升整个系统的性能时，那么最为直接和简单的做法就是抛弃传统机械硬盘，用SSD硬盘替代。像现在很多公司在解决业务性能问题的时候，最终的关键点往往就是SSD。这也是用钱换取时间和人力成本最直接和最有效的方式。在数据库部分描述的SSDB就是对LevelDB封装之后，利用SSDB的特性的一种高性能KV数据库。</p>

<p>至于HDFS，如果要使用上面的数据，是需要通过hadoop的。类似xx on yarn的一些技术就是将非hadoop技术跑在hdfs上的解决方案(当然也是为了使用MR)。</p>

<h2><a name='统一认证中心'></a>统一认证中心</h2>

<p>统一认证中心，主要是对app用户、内部用户、app等的认证服务，包括</p>

<ul>
<li>用户的注册、登录验证、token鉴权</li>
<li>内部信息系统用户的管理和登录鉴权</li>
<li>App的管理，包括app的secret生成，app信息的验证(如验证接口签名)等。</li>
</ul>


<p>之所以需要统一认证中心，就是为了能够集中对这些所有app都会用到的信息进行管理，也给所有应用提供统一的认证服务。尤其是在有很多业务需要共享用户数据的时候，构建一个统一认证中心是非常必要的。此外，通过统一认证中心构建移动app的单点登录也是水到渠成的事情(模仿web的机制，将认证后的信息加密存储到本地磁盘中供多个app使用)。</p>

<h2><a name='单点登录系统'></a>单点登录系统</h2>

<p>目前很多大的在线web网站都是有单点登录系统的，通俗的来说就是只需要一次用户登录，就能够进入多个业务应用(权限可以不相同)，非常方便用户的操作。而在移动互联网公司中，内部的各种管理、信息系统同样也需要单点登录系统。目前，比较成熟的、用的最多的单点登录系统应该是耶鲁大学开源的<a href="https://github.com/Jasig/cas">CAS</a>, 可以基于<a href="https://github.com/apereo/cas/tree/master/cas-server-webapp">https://github.com/apereo/cas/tree/master/cas-server-webapp</a>来定制开发的。此外，国人开源的<a href="http://git.oschina.net/juapk/kisso">kisso</a>的这个也不错。基本上，单点登录的原理都类似下图所示：</p>

<p><img src="//images/blog_images/server_basic_stack/cas.jpg" alt="cas" /></p>

<h2><a name='统一配置中心'></a>统一配置中心</h2>

<p>在Java后端应用中，一种读写配置比较通用的方式就是将配置文件写在propeties、yaml、HCON文件中，修改的时候只需要更新文件重新部署即可，可以做到不牵扯代码层面改动的目的。统一配置中心，则是基于这种方式之上的统一对所有业务或者基础后端服务的相关配置文件进行管理的统一服务, 具有以下特性：</p>

<ul>
<li>能够在线动态修改配置文件并生效</li>
<li>配置文件可以区分环境(开发、测试、生产等)</li>
<li>使用方便: 在java中可以通过注解、xml配置的方式引入相关配置</li>
</ul>


<p><a href="https://github.com/knightliao/disconf">disconf</a>是可以在生产环境使用的一个方案，也可能根据自己的需求开发自己的配置中心(可以选择zookeeper作为配置存储)。</p>

<h2><a name='服务治理框架'></a>服务治理框架</h2>

<p>对于外部API调用或者客户端对后端api的访问，可以使用http协议或者说restful(当然也可以直接通过最原始的socket来调用)。但对于内部服务间的调用，一般都是通过RPC机制来调用的。目前主流的RPC协议有：</p>

<ul>
<li>RMI</li>
<li>Hessian</li>
<li>Thrift</li>
<li>Dubbo</li>
</ul>


<p>这些RPC协议各有优劣点，需要针对业务需求做出相应的最好的选择。</p>

<p>这样，当你的系统服务在逐渐增多，RPC调用链越来越复杂，很多情况下，需要不停的更新文档来维护这些调用关系。一个对这些服务进行管理的框架可以大大节省因此带来的繁琐的人力工作。</p>

<p>传统的ESB(企业服务总线)本质就是一个服务治理方案，但esb作为一种proxy的角色存在于client和server之间，所有请求都需要经过esb，使得esb很容易成为性能瓶颈。因此，基于传统的esb，更好的一种设计如下图所示：</p>

<p><img src="//images/blog_images/server_basic_stack/esb.png" alt="esb" /></p>

<p>如图，以配置中心为枢纽，调用关系只存在于client和提供服务的server之间，就避免了传统esb的性能瓶颈问题。对于这种设计，esb应该支持的特性如下：</p>

<ul>
<li>服务提供方的注册、管理</li>
<li>服务消费者的注册、管理</li>
<li>服务的版本管理、负载均衡、流量控制、服务降级等</li>
<li>服务的容错、熔断等</li>
</ul>


<p>阿里开源的<a href="https://github.com/alibaba/dubbo">dubbo</a>则对以上做了很好的实现，也是目前很多公司都在使用的方案。但由于某些原因，dubbo现已不再维护，推荐大家使用当当后来维护的<a href="https://github.com/dangdangdotcom/dubbox">dubbox</a>。</p>

<h2><a name='统一调度中心'></a>统一调度中心</h2>

<p>在很多业务中，定时调度是一个非常普遍的场景，比如定时去抓取数据、定时刷新订单的状态等。通常的做法就是针对各自的业务依赖Linux的cron机制或者java中的quartz。统一调度中心则是对所有的调度任务进行管理，这样能够统一对调度集群进行调优、扩展、任务管理等。<a href="https://github.com/azkaban/azkaban">azkaban</a>和<a href="https://github.com/yahoo/oozie">oozie</a>是hadoop的流式工作管理引擎，也可以作为统一调度中心来使用。当然，你也可以使用cron或者quartz来实现自己的统一调度中心。</p>

<ul>
<li>根据cron表达式调度任务</li>
<li>动态修改、停止、删除任务</li>
<li>支持任务工作流：比如一个任务完成之后再执行下一个任务</li>
<li>任务支持脚本、代码、url等多种形式</li>
<li>任务执行的日志记录、故障报警</li>
</ul>


<p>对于Java的quartz这里需要说明一下：这个quartz需要和spring quartz区分，后者是spring对quartz框架的简单实现也是目前使用的最多的一种调度方式。但是，其并没有做高可用集群的支持。而quartz虽然有集群的支持，但是配置起来非常复杂。现在很多方案都是使用zookeeper来实现spring quartz集群的。这里有一个国人开源的<a href="http://git.oschina.net/uncode/uncode-schedule">uncode-shcedule</a>对此实现的还不错，可以根据自己的业务需求做二次开发。</p>

<h2><a name='统一日志服务'></a>统一日志服务</h2>

<p>日志是开发过程必不可少的东西。有时候，打印日志的时机、技巧是很能体现出工程师编码水平的。毕竟，日志是线上服务能够定位、排查异常最为直接的信息。</p>

<p>通常的，将日志分散在各个业务中非常不方便对问题的管理和排查。统一日志服务则使用单独的日志服务器记录日志，各个业务通过统一的日志框架将日志输出到日志服务器上。</p>

<p>可以通过实现log4j后者logback的appender来实现统一日志框架，然后通过RPC调用将日志打印到日志服务器上。</p>

<h2><a name='数据基础设施'></a>数据基础设施</h2>

<p>数据是最近几年非常火的一个领域。从《精益数据分析》到《增长黑客》，都是在强调数据的非凡作用。很多公司也都在通过数据推动产品设计、市场运营、研发等。详细的可见之前的一篇<a href="http://www.rowkey.me/blog/2016/02/23/data-talk/">《数据杂谈》</a>，对数据相关的东西做过一些总结。这里需要说明的一点是，只有当你的数据规模真的到了单机无法处理的规模才应该上大数据相关技术，千万不要为了大数据而大数据。很多情况下使用单机程序+mysql就能解决的问题非得上hadoop即浪费时间又浪费人力。</p>

<p>这里需要补充一点的是，对于很多公司，尤其是离线业务并没有那么密集的公司，在很多情况下大数据集群的资源是被浪费的。因此诞生了<strong>xx on yarn</strong>一系列技术让非hadoop系的技术可以利用大数据集群的资源，能够大大提高资源的利用率，如Docker on yarn(Hulu的VoidBox)。</p>

<h3>数据高速公路</h3>

<p>接着上面讲的统一日志服务，其输出的日志最终是变成数据到数据高速公路上供后续的数据处理程序消费的。这中间的过程包括日志的收集、传输。</p>

<ul>
<li><p>收集：统一日志服务将日志打印在日志服务上之后，需要日志收集机制将其集中起来。目前，常见的日志收集方案有：scribe、Chukwa、Kakfa和Flume。对比如下图所示：</p>

<p>  <img src="//images/blog_images/server_basic_stack/data-collect.png" alt="dc" /></p></li>
<li><p>传输：通过消息队列将数据传输到数据处理服务中。对于日志来说，通常选择kafka这种消息队列即可。</p></li>
</ul>


<p>此外，这里还有一个关键的技术就是数据库和数据仓库间的数据同步问题，即将需要分析的数据从数据库中同步到诸如hive这种数据仓库时使用的方案。比较简单的、用的也比较多的可以使用<a href="http://hortonworks.com/apache/sqoop/">sqoop</a>进行基于时间戳的数据同步，此外，阿里开源的<a href="https://github.com/alibaba/canal">canal</a>实现了基于binlog增量同步，更加适合通用的同步场景，但是基于canal你还是需要做不少的业务开发工作的。推荐另一款国人开源的<a href="http://git.oschina.net/qiangzigege/MySQL-Binlog">MySQL-Binlog</a>，原理和canal类似，默认提供了任务的后台管理功能，只需要实现接收到binlog后的处理逻辑即可。</p>

<h3>离线数据分析</h3>

<p>离线数据分析是可以有延迟的，一般针对是非实时需求的数据分析工作，产生的也是T-1的报表。目前最常用的离线数据分析技术除了hadoop还有spark。相比hadoop，spark性能上有很大优势，当然对硬件资源要求也高。</p>

<p>对于hadoop，传统的MR编写很复杂，也不利于维护，可以选择使用hive来用sql替代编写mr，但是前提务必要对hive的原理做到了解。可以参见美团的这篇博文来学习:<a href="http://tech.meituan.com/hive-sql-to-mapreduce.html">Hive SQL的编译过程</a>。而对于spark，也有类似hive的spark sql。</p>

<p>此外，对于离线数据分析，还有一个很关键的就是数据倾斜问题。所谓数据倾斜指的是region数据分布不均，造成有的结点负载很低，而有些却负载很高，从而影响整体的性能。因此，处理好数据倾斜问题对于数据处理是很关键的。对于hive的数据倾斜，可见:<a href="http://www.cnblogs.com/ggjucheng/archive/2013/01/03/2842860.html">hive大数据倾斜总结</a>。对于spark的倾斜问题，可见：<a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651745207&amp;idx=1&amp;sn=3d70d59cede236eb1cb4f7374387a235&amp;scene=0#rd">Spark性能优化指南——高级篇</a>。</p>

<h3>实时数据分析</h3>

<p>相对于离线数据分析，实时数据分析也叫在线数据分析，针对的是对数据有实时要求的业务场景，如广告结算、订单结算等。目前，比较成熟的实时技术有storm和spark streaming。相比起storm，spark streaming其实本质上还是基于批量计算的。如果是对延迟很敏感的场景，还是应该使用storm。</p>

<p>对于实时数据分析，需要注意的就是实时数据处理结果写入存储的时候，要考虑并发的问题，虽然对于storm的bolt程序来说不会有并发的问题，但是写入的存储介质是会面临多任务同时读写的。通常采用的方案就是采用时间窗口的方式对数据做缓冲后批量写入。</p>

<p>此外，实时数据处理一般情况下都是基于增量处理的，相对于离线来说并非可靠的，一旦出现故障(如集群崩溃)或者数据处理失败，是很难对数据恢复或者修复异常数据的。因此结合离线+实时是目前最普遍采用的数据处理方案。<a href="http://www.csdn.net/article/2014-07-08/2820562-Lambda-Linkedln">Lambda架构</a>就是一个结合离线和实时数据处理的架构方案。</p>

<h3>数据即席分析</h3>

<p>离线和实时数据分析产生的一些报表是给数据分析师、产品经理参考使用的，但是很多情况下，线上的程序并不能满足这些需求方的需求。这时候就需要需求方自己对数据仓库进行查询统计。针对这些需求方，SQL上手容易、易描述等特点决定了其可能是一个最为合适的方式。因此提供一个SQL的即席查询工具能够大大提高数据分析师、产品经理的工作效率。Presto、Impala、Hive都是这种工具。如果想进一步提供给需求方更加直观的ui操作界面，可以搭建内部的<a href="https://github.com/cloudera/hue">Hue</a>。</p>

<p><img src="//images/blog_images/server_basic_stack/hue.jpg" alt="hue" /></p>

<h2><a name='故障监控'></a>故障监控</h2>

<p>对于面向用户的线上服务，发生故障是一件很严重的事情。因此，做好线上服务的故障检测告警是一件非常重要的事情。可以将故障监控分为以下两个层面的监控：</p>

<ul>
<li>系统监控：主要指的对主机的带宽、cpu、内存、硬盘、io等硬件资源的监控。这可以使用开源的nagios、cacti等开源软件进行监控。目前，市面上也有很多第三方服务能够提供对于主机资源的监控，如监控宝等。对于分布式服务集群(如hadoop、storm、kafka、flume等集群)的监控则可以使用<a href="http://ganglia.github.io/">ganglia</a>。此外，小米开源的<a href="https://github.com/open-falcon">OpenFalcon</a>也很不错，涵盖了系统监控、JVM监控等，也支持自定义的监控机制。</li>
<li>业务监控：是在主机资源层面以上的监控，比如app的pv、uv数据异常、交易失败等。需要业务中加入相关的监控代码，比如在异常抛出的地方，加一段日志记录。</li>
</ul>


<p>监控还有一个关键的步骤就是告警。告警的方式有很多种：邮件、im、短信等。考虑到故障的重要性不同、告警的合理性、便于定位问题等因素，有以下建议：</p>

<ul>
<li>告警日志要记录发生故障的机器id，尤其是在集群服务中，如果没有记录机器id，那么对于后续的问题定位会很困难。</li>
<li>要对告警做聚合，不要每一个故障都单独进行告警，这样会对工程师造成极大的困扰。</li>
<li>要对告警做等级划分，不能对所有告警都做同样的优先级处理。</li>
<li>使用微信做为告警软件，能够在节省短信成本的情况下，保证告警的到达率。</li>
</ul>


<p>故障告警之后，那么最最关键的就是应对了。对于创业公司来说，24小时待命是必备的素质，当遇到告警的时候，需要尽快对故障做出反应，找到问题所在，并能在可控时间内解决问题。对于故障问题的排查，基本上都是依赖于日志的。只要日志打的合理，一般情况下是能够很快定位到问题所在的，但是如果是分布式服务，并且日志数据量特别大的情况下，如何定位日志就成为了难题。这里有几个方案：</p>

<ul>
<li>建立ELK(Elastic+Logstash+Kibana)日志集中分析平台，便于快速搜索、定位日志。对于ELK的介绍，可以见：<a href="https://xiequan.info/%E4%BD%BF%E7%94%A8elasticsearch-logstash-kibana%E6%90%AD%E5%BB%BA%E6%97%A5%E5%BF%97%E9%9B%86%E4%B8%AD%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%E5%AE%9E%E8%B7%B5/">使用Elasticsearch + Logstash + Kibana搭建日志集中分析平台实践</a></li>
<li>建立分布式请求追踪系统(也可以叫全链路监测系统)，对于分布式系统尤其是微服务架构，能够极大的方便在海量调用中快速定位并收集单个异常请求信息，也能快速定位一条请求链路的性能瓶颈。Google的<a href="http://www.cnblogs.com/LBSer/p/3390852.html?spm=5176.100239.blogcont58408.6.xuC3MP">Dapper</a>、唯品会的<a href="http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653547643&amp;idx=1&amp;sn=c06dc9b0f59e8ae3d2f9feb734da4459&amp;scene=1&amp;srcid=0808MaLgymxNlsh4Z31oWKUi#rd">Mercury</a>、阿里的<a href="https://bigbully.github.io/Dapper-translation/?spm=5176.100239.blogcont58408.7.xuC3MP">鹰眼</a>、新浪的<a href="http://ishare.iask.sina.com.cn/f/68869649.html">WatchMan</a>都是类似的思路。此外，<a href="https://www.zhihu.com/question/20292868">腾讯的染色日志机制</a>本质上也是在链路追踪之上根据响应信息做了染色机制。</li>
</ul>


<p><strong><em>以上是本人实践的一些经验。由于知识有限，难免有纰漏，敬请指出。</em></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[研发体系这点事]]></title>
    <link href="http://www.rowkey.me/blog/2016/08/17/dev-manage/"/>
    <updated>2016-08-17T20:13:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/08/17/dev-manage</id>
    <content type="html"><![CDATA[<p><strong><em>&ndash;本文于2016.08.23最新更新&ndash;</em></strong></p>

<p>早在读研究生的时候，自己负责着实验室的项目，就一直在思索如何建立一套简单又高效的研发管理体系，能够在保证项目高质量顺利进行的同时还能够提升团队成员的技术level。后来在自己在校的几次小的创业中，也做过一些尝试。直到毕业后进入前东家，在几个项目的参与过程中，见到了大公司的研发管理是如何进行的。直至加入目前的公司，将研发体系梳理一遍，且学且抄且实践，对这一套东西算是有了一定的实践感悟。</p>

<p>对于一个研发管理体系，其核心是围绕着产品的整个生命周期来进行的。因此，根据一个产品的生命周期，可以把研发体系划分为几个关键的环节，如图所示：</p>

<p><a href="http://www.rowkey.me/images/blog_images/dev-system-overview.png" target="_blank"><img src="http://www.rowkey.me/images/blog_images/dev-system-overview.png"/></a></p>

<p>更为具体的一个研发流程则如下图所示，标注了每一个环节的参与角色。</p>

<p><img src="//images/blog_images/prject_manage_detail.png" alt="prject_manage_detail.png" /></p>

<p>可知，即时沟通和技术提升虽然不属于研发流程中的某一个环节，但它们是贯穿整个研发体系不可或缺的一部分，有着不可替代的作用。此外，任务管理需要对任务做整个研发生命周期的管理，除了作为其中的一个关键环节，也是贯穿整个研发流程的。</p>

<ul>
<li><a href="#%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86">任务管理</a></li>
<li><a href="#%E6%96%87%E6%A1%A3%E5%8D%8F%E4%BD%9C">文档协作</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E5%8D%8F%E4%BD%9C">代码协作</a></li>
<li><a href="#%E8%B4%A8%E9%87%8F%E4%BF%9D%E8%AF%81">质量保证</a></li>
<li><a href="#%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2">自动化部署</a></li>
<li><a href="#%E6%95%85%E9%9A%9C%E7%AE%A1%E7%90%86">故障管理</a></li>
<li><a href="#%E5%8D%B3%E6%97%B6%E6%B2%9F%E9%80%9A">即时沟通</a></li>
<li><a href="#%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87">技术提升</a></li>
</ul>


<!--more-->


<h2><a name='任务管理'></a>任务管理</h2>

<p>任务管理是产品整个生命周期首要的环节，其对研发体系也是至关重要的。项目生命周期模型，传统的有五种：瀑布模型、原型模型、螺旋模型、增量模型、V模型，而现在最为流行的是迭代开发模型，敏捷开发则是采用迭代模型的一种典型项目管理方法集合。Scrum是目前敏捷开发中最为大家熟知的开发模式(XP极限编程也是一种比较常见的敏捷开发模式)，其开发流程的概览如下图所示：</p>

<p><img src="http://www.rowkey.me/images/blog_images/ScrumModel.jpg" style="width:500px"/></p>

<p>简单来说，Scrum是依赖于三种角色、四种会议的自组织、信息透明化、成员平等的一种敏捷开发流程。更为详细的描述，可参见此篇文章：<a href="http://blog.devtang.com/2014/09/13/scrum-introduction/">http://blog.devtang.com/2014/09/13/scrum-introduction/</a>。</p>

<p>除了Scrum之外，看板是最近兴起的另一种开发模式，在最近很火的美剧《硅谷》里面“魔笛手”就是采用的这种方式。看板将工作流程形象化，首先把工作细分成任务并根据需要将任务分为Pending、Analysis、Development、Test、Deploy等状态，然后根据任务的进行，在几种状态之间进行转换。对比Scrum，看板使用开发周期作为计划和过程改进的度量数据，不强调迭代的概念，也没有很强的时间期间概念，也不需要制定任何团队角色。对于看板方法论的详细介绍可见此篇文章：<a href="http://kanbanblog.com/explained/">http://kanbanblog.com/explained/</a>，<a href="http://www.jianshu.com/p/e44b1038c9cf">http://www.jianshu.com/p/e44b1038c9cf</a>这篇则做了比较形象具体的说明。这里有一点需要注意，Scrum和看板并非是对立的，它们是可以结合起来使用的。使用看板来管理每一次迭代的任务是一种可取也是很常见的精益实践。</p>

<p>依赖于任务管理方法论，市面上很多软件都做了相应的支撑，自己曾经使用过的任务管理软件如下：</p>

<ul>
<li><a href="http://www.redmine.org/">Redmine</a>: 这个是自己最开始接触的任务管理软件，使用也比较广泛。比较遗憾的是，redmine安装有点繁琐，而且基于ROR，如果需要二次开发，需要重新学习ROR。</li>
<li><a href="http://tower.im">Tower.im</a>: 这是一个任务管理云服务，界面设计的简单优雅，一目了然。很多小的私有项目，我都会用这个进行任务管理。类似的还有teambeation等。</li>
<li><a href="http://www.atlassian.com/software/jira/">Jira</a>: 这款软件是商业版的任务管理软件，对于这一块做的是非常专业的，很多大公司都在使用。但是，它是收费的。所以，如果你要用，要么付钱，要么去破解。。。</li>
<li><a href="http://www.zentao.net/">禅道</a>：这款软件最早是叫做bugfree, 是开源且主要针对Bug管理的，后面慢慢发展成现在的集任务管理、bug管理、团队管理等的项目管理软件，并开启了收费策略。总体来说，功能很全，也比较专业，但是ui上有种传统it系统的感觉，流程上也不具有现在敏捷开发的一些优势。</li>
<li><a href="https://github.com/kanboard/kanboard">Kanboard</a>: 是实现了Kanban方法论的任务管理软件。</li>
</ul>


<p>对于个人的项目，其实依赖于tower.im这种第三方云服务完全足够了。如果担心数据安全的话，那么推荐在内网搭建Kanboard进行看板任务管理。</p>

<h2><a name='文档协作'></a>文档协作</h2>

<p>研发中首当其冲的就是文档撰写，这个很多情况下都决定了项目的可维护、可管理性。有人会说现在流行的是敏捷开发，根本不需要写文档，但其实这是对敏捷的误解。敏捷开发强调的是快速试错、快速迭代，而非简单粗暴，<strong><em>对比传统开发模型虽然并不强调文档，但并不代表不需要</em></strong>。对于一个项目，从开始就需要需求文档、产品原型文档、项目进度文档等等，而到了研发这一步，在系统实现、写代码之前最好的就是先“想”再做，而“想”的一种比较好的输出形式就是文档。对于一个软件系统，一般来说需要写的文档有以下几种：</p>

<ul>
<li>系统业务流程文档：描述系统业务逻辑的文档，能清晰的说明真个业务的流程。</li>
<li>系统架构设计文档：对整个系统的架构的描述，需要包含系统的各个关键组成模块以及相关的各个关键技术点等。</li>
<li>系统功能模块概要设计/详细设计文档：对于某一个模块的流程、逻辑的描述。</li>
<li>数据DDL/DML文档: 与系统相关的数据库的DDL和DML文档，对于前者，是需要包含所有的操作的，而对于后者，必不可少的是查询语句，用来提供给DBA，来做查询sql的review，以保证索引的正确建立和查询语句的合理等。</li>
<li>系统部署文档：描述系统关键部分部署在哪里，需要做哪些配置。</li>
<li>系统发布ChangeLog：对系统每次发布的改动进行描述，包括数据库、缓存、数据队列、新增/变动了哪些依赖服务等。此外，对数据库、缓存这种关键服务的量化分析也可以写在这里。</li>
</ul>


<p>尤其对于一些相对复杂的功能来说，整理思路形成文档，不仅可以让自己逻辑清晰，也让后续维护的人能够更快地接手。当然，这些并不是死板要求的，应该根据实际的业务选择，不一定所有的文档都是必须的，也不一定要分开这几个文档写(可以将这些内容集成在一个文档中，这也是目前我经常采用的方式)。这些文档的范例可以见：<a href="https://github.com/superhj1987/awesome-tech-collections/tree/master/document">https://github.com/superhj1987/awesome-tech-collections/tree/master/document</a>。</p>

<p>而对于文档撰写协作的方式，我自己经历过的有以下几种：</p>

<ul>
<li>使用word撰写各种文档，提交到svn等版本管理工具上</li>
<li>使用google doc进行协作</li>
<li>使用word撰写文档，然后提交到项目管理软件中进行管理</li>
<li>使用markdown撰写文档，提交到版本管理工具上</li>
</ul>


<p>我自己比较推崇的是使用markdown撰写文档，然后使用git、svn版本管理工具或者是其他团队协作工具做版本管理。之所以使用markdown, 能够极大地节省使用word时调各种格式、样式耗费的时间。对于程序员来说真的是如虎添翼。如果是对文档多人协同编辑有刚需的团队，可以选择使用google doc或者国内的石墨(<a href="http://shimo.im">http://shimo.im</a>)。</p>

<p>此外，在移动app开发中，还有一个非常关键的文档就是<strong>api文档</strong>，是服务端提供给客户端调用接口的说明文档。比较简单直接的方法就是定制一套api文档模板，然后在写接口代码之前或者之后，按照模板编写接口文档。此外，可以实现一套根据源码自动生成文档的机制，在代码编写的同时就能自动生成相应的接口说明文档。在使用Spring MVC开发的后端应用中，个人推荐<a href="https://github.com/springfox/springfox">SpringFox</a>，使用此项目能够通过在Controller中加入相应的注解信息从而自动生成Api接口文档，同时也提供了在线调试的功能，极大减少了api文档的工作量。</p>

<h2><a name='代码协作'></a>代码协作</h2>

<p>对于一个技术团队，最最关键的肯定是写代码。一个人单打独斗那倒好说，但是这就像篮球场上，一对一靠个人硬实力，但是5对5，那就不仅仅是一个人实力强就赢得了的了。因此对于技术团队来说，代码协作是至关重要的一个部分。</p>

<ul>
<li><p>代码版本管理：Git + SVN</p>

<p>  几年前最流行的代码版本管理工具是svn（当然此前，更加古老的还有cvs之流），的确为程序员们的代码管理带来了很多便捷。但到了现在，相比起这种集中式代码管理，目前最为火热的当属git这种分布式代码管理工具，在Linux上直接搭建git服务器来构建项目的git系统的。而这几年随着Github以及类似系统的涌现，对于很多私人项目我都是采用oschina或者gitcafe提供的git私有代码管理来做代码版本管理的。当然，对于公司来说，有很多开源类github系统可以搭建在企业内网。详细的可以参见：<a href="http://www.rowkey.me/blog/2015/11/13/your-own-github/">搭建自己的github</a>。当然，对比svn，git也是有缺点的。无法天然的支持对于目录级别的权限管理和基于目录的版本管理操作是目前不得不结合svn和git一起使用的重要原因。通常情况下，可以使用git做版本管理，辅以svn做基于目录级别的发布包管理。</p></li>
<li><p>代码分支/Tag管理： Git Flow</p>

<p>  其实分支/Tag管理是代码版本管理包含的内容，之所以单独出来，是因为对于分支的使用其实还是有一定的原则和技巧的。并非如很多人一样，所有项目就一个master分支，所有修改都往这里塞。目前，最为流行的一种基于分支的工作方式就是:Git flow。介绍可以见: <a href="http://www.ituring.com.cn/article/56870">基于git的源代码管理模型——git flow</a>。简单概括就是：</p>

<ul>
<li>master和develop作为主分支。主分支是所有开发活动的核心分支。所有的开发活动产生的输出物最终都会反映到主分支的代码中。master是可以随时发布的分支，而develop则时刻保持最新的开发代码。</li>
<li>辅助分支是用于组织解决特定问题的各种软件开发活动的分支。辅助分支主要用于组织软件新功能的并行开发、简化新功能开发代码的跟踪、辅助完成版本发布工作以及对生产代码的缺陷进行紧急修复工作。这些分支与主分支不同，通常只会在有限的时间范围内存在。包括：

<ul>
<li>用于开发新功能时所使用的feature分支；</li>
<li>用于辅助版本发布的release分支；</li>
<li>用于修正生产代码中的缺陷的hotfix分支。
对于此种开发模型，这里也提供了一个命令行工具：<a href="https://github.com/nvie/gitflow">https://github.com/nvie/gitflow</a></li>
</ul>
</li>
</ul>
</li>
<li><p>代码质量保证：结对编程 + 定期review + PR目前一种比较好的方式。结对编程这个是一个老生常谈的方式，两个人共同承担某一开发任务，互相保证对方的代码质量，在很大程度上能够提高代码质量。而定期review则是让团队所有的成员都能够参与到这个过程中，不仅仅能够保证被review者的代码质量，也能够让团队成员学习到好的代码是怎样的而差的代码又是怎样的。PR是Pull Request的简写，当开发完成的代码提交到主分支时，需要发起pull request，此时团队负责人需要review相关代码，确保没有问题之后，才能accept此次pr。当然，上面讲述的是如何通过人来保证代码质量。除此之外，还可以通过技术上的手段在一定程度上保障代码的质量，这一部分在后续的自动化测试机制会讲述。</p></li>
</ul>


<p>此外，在移动app项目中，一个很普遍的问题就是：<strong>在定义好Api文档之后，客户端如何在后端并没有完成接口开发的情况下开发或者调试程序？</strong>这里有两种方案：</p>

<ul>
<li>客户端做好接口封装，在后端接口未完成前，客户端不经过网络io直接返回静态格式数据。这种方式最好是由客户端定义接口格式数据。</li>
<li>后端将示例接口返回数据写在文件里，接口直接返回静态文件数据。此种方式，由后端定义接口数据格式。另外，有一个开源的工具: <a href="https://github.com/Runscope/httpbin">httpbin</a>可以用来提供接口返回指定格式的数据，中文介绍可见: <a href="https://blog.phpgao.com/how-to-httpbin.html">https://blog.phpgao.com/how-to-httpbin.html</a>。</li>
</ul>


<p>关于客户端和后端的接口代码协作，还有一个Chrome插件<a href="https://www.getpostman.com/">POSTMAN</a>可以使用。后端可以使用此插件在编写完接口后进行自我功能测试，测试无误后可以将接口以文件或者url的形式分享给客户端供客户端参考和调试。</p>

<h2><a name='质量保证'></a>质量保证</h2>

<p>当代码开发完成之后，需要质量保证机制的介入来保证功能的正常运行，从而保证代码是可发布的。一般来说，质量保证的手段就是测试，分为：</p>

<ul>
<li>代码质量测试</li>
<li>功能测试</li>
<li>性能测试</li>
</ul>


<p>代码质量测试一般是在编译打包代码之前进行，通常是自动化进行的。针对Java项目，自动化代码质量测试可以分为以下几步：</p>

<ul>
<li>源代码规范检查：对于Java来说，代码规范的检查一般使用checkstyle来检查。默认的规范非常严格，这里大家可以根据需要放宽一些规范。</li>
<li>源代码静态质量检查: 常用的工具是pmd, 可以检查Java源文件中的潜在问题, 比如空try/catch/finally/switch语句块等。</li>
<li>字节码bug检查：常用工具是findbugs,基于Bug Patterns概念，查找javabytecode（.class文件）中的潜在bug。如NullPoint空指针检查、没有合理关闭资源、字符串相同判断错（==，而不是equals）。</li>
<li>单元测试：使用junit即可，当然在这里当使用mvn时，其test phrase会默认生成测试报告到${project.build.directory}/surefile-reports文件夹中。这里建议使用coverage生成单元测试报告，其中一个关键的单元测试覆盖率指标达到98%以上才为合格(根据需要自己调整即可)。</li>
</ul>


<p>以上提到的工具，都是有maven插件的。通常情况下，也推荐使用这些工具的maven插件来调用。目前流行的自动化ci工具jenkins、QuickBuild等结合各种丰富的插件可以提供这些功能，将他们集成到一个测试流程并形成最终的测试结果报表。</p>

<p>在代码发布到线上环境之前，一个关键的步骤就是功能测试，通常都是工程师来进行的。需要测试工程师根据产品需求，形成测试用例，然后根据这些用例做相应的测试。测试用例的一个模板如下：</p>

<table>
<thead>
<tr>
<th>用例ID </th>
<th> 功能名称 </th>
<th> 用例名称 </th>
<th> 测试数据 </th>
<th> 前置条件 </th>
<th> 操作步骤 </th>
<th> 预期结果 </th>
<th> 测试结果 </th>
<th> 备注 </th>
<th> review说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>- </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> -</td>
</tr>
</tbody>
</table>


<p>需要测试工程师根据需求创建并经过研发人员reivew确定测试用例，待到发布前进行测试以及反馈，直到所有测试用例都通过。</p>

<p>对于移动app功能的测试，目前市场上有类似<a href="https://www.bugtags.com/">bugtags</a>这种所见即所得提交测试工具，可以很方便的提交bug。</p>

<p>功能测试通过之后，对于一些对性能有要求的项目，还需要进行性能测试。对于这种测试来说，通常有以下几种方式：</p>

<ul>
<li>测试工程师写性能测试代码来进行测试</li>
<li>使用性能测试工具测试，如LoadRunner、ab等</li>
</ul>


<p>当然，所有这些测试都是在项目发布上线之前进行的，通常是在项目的测试、预发布环境中进行的。</p>

<p>此外，对于测试任务的管理工作一般在任务管理软件中都做了集成。也有类似Mantis这种事专门做缺陷管理的。</p>

<h2><a name='自动化部署'></a>自动化部署</h2>

<p>对于Java项目的发布流程，如下图所示：</p>

<p><img src="//images/blog_images/deploy_process.jpg" alt="deploy" /></p>

<p>使用ci软件可将以上步骤自动化的。</p>

<p>如上图所示，对于一个项目，我们是划分为三种或者四种环境的。</p>

<ul>
<li>测试环境: 这个环境是一个相对来说比较宽松的环境，所有代码的提交都会触发jenkins的自动代码质量检查和部署。测试工程师也是首先在这个环境下进行功能、性能测试的。只有通过了，才能部署到后续的下一个环境。</li>
<li><strong><em>集成环境</em></strong>：这个环境不是必须的，只有当项目出现了两个大的分支并行开发，发布前需要集成两部分代码时才需要这样一个环境。一般来说只使用jenkins进行部署前的打包流程，部署流程由相关人员进行。这个环境也是需要测试工程师进行测试的。</li>
<li>预发布环境：这个环境和线上环境是一模一样的，不同的是此环境下的服务器是不在线上服务器集群中的，并不为用户提供服务。此环境下的项目发布也是需要人工参与的，也必须由测试保证功能和性能的正常。</li>
<li>线上环境：这个环境是比较严格的一个环境。在发布前，一般来说会进行发布确认等一系列上线评审工作后，由项目负责人或者运维人员部署发布。

<ul>
<li>功能列表 vs 实现情况：检查是否已经实现所有计划的功能？如果有某些功能没有实现需要说明原因。</li>
<li>软件演示</li>
<li>测试结果和遗留问题列表：测试用例的情况，遗留的Bug以及情况说明</li>
<li>上线确认</li>
<li>后续任务计划</li>
</ul>
</li>
</ul>


<p>其中，<strong>上线确认书</strong>的一个例子如下：</p>

<table>
<thead>
<tr>
<th>&ndash; </th>
<th> xx项目上线确认书 </th>
<th> &ndash;</th>
</tr>
</thead>
<tbody>
<tr>
<td>需求方验证结果 </td>
<td> 意见： </td>
<td> 确认人：[由各个负责人签字]</td>
</tr>
<tr>
<td>开发确认 </td>
<td> 意见： </td>
<td> 确认人：</td>
</tr>
<tr>
<td>测试确认 </td>
<td> 意见： </td>
<td> 确认人：</td>
</tr>
<tr>
<td>服务器是否需要重启 </td>
<td> [是否需要自动更新那些App?] </td>
<td> 确认人：</td>
</tr>
<tr>
<td>服务器配置影响 </td>
<td> [是否需要增加新的服务器ip,是否需要修改nginx/tomcat，是否新装软件，是否新建域名？] </td>
<td> 确认人：</td>
</tr>
<tr>
<td>数据库更改 </td>
<td> [是否需要修改线上数据库？是否有初始化语句？索引是否正确建立？查询语句是否合理？量化分析数据(包括缓存)是否无误？] </td>
<td> 确认人：</td>
</tr>
<tr>
<td>数据初始化 </td>
<td> [是否有初始化数据？如价格，默认分类等] </td>
<td> 确认人：</td>
</tr>
<tr>
<td>上线评审结论 </td>
<td> [ ]通过 <br/> [ ] 未通过，不能上线 <br/>  [ ] 未通过，但修改完制定Bug后可直接上线</td>
<td> 确认人：</td>
</tr>
<tr>
<td>计划上线时间 </td>
<td> 2016-08-01</td>
<td></td>
</tr>
</tbody>
</table>


<p><strong>后续任务计划</strong>，示例如下：</p>

<table>
<thead>
<tr>
<th>问题描述 </th>
<th> 责任人 </th>
<th> 计划完成时间 </th>
<th> 状态</th>
</tr>
</thead>
<tbody>
<tr>
<td>xx </td>
<td> xx </td>
<td> xx    </td>
<td> xx</td>
</tr>
</tbody>
</table>


<h2><a name='故障管理'></a>故障管理</h2>

<p>由于各种客观原因如带宽、主机配置、流量异常或者程序逻辑不够严谨等原因，线上服务并非100%可用的。研发体系中最后把关的就是这一道故障应急机制。也就是说，一旦发生线上故障，如何快速反应并修复问题，如何避免下一次犯同样的错误。</p>

<p>对故障的快速反应需要依赖于运维的监控机制，包括基础设施层面的监控以及业务层面的监控，一旦发生故障应该立刻发出告警到相关人员。这里可以使用nagios、cacti或者第三方服务(如:<a href="http://www.jiankongbao.com/">监控宝</a>)实现，当然，如果你使用的是云服务，一般也会有相应的云监控服务提供给你的。后续的故障问题定位很多情况下则是取决于你的应用日志打的是否合理，是否有足够的覆盖面的，是否有足够的信息。<a href="https://xiequan.info/%E4%BD%BF%E7%94%A8elasticsearch-logstash-kibana%E6%90%AD%E5%BB%BA%E6%97%A5%E5%BF%97%E9%9B%86%E4%B8%AD%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%E5%AE%9E%E8%B7%B5/">ELK</a>和请求链路监测系统(同染色日志系统)是目前比较流行的基于日志的故障定位解决方案。问题一旦定位到了，那么修复就是水到渠成的事情了。</p>

<p>这里需要说明的一点是，上面讲述的是后端的故障快速反应和修复。针对客户端的故障，一般情况下都是由用户发现的。但是由于客户端发布流程的繁琐，很难及时修复一次发布版本的故障，只能等到下次解决。但是，目前一些客户端使用混合开发，其中的h5页面是可以在线修复的，另外，很多安卓app热更新方案也都能在线修复一些代码故障，如<a href="https://github.com/jasonross/Nuwa">Nuwa</a>、<a href="https://github.com/dodola/HotFix">HotFix</a>、<a href="https://github.com/alibaba/dexposed">dexposed</a>。</p>

<p>故障解决完并非最终的结果，之后的故障总结也是故障管理尤为关键的一点。大公司会根据故障产生的影响不同定义不同的故障级别，从而追责到个人，再进一步影响个人的职级评定或者绩效考核、奖金之类的。但这一套却并不适用于小公司，毕竟大多数小公司没有那么完善或者说根本就没有职级和绩效这么一说。其实，追责并不是主要目的，最主要的是如何避免再次出现问题。因此，对于小的创业公司来说，最需要做的就是如何对已经发生的故障做总结，吸取教训。构建一套故障总结wiki则是一种很好的方式。下面是一次故障总结模板；</p>

<table>
<thead>
<tr>
<th>&ndash; </th>
<th> 2016.08.01xxx故障总结 </th>
<th> &ndash;</th>
</tr>
</thead>
<tbody>
<tr>
<td>故障等级 </td>
<td> [故障等级]</td>
<td></td>
</tr>
<tr>
<td>故障描述 </td>
<td> [描述故障发生的现象]</td>
<td></td>
</tr>
<tr>
<td>故障发现时间及发现人 </td>
<td> [xxx于xxxx年xx月xx日 HH:mm 如何发现该问题。]</td>
<td></td>
</tr>
<tr>
<td>故障影响 </td>
<td> [影响时间范围、影响版本范围、影响产品范围]</td>
<td></td>
</tr>
<tr>
<td>故障原因 </td>
<td> [阐述故障发生的原因]</td>
<td></td>
</tr>
<tr>
<td>解决方案 </td>
<td> [详细记录如何解决此次的故障]</td>
<td></td>
</tr>
<tr>
<td>故障教训 </td>
<td> [如何避免下次出现类似的事故]</td>
<td></td>
</tr>
<tr>
<td>责任人   </td>
<td> [责任人签名]</td>
<td></td>
</tr>
</tbody>
</table>


<h2><a name='即时沟通'></a>即时沟通</h2>

<p>显而易见，即时沟通是任何团队都必不可少的一个机制，同样也是研发团队必不可缺的。常用的就是QQ、钉钉或者企业内部的im软件。那么对于小公司或者创业公司，不想用第三方服务的该怎么办呢？之前蘑菇街开源过一个teamtalk的软件，不过后来由于某些原因已经下线。目前，有一款开源的web im软件可以供大家选择：<a href="https://github.com/RocketChat/Rocket.Chat">Rocket.Chat</a>，能够搭建出内网的slack服务(将分散的沟通方式聚集到一个地方，融入到一个信息流中)。</p>

<p>此外，我自己还尝试过使用intellij自带的IDE TALK来进行研发团队的在线交流。使用这个比较好的一点是可以直接做基于代码的即时交流，比如能够发送一个代码片段给同事，他那边接收到之后是直接能在他的项目里相关代码处进行操作的。</p>

<h2><a name='技术提升'></a>技术提升</h2>

<p>一个研发团队，很重要的一点是如何提高团队的战斗力。对于个人来说，在平时的工作中，提高技术的熟练度和深度，在业余补充学习专业知识，提升技术广度，这些都无须多言。那么如何在整体层面或者说是管理上促进团队成员的技术提升呢？可以采取的方式有以下几种：</p>

<ul>
<li>构建内部的技术wiki并建立技术分享机制，鼓励大家以演讲或者技术博客的方式分享自己的技术经验或者教训，既可以对自己进行review又可以给其他成员以启示。这一点，很多公司都是纳入绩效中的。</li>
<li>将一些项目开源，让团队成员能够享受到开源项目带来的各种好处，比如提升个人在业界的知名度、提高编码的水准(毕竟不好的代码，你也不好意思放出去)。</li>
<li>定期举办类似黑客马拉松的比赛，提高团队成员的凝聚力，也能够提升成员解决实际问题的技术能力。</li>
</ul>


<p>自己比较推崇的是第一种方式，但是开始的时候往往会发现很多人是不会主动去分享的。要么是觉得自己的东西技术含量都很低，要么就觉得自己的知识为何要分享给别人。可以采取的办法就是从最初的周期性安排人员进行技术分享，然后慢慢形成一种氛围和习惯，再到后续鼓励大家主动分享。当然，辅以奖品激励或者绩效奖励也是一种不错的方式，但切忌不要忽视一些业务能力很强但不爱或者不善于分享的工程师。</p>

<p>至于项目开源，前提一定是团队的项目真的是高质量并且会对开源社区有贡献的，不能为了开源而开源。尤其是对于一个公司来说，一个开源的项目直接体现了公司技术水准的高低，会对公司的pr、招聘等都带来一定程度的影响。</p>

<p>而黑客马拉松比赛这种方式，尤为关键的一点是要选择合适的主题。一般来说，围绕现实的业务场景来出题不仅能够提升大家解决问题的能力，也能顺便解决实际问题。比如&#8221;根据用户已有行为日志预测用户未来的行为&#8221;、“怎样构建合适的用户质量模型”都是比较合适的主题。此外，借鉴黑客马拉松的这种形式，可以采取类似“每周一题”的做法：在每周例会上给出一道和线上业务相关的问题，如“如何提高信息流的点击转化率”，然后每个人发散思维给出自己的解决方案，最终形成文章发布在内部的技术wiki上。对于每次主题，都会在下周的例会上针对每个人的解决方案进行讨论。</p>

<p>此外，在安排团队成员去调研一种将要使用的新技术的时候，务必要深入到源码层面，这个观念是需要灌输到团队每一个人的意识中去的。去使用一个没有看过源码或者没有掌握其运行原理的开源软件是一件风险非常大的事情，极有可能造成巨大的线上故障。</p>

<p><strong>以上，是自己对于研发体系的一些实践和感悟，很多地方仍然有所欠缺或者并非最佳实践，也一直在探索更好的方案。</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年的几点规划]]></title>
    <link href="http://www.rowkey.me/blog/2016/02/18/2016plan/"/>
    <updated>2016-02-18T20:31:11+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/02/18/2016plan</id>
    <content type="html"><![CDATA[<p>明天就要开始新的一年正式的上班了，回想一下过去的2015年，对于自己来说，虽然有不少的收获和成长，但还是令自己比较不满意的。由于某些原因，自己的学习进度以及工作情况都受到了很大的影响，并没有达到年初的期望。不过，至少没有浑浑噩噩的一年又一年，也算不错了。^_^</p>

<p><strong>工作学习方面：</strong></p>

<ol>
<li><p>大数据</p>

<p> 公司业务的增长让以前的架构达到了瓶颈。大数据技术的引入对于我自己来说算是离开了舒适区。从hadoop、flume、kafka到storm等等都是一个崭新的领域。虽然从本质上来看，大数据和普通的程序是没啥区别的。但是牵扯到分布式，各种需要考虑的东西也就多了起来，也就引出了一个个强大的软件。15年基本上完成了公司的lambda架构，16年需要做的是完善、优化已有的，而需要考虑引入的则包括elasticsearch、spark等大数据技术。</p></li>
<li><p>数据挖掘</p>

<p> 大数据是服务于数据统计的，而数据统计的最终目的一方面是指导市场运营的工作，更重要的一点则是服务于数据挖掘。目前接触的主要是怎样构建用户画像，从而形成一个良好的推荐机制，为用户推荐更多感兴趣的运营内容。15年，完成了用户画像以及初版的推荐机制；16年，需要做的是进一步验证已有系统的效果，考虑引入更好、更成熟的方案，此外在文本内容打标签、分类等方面也需要实现成熟的机器学习方案。</p></li>
<li><p>基础平台</p>

<p> 借鉴已有开源框架，实现了公司的dao框架、redis操作框架、java ee应用性能检测框架、分布式调度框架等。16年需要继续升级基础平台。</p>

<p> 值得一提的是，公司代码版本管理使用的gitbucket，自己在此之上做了不少二次开发，有些提交给了原项目，有些则是仅仅为了应对公司的需求。鉴于此，也接触到了scala的开发，不得不说，scala的学习曲线确实很陡，16年争取要能掌握并熟练运用此语言。</p></li>
<li><p>Github</p>

<p> 在github上写代码，一方面可以提高自己的编码水平，毕竟质量太差的代码，你也怕拿出来丢人；另一方面，github上那么多优秀的项目，只做拿来党是很可耻的，一些好的东西，分享出来帮助更多的同行给自己带来的成就感反过来也能督促自己技术的提升。15年自己开发或者基于原项目二次开发了一些star较多的项目。16年要坚持在github继续贡献更多好的代码。</p></li>
<li><p>技术分享</p>

<p> 在去年的研发招聘过程中，尤其是校招，感受到了目前后端工程师教育的匮乏。对于一个后端工程师的技术体系，先不说学生，不少工作很长时间的人都没有一个清晰的认识。于是自己萌生了写一本后端工程师技术体系书籍的想法，希望能够给选择后端这个方向的人一些指导。到目前为止也写了一些，希望16年至少能出一个初稿。</p>

<p> 此外，自己在开发者头条的<a href="http://toutiao.io/subjects/4944">《后端技术杂谈》</a>专栏，会继续分享自己的技术感悟和总结。一方面，增人玫瑰，手有余香；更重要的一点还是能够督促自己多总结，多思考。</p></li>
</ol>


<p><strong>工作学习之外：</strong></p>

<p>今年最大的一点感受：不管其他如何，健康才是一个人最最重要的东西。尤其是对于天天坐在电脑面前的程序员们来说，保持健康就是保证最大的竞争力。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[研发招聘之殇]]></title>
    <link href="http://www.rowkey.me/blog/2015/12/31/dev-job-talk/"/>
    <updated>2015-12-31T22:01:02+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/12/31/dev-job-talk</id>
    <content type="html"><![CDATA[<p><strong><em>ps: 本文完成于2015年12月31号</em></strong></p>

<p>对于一个公司来说，要想健康长久的发展，招聘是一个永久的话题。而对于一个互联网公司，尤其是以产品为主的公司来说，研发是招聘中的关键职位，高质量的研发人才也是所有企业都急缺的。一直持有一个观点：招一个优秀的人给他两倍的薪资带来的效果远远大于招两个普通的人。也一直秉着这个观点来招聘。</p>

<!--more-->


<p>今年十月份去西安、武汉两地进行校招，发现了目前很多学生存在的问题(其实之前在前东家参与校招的时候也发现了)：</p>

<ol>
<li><p>技术脱离业界前沿。现在高校里开的课以及实验室用的技术基本都脱离业界，面试了很多学生，他们的技能还千篇一律都是ssh系列。而这种技术选项，目前也就在传统it行业流行，互联网公司早就摒弃了这一套。此外，分布式缓存、消息队列等技术更是鲜少有人涉及。更为遗憾的是，对于服务端工程师、前端工程师、客户工程师等职位应该具有的技术栈，在高校里也缺乏相应的课程和相关的人来指导(大公司一般都设置有入职培训针对这一点)。</p></li>
<li><p>基础素质欠缺。对于应届生来说，基础素质是最关键的一点，项目经验是加分项，但不是必需和最关键的。很多学生被问起hashmap的实现原理以及怎样解决冲突时就不知所云(明明就是数据结构课讲过的)，被问到tcp/ip、操作系统时更是乱七八糟。也有些学生做过很多项目，自认为经验丰富，但当被问起使用的技术比如spring mvc的原理、mysql的索引机制时，没有任何思路。其实项目经验、工具这些东西决定了你的下限，你的基础知识和素质才决定了你的上限。互联网行业需要的是学习能力强、基本功扎实的优秀工程师，而非很多传统IT企业需要的螺丝钉。</p></li>
<li><p>没有畏惧心。这一点可能因人而异，毕竟有些人的性格就是桀骜不驯。但是在研发这个圈子里，大神太多，是大神但比你还努力的人也太多。技术也太广，任何一门技术都很难精通。做为一个研发工程师，你必须对所有人、所有技术都有一颗为畏惧心。每个人都有亮点值得你学习，每一种技术都需要你下大功夫才能精通。记得有些学生在基础知识被问得绊绊磕磕的时候，急得号称自己精通java，但试着去问了，却发现很多知识都似是而非。说到这里，最近公司的几个实习生让我体会挺深刻的，有些学生的确会对技术有畏惧感，很谦虚，抱着一种学习的态度；但是也有很多学生自视甚高，甚至有人待了一周(很多东西都没接触到)就离职，觉得我们这技术水平入不了他的法眼，总是拿一个我听都没听过的公司跟我说这个公司很厉害的，早就给offer了等等。不敢说我们公司的技术业界领先，至少我们做出了拥有几亿用户的产品。人，还是应该有一颗畏惧心，不论对人还是对事。</p></li>
<li><p>知其然不知其所以然。这一点的反面(知其然更知其所以然)对于研发人员其实是最关键的素质。能做出东西来只能证明你上手能力强，但并不代表你学习能力强。学习能力强，是指的能够快速吸纳理解新的知识，融汇贯通。比如，就拿最简单的spring ioc来说，用过的人基本都知道大概是个什么事情，但是抛开spring，让你自己去实现ioc，很多人估计就不知所措了。</p></li>
</ol>


<p>校招毕竟只是研发招聘的补充，最关键的还是社招。但是面试了很多有经验的工程师之后，却也发现了很多问题。除了上面校招提到的一些，最令我印象深刻的就是薪资。本科毕业一两年的，之前在一些不知名的公司工作过的人，动辄就漫天要价。好吧，我觉得可能是真的很优秀，那倒也匹配的上。结果，面试过n次这种人之后，我发现帝都的薪资真的不能拿常人的眼光来看，也算是给我这种来自杭州的人开了眼界。毕竟帝都这地方互联网企业一大把，舍得给钱的、面向vc的创业公司也一大把。你觉得不值，还有一大批公司觉得值。这种现象，在今年上半年达到了顶峰。不能说正确与否，只能说市场如此，带来的效应就这样。</p>

<p>关于招聘，是一门学问。自己非专业的，所以很多东西肯定看的不够清楚。但对于研发招聘，自己经历过很多次被面试，也面试过很多人。有自己觉得好的面试形式，也有自己很嗤之以鼻的。</p>

<ol>
<li>N轮算法题目面试。这种形式是被微软和谷歌所推崇的，不一定好，但是至少客观，不会掺杂面试官的主管因素，而且据说后续的结果证明了算法好的人在工作上的成绩好的概率非常大。自己曾有幸经历过一次，由于自己对算法不感兴趣，也一直没刷过题目，所以结局很惨烈。不过，自己却也信服口服。应对这种面试，能做的就是做大量的题目(至少《算法导论》上的算法都要搞明白)，总结方法，锻炼自己的思维。当然参加一下acm比赛也不妨为一种好方法。剩下的，就看你的天赋和运气了。</li>
<li>掺杂计算机基础知识、算法以及项目经验的面试。这种形式是国内大部分公司采取的。优点是能从多方面考察面试者的技术水平；缺点就是容易被面试官的主观因素所影响，尤其是很多水平很差的面试官，或者是面试官和被面试者方向不对路。</li>
<li>软件设计。这个不同于算法题目，一般是面向某一场景的软件设计题目。每个人提交代码，然后根据代码的效率、模式设计等判定结果。现场面试的时候，面试官当场提出问题、需求，现场进行优化编程。这个面试方式，我见过某土豪日企(应届生起薪30W+)采用过。这个我暂时说不上是好是坏，应该是针对特定企业的工业场景的一种面试方式。</li>
<li>现场结对编程/ppt讲解。记得之前看过一篇文章讲世界上研发面试最难的公司是Thoughtworks。面试官和你结对编程，然后再进行圆桌会议等等一系列复杂的流程。不过，在国内的thougtworks也许是为了迎合中国国情吧，倒是没见过这么招聘。记得校招的时候，初试出一道软件设计题目，你解决好后提交代码，现场面试的时候，就针对这个问题进行ppt演示，面试官当场提出问题，看你的应对。</li>
<li>只看学历、学校。这种面试方式，我知道的一次貌似只有hw校招。当时听同学说，面试官声称不关心你会不会或者专业对不对口，只要学校符合，其他的都能培养出来。当然，我相信，这只是某种形势下hw的招聘策略，毕竟hw里面招的牛人还是大有人在的。尤其是2000年左右，进hw那可是人人羡慕的。</li>
<li>群面。这种方式多见于非研发职位。不敢说在研发面试中出现好不好，但至少对我来说，如果有公司这么干，我肯定去都不去。码农们都不擅长和人打交道的好不。。。虽然，这不一定算是件好事。不过，研发总归还是要看技术的么。</li>
</ol>


<p>目前，我们公司采取的是国内最流行的第二种，基础知识考查这个人的基本素质，也就是看看能否胜任当前工作；项目经验看看这人做过的东西有没有消化、深入理解，看这人的学习主动性、研究问题的深度、对技术的热情如何；开放性问题看看这人是否足够聪明。坚决杜绝问RTFM的问题，也坚决不出什么脑筋急转弯。也会采取一些措施，比如两轮平行面试，来避免掺杂主观因素。</p>

<p>那么怎么定义一个优秀的研发工程师呢？我们希望招到的研发人员或者说我们觉得优秀的研发人员，抛开具体技术来说，共性应该是这样的：</p>

<ol>
<li><p>聪明、思维灵活。研发最重要的一点就是要聪明，这个观点貌似雷军也说过。很难想象一个不聪明的人是如何解决复杂的工程问题的。而什么叫聪明呢？我们现在在面试的时候，会随机从现实的项目中出一道曾遇到过的问题。面试的很多人都会说没遇到过、不知道。其实最终的答案并没有对错，没遇到过这个问题也是我们最希望的，如果你能给出解决方案或者思路才说明你有足够解决现实问题的能力。</p></li>
<li><p>对技术有热情。只有对技术有热情，才不会把工作仅仅当做工作，还会当做乐趣。这样才会对接触过的技术能深入研究下去，快速学习，快速成长起来。相比起聪明，这一点也是至关重要的。如果仅仅是聪明，而对技术不具有热情，那么很多人会浅尝辄止，不求甚解，最后聪明反被聪明误。而没有那么聪明的人如果足够有热情，找到合适的方法，努力学习原理层的东西，也会很快成为技术大牛的。</p></li>
<li><p>基础知识扎实。和上面校招那一部分说的一样，基础知识决定一个人的上限。如果一直停留在表面应用业务的开发，不接触到底层计算机原理，那么即使你在nb闪闪发光的大公司里，你也是可有可无的一个人，价值慢慢会趋于0。而基础知识扎实，那么学起其他的业务层技术也根本不会成为问题，上限也会很高。</p></li>
<li><p>有执行力。执行力在某种方面说就是结果导向。见过很多聪明、对技术有热情的人，却总是钻牛角尖，容易陷在一个细节上出不来，这一点自己也不例外。但是有人会考虑到整个项目的进度，做好控制，先用快速的方案实现，后续再调整和优化；有些人却往往为了一个细节，纠结来纠结去，最后造成进度延误，这就是一种没有执行力的表现。当然，如果你效率高，那么你随便钻牛角尖，不然你应该以全局为重。</p></li>
</ol>


<p>以上是今年招聘的一些感悟，希望来年能招到更多符合期望的人才。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[工作总结@2014]]></title>
    <link href="http://www.rowkey.me/blog/2015/01/15/2014-final-note/"/>
    <updated>2015-01-15T16:08:48+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/01/15/2014-final-note</id>
    <content type="html"><![CDATA[<p>突然发觉已经是2015年的1月15号了，即兴补上一篇2014年的总结吧。</p>

<p>对自己来说，今年最大的事情莫过于离开一座城市，到达另一座城市，开始了新的职业生涯。</p>

<p>进入新的公司，一个创业公司，截然不同的运作方式让我一开始有点措手不及。相比之前在大公司，小公司更需要一个人的快速成长以及自我约束，以及那种随叫随到、不怕脏累的奋斗精神。而技术层面，要尽最大化压榨硬件资源，用有限的硬件资源达到最大的性能。这些都让自己的架构方式和代码编写不得不去改变、去适应，这也算是一种成长吧。公司的基础架构、公共组件、项目管理、技术体系、项目架构都是一个初级的水平，改变这些是一个很难很长的路，但又不得不做。到现在，在做这些改变的过程中，自己的基础知识得到了巩固、架构能力也有了一定的提升，技术视野也开阔了一些。熟悉了公司的流程和整体的氛围，也算融入了这个团队，要做的还有很多，阻力也有很多。一切都在逼迫自己去学习、去思考、去提高。这也是与以前相比，给自己最大动力的事情。</p>

<p>2015年，工作上希望自己能做到这些</p>

<ul>
<li>合理设计并实现整个公司的基础架构</li>
<li>构建合理的项目管理流程、监督机制</li>
<li>提升团队的整体水平</li>
<li>保证产品的研发进度以及线上稳定性</li>
<li>招一些优秀的人加入</li>
</ul>


<p>自身方面，希望能做到这些：</p>

<ul>
<li>提升自身的技术水平和视野</li>
<li>深入学习一门技术：docker netty kafka rabbitmq elasticsearch solr</li>
<li>阅读至少五本非技术书籍</li>
</ul>


<p>Stay hungry,stay foolish!</p>
]]></content>
  </entry>
  
</feed>
