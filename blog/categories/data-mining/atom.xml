<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: data-mining | 后端技术杂谈]]></title>
  <link href="http://www.rowkey.me/blog/categories/data-mining/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2022-06-01T13:44:30+00:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[Mr.H]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[推荐系统杂谈]]></title>
    <link href="http://www.rowkey.me/blog/2016/08/30/recommend-sys/"/>
    <updated>2016-08-30T12:39:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2016/08/30/recommend-sys</id>
    <content type="html"><![CDATA[<p>推荐系统是近些年非常火的技术，不管是电商类软件还是新闻类app，都号称有精准的推荐系统能给你推送你最感兴趣的内容。现象级的资讯类app“今日头条”就得益于此成为了势头非常猛的一款产品。本文就针对推荐系统讲述一些相关概念和实践经验。</p>

<p>首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：</p>

<ul>
<li>用户满意性：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。</li>
<li>多样性：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。</li>
<li>新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。</li>
<li>惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。</li>
<li>实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。</li>
<li>推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、&#8221;你购买过的xx和此商品类似&#8221;。</li>
<li>覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。</li>
</ul>


<!--more-->


<p>基于这些目标，推荐系统包括四种推荐方式：</p>

<ul>
<li>热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。</li>
<li>人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。</li>
<li>相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。</li>
<li>个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。</li>
</ul>


<p>其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。</p>

<h2>个性化推荐系统</h2>

<p>个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。</p>

<p>个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。</p>

<ul>
<li>日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。</li>
<li>推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。</li>
<li>内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。</li>
</ul>


<p>其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：</p>

<ul>
<li>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</li>
<li>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。</li>
<li>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。</li>
</ul>


<p>个性化推荐系统的典型架构如下图所示：</p>

<p><img src="//images/blog_images/recommend-sys/recommend-sys-arch.png" alt="recommend-sys" /></p>

<p>在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。</p>

<p>基于此框架，个性化推荐系统的典型流程如下所示：</p>

<p><img src="//images/blog_images/recommend-sys/recommend-process.png" alt="recommend" /></p>

<p>可知，一个推荐系统主要有以下模块组成：</p>

<ul>
<li>用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。</li>
<li>数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。</li>
<li>推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。</li>
<li>数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。</li>
<li>用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。</li>
<li>推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。</li>
<li>服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。</li>
</ul>


<h3>数据ETL-1</h3>

<p>对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。</p>

<h3>推荐算法</h3>

<p>对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：</p>

<ul>
<li>基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：<a href="http://www.rowkey.me/blog/2016/04/07/up-recommend/">http://www.rowkey.me/blog/2016/04/07/up-recommend/</a>。</li>
<li>基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：<a href="http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/">http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/</a>。</li>
<li>用户&amp;物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。</li>
</ul>


<p>推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。</p>

<p>推荐算法的基本流程如下图所示：</p>

<p><img src="http://www.rowkey.me/images/blog_images/recommend-sys/recommend-sys.png" style="width:400px"/></p>

<h3>数据ETL-2</h3>

<p>对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。</p>

<h3>用户画像存储</h3>

<p>存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用<strong>ElasricSearch</strong>构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。</p>

<h3>推荐结果存储</h3>

<p>对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。</p>

<h3>服务调用</h3>

<p>整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。</p>

<ol>
<li>根据用户id，获取推荐的item列表。</li>
<li>根据item，获取相关联的item列表。</li>
<li>根据用户id, 获取用户画像。</li>
</ol>


<p>该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。</p>

<h2>需要考虑的问题</h2>

<p>对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。</p>

<h3>实时性问题</h3>

<p>由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。</p>

<h3>时效性内容问题</h3>

<p>时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。</p>

<h3>冷启动问题</h3>

<p>不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？</p>

<ul>
<li>对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。</li>
<li>对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。</li>
</ul>


<h3>多样性问题</h3>

<p>在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。</p>

<p>如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么</p>

<pre><code>RecommendList(u) = A[Total推荐 * wA] + B[Total推荐 * wB] + C[Total推荐 * wC] + D[Total推荐 * wD]
</code></pre>

<h3>内容质量</h3>

<p>不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？</p>

<p>当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。<strong>click/pv</strong>是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。</p>

<h4>惊喜问题</h4>

<p>推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit &amp; Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：<a href="https://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;mid=2449231300&amp;idx=1&amp;sn=fe975d6af79596b5eaf576e5f65e8e06">推荐系统的苟且和远方</a>。</p>

<h2>总结</h2>

<p>借用<a href="http://itindex.net/detail/50820-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F">推荐系统的那点事</a>一文的几句话做为结语：</p>

<ul>
<li>实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。</li>
<li>学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】</li>
<li>【几乎所有所谓的智能推荐算法都是花拳绣腿】</li>
<li>当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。</li>
</ul>


<p><strong><em>以上是推荐系统实践的一些经验</em></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于内容和用户画像的个性化推荐]]></title>
    <link href="http://www.rowkey.me/blog/2016/04/07/up-recommend/"/>
    <updated>2016-04-07T06:59:44+00:00</updated>
    <id>http://www.rowkey.me/blog/2016/04/07/up-recommend</id>
    <content type="html"><![CDATA[<p>目前比较流行的个性化推荐算法有以下几种：</p>

<ul>
<li>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</li>
<li>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。</li>
<li>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)或者ALS；基于图模型协同，即Graph，也叫社会网络图模型。</li>
</ul>


<p>本文所讲述的基于内容和用户画像的个性化推荐属于第一种。对于此种推荐，有两个实体：内容和用户，因此需要有一个联系这两者的东西，即为标签。内容转换为标签即为内容特征化，用户则称为用户特征化。对于此种推荐，主要分为以下几个关键部分：</p>

<ul>
<li>标签库</li>
<li>内容特征化</li>
<li>用户特征化</li>
<li>隐语义推荐</li>
</ul>


<p>综合上面讲述的各个部分即可实现一个基于内容和用户画像的个性化推荐系统。如下图所示：</p>

<p><img src="//images/blog_images/up-recommend.png" alt="uc_interest" /></p>

<!--more-->


<h3>标签库</h3>

<p>标签是联系用户与物品、内容以及物品、内容之间的纽带，也是反应用户兴趣的重要数据源。标签库的最终用途在于对用户进行行为、属性标记。是将其他实体转换为计算机可以理解的语言关键的一步。</p>

<p>标签库则是对标签进行聚合的系统，包括对标签的管理、更新等。</p>

<p>一般来说，标签是以层级的形式组织的。可以有一级维度、二级维度等。</p>

<p>标签的来源主要有：</p>

<ul>
<li>已有内容的标签</li>
<li>网络抓取流行标签</li>
<li>对运营的内容进行关键词提取</li>
</ul>


<p>对于内容的关键词提取，使用<a href="https://github.com/fxsjy/jieba">结巴分词</a> + <a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html">TFIDF</a>即可。此外，也可以使用<a href="http://www.tuicool.com/articles/UZ77Z3">TextRank</a>来提取内容关键词。</p>

<p>这里需要注意的一点是对于关联标签的处理，比如用户的标签是足球，而内容的标签是德甲、英超，那么用户和内容是无法联系在一起的。最简单的方式是人工设置关联标签，此外也可以使用word2vec一类工具对标签做聚类处理，构建主题模型，将德甲、英超聚类到<strong>足球</strong>下面。</p>

<h3>内容特征化</h3>

<p>内容特征化即给内容打标签。目前有两种方式：</p>

<ul>
<li>人工打标签</li>
<li>机器自动打标签</li>
</ul>


<p>针对机器自动打标签，需要采取机器学习的相关算法来实现，即针对一系列给定的标签，给内容选取其中匹配度最高的几个标签。这不同于通常的分类和聚类算法。可以采取使用分词 + <a href="http://www.cnblogs.com/wowarsenal/p/3293586.html">Word2Vec</a>来实现，过程如下：</p>

<ul>
<li>将文本语料进行分词，以空格,tab隔开都可以，使用结巴分词。</li>
<li>使用word2vec训练词的相似度模型。</li>
<li>使用tfidf提取内容的关键词A,B,C。</li>
<li>遍历每一个标签，计算关键词与此标签的相似度之和。</li>
<li>取出TopN相似度最高的标签即为此内容的标签。</li>
</ul>


<p>此外，可以使用文本主题挖掘相关技术，对内容进行特征化。这也分为两种情况:</p>

<ol>
<li>通用情况下，只是为了效果优化的特征提取，那么可以使用非监督学习的主题模型算法。如LSA、PLSI和GaP模型或者LDA模型。</li>
<li>在和业务强相关时，需要在业务特定的标签体系下给内容打上适合的标签。这时候需要使用的是监督学习的主题模型。如sLDA、HSLDA等。</li>
</ol>


<h3>用户特征化</h3>

<p>用户特征化即为用户打标签。通过用户的行为日志和一定的模型算法得到用户的每个标签的权重。</p>

<ul>
<li>用户对内容的行为：点赞、不感兴趣、点击、浏览。对用户的反馈行为如<strong>点赞</strong>赋予权值1，<strong>不感兴趣</strong>赋予-1；对于用户的浏览行为，则可使用<strong>点击/浏览</strong>作为权值。</li>
<li>对内容发生的行为可以认为对此内容所带的标签的行为。</li>
<li>用户的兴趣是时间衰减的，即离当前时间越远的兴趣比重越低。时间衰减函数使用<strong>1/[log(t)+1]</strong>, t为事件发生的时间距离当前时间的大小。</li>
<li>要考虑到热门内容会干预用户的标签，需要对热门内容进行降权。使用<strong>click/pv</strong>作为用户浏览行为权值即可达到此目的。</li>
<li>此外，还需要考虑噪声的干扰，如标题党等。</li>
</ul>


<p>另，在非业务强相关的情况下，还可以考虑使用LSA主题模型等矩阵分解的方式对用户进行标签化。</p>

<h3>隐语义推荐</h3>

<p>有了内容特征和用户特征，可以使用<a href="http://blog.csdn.net/harryhuang1990/article/details/9924377">隐语义模型</a>进行推荐。这里可以使用其简化形式，以达到实时计算的目的。</p>

<p>用户对于某一个内容的兴趣度(可以认为是CTR)：</p>

<p><img src="//images/blog_images/uc_interest.jpg" alt="uc_interest" /></p>

<p>其中i=1&hellip;N是内容c具有的标签，m(ci)指的内容c和标签i的关联度(可以简单认为是1),n(ui)指的是用户u的标签i的权重值,当用户不具有此标签时n(ui)=0，q&copy;指的是内容c的质量，可以使用点击率(click/pv)表示。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据杂谈]]></title>
    <link href="http://www.rowkey.me/blog/2016/02/23/data-talk/"/>
    <updated>2016-02-23T10:44:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2016/02/23/data-talk</id>
    <content type="html"><![CDATA[<h2>目录</h2>

<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE">数据</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F">数据系统</a></li>
<li><a href="#%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1">数据统计</a></li>
<li><a href="#%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90">个性化推荐</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li>
</ul>


<h2><a name='前言'></a>前言</h2>

<p>记得几年前，曾经有人预测过未来最流行的三大技术：大数据、高并发、数据挖掘。到现在来看，这三种技术的确也随着这几年互联网的发展变得越发成熟和可靠。掌握这三种技术的人，不管是求职还是创业，都属于香饽饽。一个很深的印象就是当年研究生毕业的时候，专业是数据挖掘、大数据的学生都比较受各种企业的青睐，不管他是不是真的掌握了这些东西。虽然我对大部分高校的相关专业持怀疑态度，但是却也不得不承认，这些专业的确改变了很多东西，也给很多学生镀上了一层金。</p>

<p>自己一直从事的是Java EE中间件、基础架构等方面的研发工作，对数据这一块只是略知皮毛，在前东家的时候我也没有机会接触数据平台。但由于现公司业务的原因，却不得不去触碰这一块，到目前为止也就仅仅半年时间（其间穿插各种协调、管理的杂事）。因此，数据相关的东西对我来说完全是一个新的领域，算是离开了自己的舒适区。不过，逃离舒适区这个想想也挺兴奋的。</p>

<!--more-->


<h2><a name='数据'></a>数据</h2>

<h3>什么是数据？</h3>

<p>最近有一本很火的书叫《精益数据分析》，其核心的一个观点就是：需要用数据驱动产品和公司的发展，而不能靠直觉或者拍脑袋。可见，数据是多么的重要。在一个产品的生命周期中，会产生很多数据：用户信息、用户行为信息、ugc数据等等。这些数据表现形式可以为文字、图片、日志、视频、音频等等。</p>

<p>从技术角度来讲，数据一般分为结构化数据、半结构化数据和非结构化数据。</p>

<ul>
<li>结构化数据：指的是行数据库可以存储的，数据具有相同的字段，以及相同的存储大小,可以用二维表的逻辑结构来表达实现。</li>
<li>半结构化数据：半结构化数据，指的整体上是结构化数据形式，但字段数目不定，数据结构和内容混杂在一起。</li>
<li>非结构化数据：不方便用二维表描述的数据，如各种文档、图片、音/视频等。</li>
</ul>


<h3>能用来干什么?-数据挖掘</h3>

<p>说到数据的作用，不得不提数据分析师这个职位。此职位一般来说倾向的是数学相关专业人士，使用数据来指导产品、运营、市场等工作，是公司中使用数据最多的人。在公司中，市场运营销售这几个部门也都是和数据关系很密切的。市场需要参考数据分析哪一个渠道推广效果更好，运营部门需要根据数据分析什么内容更能提高产品的活跃度，销售部门则需要数据反映公司的收入情况。当然，除了这些，数据挖掘就是另一个很重要的使用数据的方面了，可以使用数据对用户进行行为分析，从而挖掘用户的兴趣，最终达到精准推荐、精准营销的目的。</p>

<p>概括来看，数据的作用就是数据挖掘，就是试图从海量数据中找出有用的知识，也可以称为“知识发现”。数据挖掘的支撑技术主要包含统计学以及机器学习两方面。从这个角度来看，数据主要有以下两点作用：</p>

<ul>
<li>数据统计：通过对数据的统计计算出一些和产品、用户相关的指标，从而指导产品、市场、运营、销售工作。</li>
<li>机器学习：使用相关技术让机器通过已有的数据学习到新的有用的知识。比如：从已有的用户行为数据分析得到用户的兴趣、爱好等信息，从而进一步实现用户个性化推荐。个性化推荐也是机器学习目前使用数据最为广泛的一点。</li>
</ul>


<h3>数据库&amp;&amp;数据仓库</h3>

<p>有了数据，就需要有存放数据的地方。数据库和数据仓库即存放数据库的两种形式。两者在本质上没有区别，都是为了存储数据。</p>

<ul>
<li><p>数据库：面向业务设计，一般针对的是在线业务，存储的是在线业务数据。如：Oracle、DB2、MySQL、Sybase、MS SQL Server等。可以分为：关系型数据库和NoSql数据库，其中后者又可分为KV数据库、文档型数据库、列数据库。</p></li>
<li><p>数据仓库：是数据库概念的升级，面向分析，存储的是历史数据。从数据量来说，数据仓库要比数据库更庞大得多。主要用于数据挖掘和数据分析，代表软件为Hive。</p></li>
</ul>


<p>ETL: 数据仓库很多时候是需要从其他地方传输数据到数据仓库，这个过程就是ETL：extract-抽取、transform-转换、load-加载。</p>

<h3>数据的生命周期</h3>

<p>无论是历史数据还是线上数据，都是有生命周期的。比如，对于一个产品的用户活跃度统计业务，最近半年的数据是热点数据，访问较频繁；而随着时间的推移，慢慢的这些数据不再被频繁关注，变为了一般数据；再随着时间的推移，总有一天这些数据不再会被关注就成为了冷数据。</p>

<p>热点数据→一般数据→冷数据，这就是数据的一个生命周期，对于不同的生命周期，所需要的技术选型也应该不一样。</p>

<h2><a name='数据系统'></a>数据系统</h2>

<p>不管是数据统计还是数据挖掘，构建一个数据系统都是做好这些的前提。一般来说，构建一个完备的数据系统有以下几点：</p>

<ol>
<li><p>数据采集</p>

<p> 无论是移动端还是web上，要做好数据采集集最重要的一点就是埋点。也就是要在你需要采集数据的地方做一个标记，向服务端发起一个日志请求。当然，对于服务端能够通过业务逻辑获取的内容，原则上不要打点。比如，统计某一篇新闻的阅读数目、点赞数，这些行为其实在用户打开此新闻、点赞时已经发起了服务端请求，不需要再埋一个点；此外，统计用户数目这种，在用户数据库中就可以计算出来，也不需要埋点。埋点主要针对的是通过产品的业务逻辑无法获取到的一些数据，如一个站点中某一个模块的pv、uv等。</p>

<p> 埋点后向服务端发起日志请求，这些请求在用户量规模并不很大的架构设计中直接实时计算数据入库即可，但是在用户请求量很大的情况下，这种设计是有问题的，会增加业务请求的压力，从而影响线上服务，因此好的设计应该是数据请求只形成一条日志（一般通过nginx日志实现）。因此，这里很关键的一点就是如何将这些日志收集起来进行处理。目前常用的技术有flume、Scribe、Chukwa等。其中，flume是目前比较成熟且应用比较广泛的方案。</p>

<p> 由于从数据源到来的数据并不一定是我们处理需要的数据或者数据格式，因此这里还有数据的清洗过程，包括分析，验证，清洗，转换，去重，</p></li>
<li><p>数据队列</p>

<p> 数据采集之后需要通过数据队列传输，这里的队列主要起的是缓冲作用以及其他非采集数据源的输入(比如某一业务逻辑产生了一条统计报文，可以直接写入队列中)，可以采取本地队列或者分布式队列。目前，比较成熟的队列有kafka、rabbitMQ等。其中，在数据统计领域kafka是应用比较广泛的。</p></li>
<li><p>数据处理</p>

<p> 对于采集到的数据，很多是需要计算才能得到需要的统计结果的。这时候就牵扯到了计算模型。这里分为离线计算和实时计算两种模型。离线计算针对实时来讲，就是非实时的，可以定时调度进行计算的，一般来说是耗时比较长，对结果需求没那么实时的业务场景，适合非线上业务；实时计算则是需要在数据一到达就开始进行计算、处理的，适合对实时性要求高的一些业务场景，比如广告的实时结算等。</p></li>
<li><p>数据存储</p>

<p> 服务端在数据统计中一个关键的功能是对采集到的内容进行存储。对于中小规模的数据，使用mysql等传统数据库即可应对，大一点规模采用分表、分库也能应对。再大一点的那就只能祭出大数据数据库了。此外，数据的存储结构也需要慎重考虑，尤其是在应对多维度查询的时候，不合理的数据结构设计会导致低下的查询效率和冗余的存储空间。</p></li>
<li><p>数据可视化</p>

<p> 数据存储的下一步是要把数据展示出来，也就是数据可视化。通常情况下，导出excel表格是一种形式，此外，web端/移动端甚至pc端也需要展示数据的话，就引出了数据可视化技术，尤其是在大数据量情况下如何更加高效快速地展示数据。</p></li>
</ol>


<p>数据采集+数据队列+数据处理+数据存储+数据可视化即组成了一个完整的数据系统。而从本质上来看，数据系统=数据+查询，万变不离其宗。</p>

<p>对于一般规模的产品，数据其实远远没有达到需要使用大数据技术的地步。使用传统的收集数据→定时调度程序计算，存储到mysql中即可解决。如果有大的并发请求，那么使用数据队列做缓冲。当数据规模大到一定规模时，例如mysql数据库在分表分库的情况下，单表数据量还是达到了千万的规模、单机存储依然不够或者单机计算已经慢到无法容忍。应对这种情况，就需要分布式技术出场了。</p>

<p>说到这里，借用《计算广告》一书中所讲，对于数据分为三种：</p>

<ul>
<li>小规模数据：此种数据可以通过采样部分数据即可反映出数据的特征。这时候，根本无需什么大数据技术，单机规模的传统数据系统架构即可应对这种场景。</li>
<li>中等规模数据：小规模数据无法反应数据特征，当数据规模达到一定规模时，再增大特征趋向于平稳，那么此时也无需大数据技术的出场。</li>
<li>大规模数据：不能通过采样来反应数据特征，必须全量采集数据才能获取到数据特征。此时，就需要大数据技术来解决问题。</li>
</ul>


<p>其中，大规模数据就不是一般架构可以解决的了的了。</p>

<h2><a name='大数据'></a>大数据</h2>

<p>麦肯锡的《大数据：创新、竞争和生产力的下一个前沿领域》中对大数据的定义：</p>

<pre>
大数据指的是规模超过现有数据库工具获取、存储、管理和分析能力的数据集，并同时强调并不是超过某个特定数量级的数据集才是大数据。
</pre>


<p></p>

<p>大数据系统通常被认为具有数据的五个主要特征，通常称为数据的5Vs。分别是大规模，多样性，高效性、准确性和价值性。</p>

<h3>相关技术</h3>

<p>大数据是一个很宽泛的概念。当单机无法处理数据时，就有了大数据。而应对各种不同的业务场景，诞生了很多不同的软件。完成一个功能完备的系统需要多个软件的组合。</p>

<ol>
<li><p>文件/数据存储</p>

<p> 传统的文件存储都是单机的，不能横跨不同的机器，一般会使用raid做安全冗余保障。但是还是无法从根本上解决问题。HDFS（Hadoop Distributed FileSystem）则是为了应对这种业务场景产生的，其基本原理来自于google的gfs，让大量的数据可以横跨成千上百万台机器。但是对用户来说，看到的文件和单机没任何区别，已经屏蔽掉了底层细节。</p>

<p> 除了文件存储，还有数据的存储，即数据库。传统的mysql等数据库，在存储结构化、小规模数据的时候可以妥妥应对。但当需要存储半结构化或者非结构化数据，或者用分表、分库来解决存储性能、空间问题带来了复杂的管理、join时，就需要一种更好的数据库的出现。大数据领域的Hbase就是为了这种场景产生的，其原理是google的BigTable。当然，hbase底层还是依赖于hdfs，是一个针对半结构化、非结构化、稀疏的数据的数据库。</p>

<p> 此外，hbase和hdfs相比起mysql这种毫秒级数据库，其响应速度是很慢的。如果线上业务场景需要使用这些数据，那么这时候就需要更好的数据库的出现。elasticserach就是其中的佼佼者，当然，使用这种基于索引、高效的查询数据库，并不建议存储全量数据(除非你钱有的是)。一般情况下，存储热点数据即可。</p></li>
<li><p>离线数据处理</p>

<p> 大数据的处理是非常关键的一个环节。当单机的处理程序无法在期望的时间内处理完数据时，就需要考虑使用分布式技术了。于是就出现了MapReduce、Tez、Spark这些技术。MapReduce是第一代计算引擎，Tez和Spark是第二代。MapReduce的设计，采用了很简化的计算模型，只有Map和Reduce两个计算过程（中间用Shuffle串联），用这个模型，已经可以处理大数据领域很大一部分问题了。但是，MR模型很简单，但也很笨重，有不少缺点，比如：编程模型非常复杂；计算过程磁盘IO过多。于是催生出了第二代数据处理技术，Tez、Spark这些鉴于MR模型的缺点，引入了内存cache之类新的feature，让Map和Reduce之间的界限更模糊，数据交换更灵活，更少的磁盘读写，以便更方便地描述复杂算法，取得更高的吞吐量。</p>

<p> 如上面所说，编写MR的编程复杂度非常高，于是就产生了Hive、Pig，在MR上面又抽象了一层更高级的语法出来，大大简化了MR的编程复杂度。其中以Hive为代表是Sql on xx的一个典型应用。之所以使用sql，一方面是容易编写、容易维护；另一方面SQL可以让没有编程技能的诸如数据分析师都可以不依赖工程师就可以使用数据。但由于一开始的hive还是基于MR之上的，因此，其运算速度还是受到不少人的诟病。于是Hive on Tez / Spark和SparkSQL也出现了。它们都旨在用新一代通用计算引擎Tez或者Spark来跑SQL，这样就避免了基于MR带来的运算瓶颈。</p>

<p> 对于程序的离线数据处理，hive一般情况下都能够满足需求。但是对于数据分析师的数据分析需求来说，这速度就真的有点龟速了。因此为了应对数据分析的需求，Impala、Presto、Drill这些交互式sql引擎应运而生。这些系统的唯一目标就是快，能够让用户更快速地处理SQL任务，因此牺牲了通用性稳定性等特性。</p>

<p> 一个典型的数据仓库系统可以满足中低速数据处理的需求：底层HDFS，之上是MR、Tez、Spark,再上面则是Hive、Pig；此外，直接跑在HDFS上的Presto、Impala等也是另一种方案。</p>

<p> 由于是离线计算，因此是需要一个任务调度工具来定时调度计算过程的。比较流行的一个任务调度工具是azkaban，是一个基于工作流的调度软件，在一定程度上能够满足目前的离线调度需求。</p></li>
<li><p>实时计算</p>

<p> 上面说的都是数据仓库以及离线处理需求，也是低速数据处理需求。对于高速的数据处理，则需要引出实时计算的概念，也叫流式计算。目前，storm是比较成熟和流行的流式计算技术，spark streaming则是另外一种基于批量计算的流式计算技术。所谓流式计算，就是指数据过来的时候立刻进行处理，基本无延迟，但是不够灵活，计算过的数据也不能回放，因此也无法替代上面说的数据仓库和离线计算技术。</p></li>
<li><p>资源调度</p>

<p> 综上的所有东西都在同一个集群上运行，需要达到一个有序工作的状况。因此，需要一个资源调度系统来调度这些工作，MR2.0带来的yarn就是负责此工作的一个框架。目前，docker on yarn，storm on yarn等on yarn技术的出现都得益于此框架，大大提高了大数据集群的资源使用率。此外，mesos也是另一种资源调度框架。</p></li>
<li><p>协调服务</p>

<p> 一个分布式系统能够有条不紊的运行离不开协调服务的功劳。不管是hadoop还是storm、kakfa等，都是需要通过zookeeper进行协调的。zookeeper在分布式服务中扮演的角色就类似其字面意思-动物园管理员，而大数据的各个组件就类似动物园中的动物们。</p></li>
<li><p>集群监控</p>

<p> 集群的稳定性对于一个数据系统是至关重要的。因此，集群监控技术也是需要重点考虑的一点。目前，ganglia是对hadoop进行监控一个较好的工具。除了hadoop之外，ganglia也可以对kafka、zookeeper、storm等集群进行监控。当然，只要支持jmx，任何集群都是可以通过ganglia进行监控的。</p></li>
<li><p>数据可视化</p>

<p> 最近几年，数据可视化是一个很火的概念。尤其是大数据的可视化，考虑到高效、速度以及体验等等问题，并非是个很简单的事情。目前，百度开源的echarts是比较好的一个可视化前端解决方案，在大数据可视化方面支持的也比较好。</p></li>
</ol>


<p>《大数据：可扩展实时系统的原理和最佳实践》一书的作者将big data相关的开源项目做了以下分类：</p>

<ol>
<li>批量计算系统：延时较高、吞吐量大，如Hadoop。</li>
<li>序列化框架：为对象和字段提供一种模式定义语言，实现传输通信以及不同语言环境之间的转化。如Thrift, Protocol Buffers, 和Avro。</li>
<li>支持任意存取的NoSQL数据库：牺牲了SQL强大的表现力优势，根据应用场景不同仅支持部分操作。按照CAP理论来说，就是牺牲C（一致性）或A（可用性）来实现AP或CP。如Cassandra, HBase, MongoDB,Voldemort, Riak, CouchDB等。</li>
<li>消息/排队系统：保证进程之间以容错和异步的方式传递消息，在实时处理系统中非常重要。如Kestrel。</li>
<li>实时计算系统：高吞吐、低延时的流处理系统。如Storm。</li>
</ol>


<h3>一般架构</h3>

<p>下图为一个典型的大数据系统架构：</p>

<p><img src="//images/blog_images/data-arch.png" alt="data-arch" /></p>

<p>这里还需要提到的是Lambda架构这个概念。Lambda架构是由Storm的作者Nathan Marz提出的一个实时大数据处理框架。目标是设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。Lambda架构整合离线计算和实时计算，融合不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，可集成Hadoop，Kafka，Storm，Spark，Hbase等各类大数据组件。</p>

<p><img src="//images/blog_images/lambda-arch.png" alt="lambda-arch" /></p>

<p>Lambda架构是由三层组成：批处理层、服务层和速度层，总体可由query = function(alldata)这个公式来表示。</p>

<ul>
<li>批处理层：Hadoop是理想的批处理层工具。特点是延时较高、高吞吐量，并且是append-only（没有delete和update的概念）的。包括对全部数据集的预计算。</li>
<li>服务层：用于加载和显示数据库中的批处理视图，以便用户能够查询。可以使用Impala作为这一层的工具（使用Hive元数据指向HDFS中的一个表）。</li>
<li>速度层：主要处理新数据和服务层更新造成的高延迟补偿，利用流处理系统如 (Storm, Spark)计算实时视图(HBase)。这些视图有效期一直到它们已经能通过批处理和服务层获得时为止。</li>
</ul>


<p>为了获得一个完整结果，批处理和实时视图都必须被同时查询和融合(实时代表新数据)。</p>

<p>当然，架构的引入是不能照本宣科的，还是需要根据实际情况进行调整，以更好地适应业务场景。</p>

<h2><a name='数据统计'></a>数据统计</h2>

<p>数据统计是数据首当其冲的一个作用。关于数据统计，有以下几个关键点：</p>

<ol>
<li>数据统计是业务导向的，需要和数据分析师、运营、市场等需求方做好充分的沟通，且很关键的一点要区分清楚哪些是真正的需求，哪些仅仅是临时需求，对于前者需要以对待产品的态度去对待，后者则一过性产生结果即可。</li>
<li>数据统计一般来说都是pv、uv这些累加指标。使用数据库自带的累加器即可，如hbase/redis的incr。</li>
<li>数据统计在牵扯到用户、IP时，有些业务是需要去重的。去重的方案有bitmap、bloomfilter等，其中，redis的hyperloglog在容许一定误差的情况下使用比较广泛。</li>
<li>用户统计中的用户质量模型是比较复杂的一个地方。这个地方需要一定的建模，才能做到更好的判断一个用户的质量。通常，把一个新增用户一周内以及一周后的活跃情况作为这个用户质量的判别标准。</li>
</ol>


<h2><a name='个性化推荐'></a>个性化推荐</h2>

<p>由于个性化推荐是“机器学习”的典型应用，因此这里首先要讲一下“机器学习”。</p>

<p>机器学习是为了让机器具有人的学习能力，目的是建模隐藏的数据结构，然后做识别、预测、分类等。大多数情况下，这相当于将一组数据传递给算法，并由算法判断出与这些数据的属性相关的信息，借助这些信息可以预测出未来有可能出现的其他数据。对于机器学习广泛的一个定义是“利用经验来改善计算机系统自身的性能”，而计算机中的经验都是以数据的形式存在的。机器学习的一个典型过程就是机器利用它所认定的出现于数据中的重要特征对数据进行“训练”，并借此得到一个模型。</p>

<p>此外，与机器学习相关的还有几个名词会被混淆或者概念不清。</p>

<ul>
<li>集体智慧：简称集智，它是一种共享的或群体的智能。百度百科、维基百科、百度知道、猪八戒网等都是目前使用集体智慧的一种形式；数据挖掘、机器学习同样需要大量群体的数据才能做出计算，是使用集体智慧的另一种形式。</li>
<li>数据挖掘：数据挖掘就是试图从海量数据中找出有用的信息。数据挖掘支撑技术包含了机器学习、数据库、统计学等。其中，数据库提供数据管理技术，机器学习和统计学提供了数据分析技术。但是由于机器学习并不以大数据作为处理对象，因此数据挖掘要对算法进行改造，使得算法性能和空间占用达到实用的地步。</li>
<li>模式识别：模式识别是一种目的。传统的模式识别的方法一般分为两种：统计方法和句法方法。句法分析一般是不可学习的，而统计分析则是发展了不少机器学习的方法。因此机器学习给模式识别提供了数据分析技术。当然，也就是因为几乎所有的非随机数据都会包含这样或者那样的“模式(pattern)”，才使得机器学习的预测是可能的。</li>
</ul>


<p>总之，机器学习也是使用数据的一个很关键的领域，典型应用有个性化推荐、CTR预估、模式识别等。牵扯到的算法、技术非常多。如此部分开头所说，其中的个性化推荐是应用最广泛的领域，用到了很多机器学习相关技术。</p>

<p>从本质上看，个性化推荐和大家接触很普遍的搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，其输入特征是从搜索关键字可以直接得到的。而个性化推荐中，输入特征则是需要使用机器学习相关技术才能得到。</p>

<p>个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。</p>

<ul>
<li>日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。</li>
<li>推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。</li>
<li>内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。</li>
</ul>


<p>其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：</p>

<ul>
<li>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</li>
<li>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。</li>
<li>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。</li>
</ul>


<p>个性化推荐系统的典型架构如下图所示：</p>

<p><img src="//images/blog_images/recommend-sys/recommend-sys-arch.png" alt="recommend-sys" /></p>

<p>在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。</p>

<p>基于此框架，个性化推荐系统的典型流程如下：</p>

<p><img src="//images/blog_images/recommend-sys/recommend-sys.png" alt="recommend-sys" /></p>

<p>其他更为详细的，个性化推荐牵扯到的算法、细节还有很多，留待后续推荐系统相关文章中再谈。</p>

<h2><a name='总结'></a>总结</h2>

<p>无论是互联网还是其他领域的产品，数据的作用正变得越来越重要。综合来看，数据统计和机器学习/个性化推荐是目前最关键的使用数据的领域。基于具体的需求，搭建合适的数据系统是解决问题的关键。其中，大数据是在应对大规模数据的情况下合适的技术选型架构。</p>

<h2><a name='参考资料'></a>参考资料</h2>

<ul>
<li><a href="https://book.douban.com/subject/26596778/">《计算广告》</a></li>
<li><a href="https://book.douban.com/subject/10769749/">《推荐系统实践》</a></li>
<li><a href="https://www.zhihu.com/question/27974418/answer/38965760">知乎@Xiaoyu Ma的有关回答</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
