<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kafka | 后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/blog/categories/kafka/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2018-04-01T22:22:04+08:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[kafka学习笔记 - Consumer开发的一些关键点]]></title>
    <link href="http://www.rowkey.me/blog/2015/05/30/kafka-consumer/"/>
    <updated>2015-05-30T22:00:18+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/05/30/kafka-consumer</id>
    <content type="html"><![CDATA[<p>Kafka的consumer是以pull的形式获取消息数据的。不同于队列和发布-订阅模式，kafka采用了consumer group的模式。通常的，一般采用一个consumer中的一个group对应一个业务，配合多个producer提供数据。</p>

<p><img src="//images/blog_images/kafka-consumer.jpg" alt="pic" /></p>

<h2>一. 消费过的数据无法再次消费</h2>

<p>在user level上，一旦消费过topic里的数据，那么就无法再次用同一个groupid消费同一组数据。如果想要再次消费数据，要么换另一个groupid，要么使用镜像：</p>

<p><img src="//images/blog_images/kafka-consumer-1.jpg" alt="pic" /></p>

<p>此外，low level的api提供了一些机制去设置partion和offset。</p>

<h2>二. offset管理</h2>

<p>kafka会记录offset到zk中。但是，zk client api对zk的频繁写入是一个低效的操作。0.8.2 kafka引入了native offset storage，将offset管理从zk移出，并且可以做到水平扩展。其原理就是利用了kafka的compacted topic，offset以consumer group,topic与partion的组合作为key直接提交到compacted topic中。同时Kafka又在内存中维护了<consumer group,topic,partition>的三元组来维护最新的offset信息，consumer来取最新offset信息的时候直接内存里拿即可。当然，kafka允许你快速的checkpoint最新的offset信息到磁盘上。</p>

<h2>三. stream</h2>

<p>This API is centered around iterators, implemented by the KafkaStream class. Each KafkaStream represents the stream of messages from one or more partitions on one or more servers. Each stream is used for single threaded processing, so the client can provide the number of desired streams in the create call. Thus a stream may represent the merging of multiple server partitions (to correspond to the number of processing threads), but each partition only goes to one stream.</p>

<p>根据官方文档所说，stream即指的是来自一个或多个服务器上的一个或者多个partition的消息。每一个stream都对应一个单线程处理。因此，client能够设置满足自己需求的stream数目。总之，一个stream也许代表了多个服务器partion的消息的聚合，但是每一个partition都只能到一个stream。</p>

<h2>四. consumer和partition</h2>

<ol>
<li>如果consumer比partition多，是浪费，因为kafka的设计是在一个partition上是不允许并发的，所以consumer数不要大于partition数</li>
<li>如果consumer比partition少，一个consumer会对应于多个partitions，这里主要合理分配consumer数和partition数，否则会导致partition里面的数据被取的不均匀</li>
<li>如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同</li>
<li>增减consumer，broker，partition会导致rebalance，所以rebalance后consumer对应的partition会发生变化</li>
<li>High-level接口中获取不到数据的时候是会block的</li>
</ol>


<p>负载低的情况下可以每个线程消费多个partition。但负载高的情况下，Consumer 线程数最好和Partition数量保持一致。如果还是消费不过来，应该再开 Consumer 进程，进程内线程数同样和分区数一致。（多谢 @shadyxu 指出）</p>

<h2>五. high-level的consumer工具</h2>

<ol>
<li><p>bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker &ndash;group pv</p>

<p> 可以看到当前group offset的状况。</p></li>
<li><p>bin/kafka-run-class.sh kafka.tools.UpdateOffsetsInZK earliest config/consumer.properties  page_visits</p>

<pre><code> 3个参数， 
 [earliest | latest]，表示将offset置到哪里 
 consumer.properties ，这里是配置文件的路径 
 topic，topic名，这里是page_visits
</code></pre></li>
</ol>


<h2>六. SimpleConsumer</h2>

<p>kafka的low-level接口，使用场景：</p>

<ol>
<li>读取一个消息多次。</li>
<li>在一个进程中仅仅消费某一个topic中几个partition的数据.</li>
<li>管理事务以确保一个消息处理且仅仅被处理一次。</li>
</ol>


<p>用这个接口需要注意一下几点：</p>

<ol>
<li>在应用中必须跟踪记录offset以确保能够确定上次消费到的位置。</li>
<li>必须设置哪一个broker是要操作的topic和partition的leader。</li>
<li>必须自己控制broker的leader的改变。</li>
</ol>


<p>使用步骤：</p>

<ol>
<li>找出一个active状态的broker并且找出哪一个broker是那些topic和partition的leader，必须知道读哪个topic的哪个partition。</li>
<li>找到负责该partition的broker leader，从而找到存有该partition副本的那个broker。</li>
<li>自己去写request并fetch数据。</li>
<li>获取数据。</li>
<li>需要识别和处理broker leader的改变。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[kafka学习笔记 - 使用与配置]]></title>
    <link href="http://www.rowkey.me/blog/2015/05/30/kafka-usage/"/>
    <updated>2015-05-30T21:01:18+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/05/30/kafka-usage</id>
    <content type="html"><![CDATA[<h2>目录</h2>

<ul>
<li><a href="#%E4%B8%80.%20%E4%BD%BF%E7%94%A8">一. 使用</a></li>
<li><a href="#%E4%BA%8C.%20%E5%85%B3%E9%94%AE%E9%85%8D%E7%BD%AE">二. 关键配置</a></li>
<li><a href="#%E4%B8%89.%20Storm-kafka%E4%BD%BF%E7%94%A8">三. Storm-kafka使用</a></li>
</ul>


<p>本文一、二部分内容主要来自官方文档。</p>

<h2><a name='一. 使用'></a>一. 使用</h2>

<ol>
<li><p>下载代码</p>

<p> <a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.0/kafka_2.10-0.8.2.0.tgz">https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.0/kafka_2.10-0.8.2.0.tgz</a></p>

<pre><code> tar -xzf kafka_2.10-0.8.2.0.tgz
 cd kafka_2.10-0.8.2.0
</code></pre></li>
<li><p>启动服务器</p>

<p> kafka依赖zookeeper，所以需要首先安装并启动zookeeper。可以使用kafka自带的zookeeper。</p>

<pre><code> bin/zookeeper-server-start.sh config/zookeeper.properties
</code></pre>

<p> 然后即可启动kafka</p>

<pre><code> bin/kafka-server-start.sh config/server.properties
</code></pre></li>
<li><p>创建topic</p>

<p> 消息传输需要指定topic。所以首先要创建一个topic。</p>

<pre><code> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
</code></pre>

<p> 之后，可以看到已经创建的topic.其中的replication-factor指的是复制因子，即log冗余的份数，这里的数字不能大于broker的数量。</p>

<pre><code> bin/kafka-topics.sh --list --zookeeper localhost:2181
</code></pre>

<p> 也可以不用手动创建topic，只需要配置broker的时候设置为auto-create topic when a non-existent topic is published to.</p></li>
<li><p>发送消息</p>

<p> kafka提供了一个命令行客户端，可以从一个文件或者标准输入里读取并发送到kafka集群。默认的，每一行都作为一个单独的消息。</p>

<pre><code> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 
</code></pre>

<p> 在命令行输入消息并回车即可发送消息。</p></li>
<li><p>启动一个消费者</p>

<p> kafka也提供了一个命令行消费者，接受消息并打印到标准输出。</p>

<pre><code> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
</code></pre></li>
<li><p>设置多broker集群</p>

<p> 首先需要为每一个broker创建一个配置文件。</p>

<pre><code> cp config/server.properties config/server-1.properties 
 cp config/server.properties config/server-2.properties

 config/server-1.properties:
     broker.id=1
     port=9093
     log.dirs=/tmp/kafka-logs-1

 config/server-2.properties:
     broker.id=2
     port=9094
     log.dirs=/tmp/kafka-logs-2  
</code></pre>

<p> 然后启动这两个结点：</p>

<pre><code> bin/kafka-server-start.sh config/server-1.properties &amp;
 bin/kafka-server-start.sh config/server-2.properties &amp;
</code></pre>

<p> 现在一共有了三个结点，三个broker，那么这样就可以形成一个集群。</p>

<p> 创建一个复制引子为3的topic</p>

<pre><code> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
</code></pre>

<p> 如果想查看目前这个topic的partion在broker上的分布情况</p>

<pre><code> bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
</code></pre></li>
</ol>


<h2><a name='二. 关键配置'></a>二. 关键配置</h2>

<h3>2.1 broker</h3>

<ul>
<li>broker.id: broker的唯一标识符，集群环境该值不可重复。</li>
<li>log.dirs: 一个用逗号分隔的目录列表，可以有多个，用来为Kafka存储数据。每当需要为一个新的partition分配一个目录时，会选择当前的存储partition最少的目录来存储。</li>
<li>zookeeper.connect：zookeeper访问地址，多个地址用’,’隔开</li>
<li>message.max.bytes: server能接收的一条消息的最大的大小。这个属性跟consumer使用的最大fetch大小是一致的，这很重要，否则一个不守规矩的producer会发送一个太大的消息。默认值：1000000。</li>
</ul>


<h3>2.2 producer</h3>

<ul>
<li>metadata.broker.list： kafka的broker列表，格式为host1:port1,host2:port2</li>
<li>request.required.acks：用来控制一个produce请求怎样才能算完成，准确的说，是有多少broker必须已经提交数据到log文件，并向leader发送ack，可以设置如下的值：

<ul>
<li>0，意味着producer永远不会等待一个来自broker的ack，这就是0.7版本的行为。这个选项提供了最低的延迟，但是持久化的保证是最弱的，当server挂掉的时候会丢失一些数据。</li>
<li>1，意味着在leader replication已经接收到数据后，producer会得到一个ack。这个选项提供了更好的持久性。</li>
<li>-1，意味着在所有的ISR都接收到数据后，producer才得到一个ack。这个选项提供了最好的持久性，只要还有一个replication存活，那么数据就不会丢失。</li>
</ul>
</li>
<li>producer.type：决定消息是否应在一个后台线程异步发送。async表示异步发送；sync表示同步发送。设置为async则允许批量发送请求，这回带来更高的吞吐量，但是client的机器挂了的话会丢失还没有发送的数据。</li>
<li>serializer.class: 消息的序列化使用的class，如kafka.serializer.StringEncoder</li>
</ul>


<p>更多细节参见kafka.consumer.ProducerConfig类。</p>

<h3>2.3 consumer</h3>

<ul>
<li>group.id: 唯一的指明了consumer的group的名字，group名一样的进程属于同一个consumer group。</li>
<li>zookeeper.connect: 通broker的配置</li>
<li>consumer.id：consumer的唯一标识符，如果没有设置的话则自动生成。</li>
<li><strong><em>fetch.message.max.bytes</em></strong>：每一个获取某个topic的某个partition的请求，得到最大的字节数，每一个partition的要被读取的数据会加载入内存，所以这可以帮助控制consumer使用的内存。这个值的设置不能小于在server端设置的最大消息的字节数，否则producer可能会发送大于consumer可以获取的字节数限制的消息。默认值：1024 * 1024。</li>
<li><strong><em>fetch.min.bytes</em></strong>：一个fetch请求最少要返回多少字节的数据，如果数据量比这个配置少，则会等待，直到有足够的数据为止。默认值：1。</li>
<li><strong><em>fetch.wait.max.ms</em></strong>：在server回应fetch请求前，如果消息不足，就是说小于fetch.min.bytes时，server最多阻塞的时间。如果超时，消息将立即发送给consumer。默认值：100。</li>
<li><strong><em>socket.receive.buffer.bytes</em></strong>: socket的receiver buffer的字节大小。默认值：64 * 1024。</li>
</ul>


<p>更多细节参见kafka.consumer.ConsumerConfig类。</p>

<h2><a name='三. Storm-kafka使用'></a>三. Storm-kafka使用</h2>

<p>Kafka很多使用场景是输出消息到Storm的，Storm本身也提供了storm-kafka的包，在使用Storm的KafkaSpout时需要注意以下几点：</p>

<ul>
<li><p>在采用基于SimpleConsumer的消费端实现时，我们遇到过一个情况是大量的轮询导致整个环境网络的流量异常，原因是该topic一直没有新消息，consumer端的轮询没有设置等待参数，也没有在client线程里判断进行一个短暂的sleep。几乎是以死循环的方式不断跟server端通讯，尽管每次的数据包很小，但只要有几个这样的消费端足以引起网络流量的异常。这里需要设置maxWait参数，但是此参数必须与minBytes配合使用才有效。但是在storm-kafka的KafkaUtils中的fetchMessages方法中对minBytes没有设置，因此即使设置了maxWait也没有效果。这里需要自己重写KafkaUtils来解决。</p>

<pre><code>  FetchRequest fetchRequest = builder.addFetch(topic, partitionId, offset, config.fetchSizeBytes).                    clientId(config.clientId).maxWait(config.fetchMaxWait).minBytes(1).build(); // 此处是修复了原来代码里没有设置minBytes
</code></pre></li>
<li><p>修复了上述问题后，后来还是遇到网络流量异常的情况，后来在追踪KafkaSpout源码的过程中，发现当kafka中的消息过大时，如果不设置合适的bufferSizeBytes以及fetchSizeBytes(至少要大于kafka中最大消息的大小)，那么很容易造成客户端由于bufferSizeBytes或者fetchSize设置过小，无法将消息放入buffer中也不能成功fetch而不停地去轮询服务端，从而导致网络流量异常。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[kafka学习笔记 - 介绍]]></title>
    <link href="http://www.rowkey.me/blog/2015/05/30/kafka-intro/"/>
    <updated>2015-05-30T20:06:18+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/05/30/kafka-intro</id>
    <content type="html"><![CDATA[<h2>什么是kafka</h2>

<p>最近公司需要上基于nginx log的数据统计系统。其中一个重要的结点即分布式日志收集。在调研了多种方案之后，最终确定了flume+kafka+storm+hbase的系统架构。其中kafka则是linkedin一个专门为日志而产生的service。官方文档上如是说：Kafka是一个分布式、分区、冗余的commit日志service。它提供了一种特殊设计的消息系统功能。</p>

<!--more-->


<p>以下内容来自官方文档。</p>

<h2>特点</h2>

<ul>
<li>不支持事务</li>
<li>不保证全局消息顺序，可以保证partition消息顺序</li>
<li>顺序写磁盘，性能可媲美内存操作</li>
<li>无论消息是否被消费，都会持久化保存（保存时间可以设置）</li>
<li>消费者看到的消息顺序即是保存在log中的顺序</li>
<li>对于一个复制因子(replication factor)为N的topic,可以保证在N-1个server挂掉的情况下，已经提交到log中的消息不会丢失。</li>
</ul>


<h2>组成部分</h2>

<p>总体结构如下图：</p>

<p><img src="//images/blog_images/producer_consumer.png" alt="" />p</p>

<ul>
<li>kafka将消息以category的方式保存在一起，称为topic</li>
<li>向topic产生消息的进程称为producer</li>
<li>处理topic上的消息的进程称为consumer</li>
<li>kafka集群由一个或者多个server组成，称为broker.</li>
</ul>


<h3>Topics and Logs</h3>

<p>topic是kafka提供的高一层的抽象。</p>

<p>一个topic指的是消息发布到的一个分类或者feed名称。对于每一个topic，kafka集群都保存了一个分区log，如下：</p>

<p><img src="//images/blog_images/log_anatomy.png" alt="" /></p>

<p>每一个分区都是一个提交日志，一系列有序的、不可变顺序的消息连续地追加到上面。</p>

<p>每一个在分区中的消息都会被指定一个顺序编号offset，这个值可以唯一标识这个分区中的每一个消息。</p>

<p>无论一个消息是否已经被消费过，kfka集群都会保存这个消息（保存时间可以设置）。例如，如果log的保存时长设置为两天，那么在一个消息发布后的两天内都是可以被消费的，之后才被丢弃。kafaka在数据容量方面的性能实际上是可以用常量衡量的，所以保存大量的数据并不是一个问题。</p>

<p>对于每一个消费者来说，其仅仅需要保存的元数据就是在kafka日志的位置，称为“offset”。消费者控制这个值：一般情况下，当消费者读取消息的时候，增加offset，但是实际上消费者可以任意顺序读取消息。例如，消费者能够重置到一个旧的offset做再次处理。</p>

<p>上面说到的一些特性表明kafka的消费者是非常轻量级的，并不受到集群或者其他消费者的影响。例如，可以使用命令行工具去“tail”任何topic的内容，而不需要改变任何已经被消费过的内容。</p>

<p>日志中的partition有以下几个作用：</p>

<ul>
<li>日志可以在单个服务器上扩展。虽然单个partition的扩展必须适应于所在的服务器，但是一个topic有许多partition，因此能够承载大量的数据。</li>
<li>partition作为并行的一个单元</li>
</ul>


<h3>分布式</h3>

<p>日志的partition分布在kafka集群的服务器上，其中的每一个服务器都控制一组分区上的数据和请求。每一个分区通过一定数量的服务器的冗余提高容错率。</p>

<p>每一个partition都有一个服务器作为&#8221;leader&#8221;，零个或者多个服务器作为“followers”。对于某一个partition,Leader控制所有的读写请求，followers被动地去冗余leader。如果leader发生了故障，那么followers中的一个会自动地成为新的leader。每一个服务器对于其中的一部分partition是做为leader,对于其他的partition则是做为follower，这样就能很好的在集群内部做好负载均衡。</p>

<h3>生产者</h3>

<p>生产者向所选择的topics发布消息。生产者负责选择哪一个消息被指定到topic的哪一个partition中。这个也可以通过round-robin简单地做负载均衡或者按照一些语义分区机制（例如基于消息中的一些key）来做。</p>

<h3>消费者</h3>

<p>传统的消息机制有两种模型：队列和发布-订阅。在队列模型中，一个由消费者组成的池从服务器读取消息，每一个消息都可以达到其中的某一个消费者；在发布-订阅模型中，消息被广播到所有消费者中。kafka融合这两种方式提供了一个消费者抽象：consumer group。</p>

<p>消费者以消费者group name给自己打标签，每一个消息都会发布到一个topic，然后传递到每一个注册的消费者group中的消费者实例。消费者实例可以在单独的进程或者机器上。</p>

<p>如果所有的消费者实例都在同一个消费者group中，那么工作机制就类似于传统的队列。</p>

<p>如果每一个消费者实例都在不同的消费者group中，那么就类似于发布-订阅模型，所有消息被广播到所有消费者。</p>

<p>更为普遍的，topic具有几个消费者group。每一个group由许多消费者实例组成，以备扩展和容错。比起发布-订阅模型，用消费者cluster替代了单一进程。</p>

<p>在消息顺序方面，kafka也具有比传统的消息系统更好的保障机制。</p>

<p>传统的队列在服务端保存消息的顺序，服务端按照存储的顺序传递消息，多consumer去消费这些消息。然而，即使服务端按照顺序交出消息，但是消息是异步传递给消费者的，那么这些消息可能乱序到达不同的消费者。这也意味着消息的顺序在并发消费的情况下丢失了。消息系统通常用一个概念“执行消费者”来完成消息的顺序传递，即只允许一个进程从一个队列中消费消息，当然这样也意味着在处理过程中没有了并行化处理。</p>

<p>kafka里有一个概念叫做parallelism—the partition—within the topics，能够同时为一个consume池提供顺序保证和负载均衡。指定分区到一个消费者group中的消费者，这样每一个分区只被这个group中的一个consumer消费。此consumer则成为这个分区唯一的reader去顺序消费这些数据。当有许多partitions，这样也能同时将这些consumer实例进行负载均衡。值得注意的一点是不能有比分区数目更多的消费者实例。</p>

<p>kafa仅仅能够提供一个partition中的消息顺序保证。如果你需要一个完全的消息顺序保障，那么可以通过仅仅具有一个partition的topic来实现，当然，这样就意味着这里仅仅有一个消费者进程。</p>

<h3>保证</h3>

<p>kafka在高层次上可以给予以下保障：</p>

<ul>
<li>通过同一个生产者发出到某个topic上partition的消息将会以其原始发送顺序附加到partition上。</li>
<li>一个消费者实例看到消息的顺序即其在log中的顺序。</li>
<li>对于一个复制引子为N的topic，其可以允许N-1个服务器故障而不丢失任何已经提交到log中的消息。</li>
</ul>


<h3>使用场景</h3>

<ol>
<li><p>消息传输</p>

<p> kafka能够很好地替代传统的消息代理。消息代理的使用场景多种多样（缓冲消息生产者的消息）。相比大多数消息系统kafka具有更好地吞吐量，内建的分区机制、复制、容错，这让它成为一个大规模消息处理的不错的选择。</p>

<p> 消息系统使用者一般要求的是低吞吐，但是同时也要求端对端的低延迟。</p>

<p> 这个场景下，另外经常用到的传统消息系统有ACtiveMQ和RabbitMQ。</p></li>
<li><p>网站行为追踪</p>

<p> 最开始kafka是用来构建一个用户行为追踪管道，作为一个实时发布-订阅feed系统。这意味着站点活动（pv，搜索或者其他用户会产生的行为）会被发布到中央topics，对应于每一中行为对应一个topic。如此，可以包括多种使用场景包括实时处理、实时监控等。</p>

<p> 由于对于每一个uv会产生大量行为消息，因此行为追踪的量级通常会非常大。</p></li>
<li><p>度量</p>

<p> kafka通常被用来操作监控数据。包括聚合分布式应用的统计数据，产生操作数据的中心feed。</p></li>
<li><p>日志聚合</p>

<p> 日志聚合也叫做日志分布式收集，同样的方案有flume、scribe等。与之相比，kafka提供了差不多的性能、更强的可持续保证以及更低的端到端的延迟。</p></li>
<li><p>流处理</p>

<p> 在用户、内容推荐领域，需要对数据流进行处理，kakfa经常被用来聚合、收集原始数据然后传输到新的topic中。一般结合storm和samza使用。</p></li>
<li><p>事件源</p>

<p> 事件源是一种针对策略变动的记录作为时间序记录的应用设计。kafka对大规模log数据存储的支持使得它能够非常好支持事件源的设计。</p></li>
<li><p>提交日志</p>

<p> kakfa可以为分布式系统提供一种外部的提交日志。日志可以冗余结点间、act间的数据，作为一个re-syncing机制。此外，kafka的日志压缩也是一个优势。此场景，kafka的使用和Apache的BookKeeper类似。</p></li>
</ol>

]]></content>
  </entry>
  
</feed>
