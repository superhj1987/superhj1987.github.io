
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!-->
<html class="no-js" lang="zh-CN"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>后端技术杂谈 | 飒然Hang</title>
  <meta name="author" content="飒然Hang">
  <!--[if lt IE 9]>
    <script src="http://x.papaapp.com/farm1/a571d2/8dda131d/html5shiv.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
    <![endif]-->
  
  <meta name="description" content="也谈IO模型 Jan 18th, 2016 目录 前言
IO模型
网络编程模型
参考资料 前言 说到IO模型，都会牵扯到同步、异步、阻塞、非阻塞这几个词。从词的表面上看，很多人都觉得很容易理解。但是细细一想，却总会发现有点摸不着头脑。自己也曾被这几个词弄的迷迷糊糊的，每次看相关资料弄明白了， &hellip;">
  

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.rowkey.me/blog/posts/7/">
  <link href="/favicon.ico" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <!-- <script src="http://cdn.staticfile.org/jquery/1.9.1/jquery.min.js"></script> -->
  <script src="//cdn.staticfile.org/jquery/2.0.3/jquery.min.js"></script>
  <link href="/atom.xml" rel="alternate" title="后端技术杂谈 | 飒然Hang" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link rel="stylesheet" href="/stylesheets/comment.css">
<link rel="stylesheet" href="//cdn.staticfile.org/highlight.js/9.10.0/styles/default.min.css">
<style type="text/css">
  span#cnzz_stat_icon_1257166229{
  	display: none !important
  }
  .btn_primary{
    color: #fff;
    background-color: #006dcc;
    background-image: linear-gradient(to bottom,#08c,#04c);
    border-color: rgba(0,0,0,.1) rgba(0,0,0,.1) rgba(0,0,0,.25);
    padding: 4px 12px;
    margin-bottom: 0;
    font-size: 14px;
    line-height: 20px;
    vertical-align: middle;
    cursor: pointer;
    border-radius: 4px;
    box-shadow: inset 0 1px 0 rgba(255,255,255,.2), 0 1px 2px rgba(0,0,0,.05);
    display: inline-block;
    text-align: center;
  }
  #recent-comments .comment-widget-content {
      color: #000000 !important;
  }
</style>

  

</head>
<body   >
  <header id="header" class="clearfix">    <!-- cnzz统计 -->
    <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1257166229'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1257166229%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                <a id="logo" href="/">
                   后端技术杂谈
                </a>
                <p class="description">What、Why、How</p>
            </div>
            <div id="m-search">
                <section class="widget">
    <form action="http://cn.bing.com/search" method="get" target="_blank" onsubmit="return doSearch(this)">
    <div class="content">
      <input type="text" class="textfield searchtip" name="s" placeholder="请输入关键字" size="24" value="">
    </div>
    </form>
    <form action="http://cn.bing.com/search" method="get" target="_blank" style="display:none" name="frmSearch">
    <div class="content">
      <input type="hidden" name="q" value="">
    </div>
    </form>
</section>
<script type="text/javascript">
  function doSearch(o){
    var $s = $(o).find("input[name=s]");
    var $q = $(o).next("form").find("input[name=q]");
    $q.val($s.val() + " site:rowkey.me");
    $(o).next("form").submit();
    return false;
  }
</script>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="index-nav current" href="/">首页</a>
<a class="java-nav" href="/blog/categories/java">Java</a>
<a class="architecture-nav" href="/blog/categories/architecture">架构</a>
<a class="categories-nav" href="/blog/categories">分类</a>
<a class="archives-nav" href="/blog/archives">归档</a>
<a class="about-nav" href="/about_me.html">关于</a>
                </nav>
            </div>
        </div>
    </div>
</header>
  <div id="body">
    <div class="container">
    	<div class="col-group">
			  <div class="col-8" id="main">
    <div class="res-cons">
    
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2016/01/18/io-model/">也谈IO模型</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2016-01-18T07:41:31+00:00" pubdate data-updated="true">Jan 18<sup>th</sup>, 2016</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><h2>目录</h2>

<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a></li>
<li><a href="#IO%E6%A8%A1%E5%9E%8B">IO模型</a></li>
<li><a href="#%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B">网络编程模型</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li>
</ul>


<h2><a name='前言'></a>前言</h2>

<p>说到IO模型，都会牵扯到同步、异步、阻塞、非阻塞这几个词。从词的表面上看，很多人都觉得很容易理解。但是细细一想，却总会发现有点摸不着头脑。自己也曾被这几个词弄的迷迷糊糊的，每次看相关资料弄明白了，然后很快又给搞混了。经历过这么几次之后，发现这东西必须得有所总结提炼才不至于再次混为一谈。尤其是最近看到好几篇讲这个的文章，很多都有谬误，很容易把本来就搞不清楚的人弄的更加迷糊。</p>

<p>最适合IO模型的例子应该是咱们平常生活中的去餐馆吃饭这个场景，下文就结合这个来讲解一下经典的几个IO模型。在此之前，先需要说明以下几点：</p>

<ul>
<li>IO有内存IO、网络IO和磁盘IO三种，通常我们说的IO指的是后两者。</li>
<li>阻塞和非阻塞，是函数/方法的实现方式，即在数据就绪之前是立刻返回还是等待，即发起IO请求是否会被阻塞。</li>
<li>以文件IO为例,一个IO读过程是文件数据从磁盘→内核缓冲区→用户内存的过程。同步与异步的区别主要在于数据从内核缓冲区→用户内存这个过程需不需要用户进程等待，即实际的IO读写是否阻塞请求进程。(网络IO把磁盘换做网卡即可)</li>
</ul>


<p><strong><em>更新了有关异步非阻塞IO;修正了java aio的说明</em></strong></p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/01/18/io-model/">继续阅读 &rarr;</a>
    </footer>
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2016/01/10/git-cheatsheet/">Git CheatSheet</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2016-01-10T02:15:30+00:00" pubdate data-updated="true">Jan 10<sup>th</sup>, 2016</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><p><strong><em>ps:本指南会持续更新</em></strong></p>

<p>其实一般情况下，只需要掌握git的几个常用命令即可，但是在使用的过程中难免会遇到各种复杂的需求，这时候经常需要搜索，非常麻烦，故总结了一下自己平常会用到的git操作。</p>

<p><img src="/images/blog_images/git-process.png" alt="git-process" /></p>

<p>上图所示，使用git的流程一般如此，通常使用图中的六个命令即可。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/01/10/git-cheatsheet/">继续阅读 &rarr;</a>
    </footer>
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/12/31/dev-job-talk/">研发招聘之殇</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-12-31T14:01:02+00:00" pubdate data-updated="true">Dec 31<sup>st</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><p><strong><em>ps: 本文完成于2015年12月31号</em></strong></p>

<p>对于一个公司来说，要想健康长久的发展，招聘是一个永久的话题。而对于一个互联网公司，尤其是以产品为主的公司来说，研发是招聘中的关键职位，高质量的研发人才也是所有企业都急缺的。一直持有一个观点：招一个优秀的人给他两倍的薪资带来的效果远远大于招两个普通的人。也一直秉着这个观点来招聘。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/12/31/dev-job-talk/">继续阅读 &rarr;</a>
    </footer>
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/12/21/front-these-years/">前端这些年</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-12-21T10:53:48+00:00" pubdate data-updated="true">Dec 21<sup>st</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><h2>前言</h2>

<p>本人一直从事的是服务端开发工作，写前端貌似有点跑题，不过自己初中也就是2000年左右的时候，引领我进入计算机大门的也的确是前端，后来也做过不少的前端工作。于是，就想着从自己的角度写点前端这些年的发展。但毕竟不是专业所长，有所纰漏在所难免。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/12/21/front-these-years/">继续阅读 &rarr;</a>
    </footer>
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/11/20/2015books/">2015年读过的书</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-11-20T09:13:46+00:00" pubdate data-updated="true">Nov 20<sup>th</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><h2>技术</h2>

<h3>1. 精益数据分析</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/26278639/">http://book.douban.com/subject/26278639/</a></li>
<li>说明：一本讲述数据驱动创业的书籍，比如在你的产品中如何区分虚荣指标，如何抓住关键指标等。对于每一个商业模式都有其特定的关键指标和底线。而且对于一个公司的几个阶段（移情、黏性、病毒性、营收、规模化）指标也不是相同的。商业模式+阶段决定了你需要关注的指标。</li>
<li>进度：100%</li>
</ul>


<h3>2. 推荐系统实践</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/10769749/">http://book.douban.com/subject/10769749/</a></li>
<li>说明：讲述了构建一个推荐系统的基本知识、算法以及架构等。基本涵盖了能实现一个基本的推荐系统所需的相关技术等。看完这本书，基本能对推荐系统入门。</li>
<li>进度：100%</li>
<li>备注：此书上大学时曾经看过，但当时由于没有实战环境，所以没啥印象。此次阅读是基于项目需要，但其中部分牵扯到具体算法的部分没有细看</li>
</ul>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/11/20/2015books/">继续阅读 &rarr;</a>
    </footer>
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/11/13/your-own-github/">搭建自己的github</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-11-13T02:27:40+00:00" pubdate data-updated="true">Nov 13<sup>th</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><p>说起github，大家应该都是非常熟悉的。正是github的兴起，带来了开源的一个高潮，也诞生了无数优秀的开源项目。最最著名的Linux也在github上有了自己的repository。当然，github的核心技术git也是李纳斯的代表作。</p>

<p>记得几年前由于项目的需要，曾尝试自己去搭建一套git服务给项目组使用，折腾了好久，才总算搭建了一个基础的系统, 刚刚能用，权限控制都没有(<a href="http://srhang.iteye.com/blog/1339110">http://srhang.iteye.com/blog/1339110</a>)。但最终因为git的上手门槛有点高，还是选择了svn。后来随着github的兴起，git才如火如荼地在国内火了起来。许多大的互联网公司，也都开始把项目由svn转到git。但如果仅仅是搭建一个git服务，那么github这种网站提供的可视化ui带来的便捷却也不复存在了。对于一些小的有钱的团队，使用github的收费私人repository倒也是一种解决办法。但是，对于大部分公司来说，还是不会把公司内部的代码放到这种公共服务上的。这种需求场景下，就诞生了很多github的克隆实现，以方便部署内网的github。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/11/13/your-own-github/">继续阅读 &rarr;</a>
    </footer>
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/09/09/load-analysis/">系统负载能力浅析</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-09-09T10:42:58+00:00" pubdate data-updated="true">Sep 9<sup>th</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><p><strong><em>&mdash;本文于2015.12.23最新更新&mdash;</em></strong></p>

<p>互联网时代，高并发是一个老生常谈的话题。无论对于一个web站点还是app应用，高峰时能承载的并发请求都是衡量一个系统性能的关键标志。像阿里双十一顶住了上亿的峰值请求、订单也确实体现了阿里的技术水平（当然有钱也是一个原因）。</p>

<p>那么，何为系统负载能力？怎么衡量？相关因素有哪些？又如何优化呢？</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/09/09/load-analysis/">继续阅读 &rarr;</a>
    </footer>
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/06/10/hbase-about/">Hbase关键的几个点</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-06-10T02:59:59+00:00" pubdate data-updated="true">Jun 10<sup>th</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><h2>一. 什么时候需要HBase</h2>

<ol>
<li><p>半结构化或非结构化数据</p>

<p> 对于数据结构字段不够确定或杂乱无章很难按一个概念去进行抽取的数据适合用HBase。当业务发展需要增加存储比如一个用户的email，phone，address信息时RDBMS需要停机维护，而HBase支持动态增加.</p></li>
<li><p>记录非常稀疏</p>

<p> RDBMS的行有多少列是固定的，为null的列浪费了存储空间。而如上文提到的，HBase为null的Column不会被存储，这样既节省了空间又提高了读性能。</p></li>
<li><p>多版本数据</p>

<p> 根据Row key和Column key定位到的Value可以有任意数量的版本值，因此对于需要存储变动历史记录的数据，用HBase就非常方便了。对于某一值，业务上一般只需要最新的值，但有时可能需要查询到历史值。</p></li>
<li><p>超大数据量</p>

<p> 当数据量越来越大，RDBMS数据库撑不住了，就出现了读写分离策略，通过一个Master专门负责写操作，多个Slave负责读操作，服务器成本倍增。随着压力增加，Master撑不住了，这时就要分库了，把关联不大的数据分开部署，一些join查询不能用了，需要借助中间层。随着数据量的进一步增加，一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按ID取模分成多个表以减少单个表的记录数。经历过这些事的人都知道过程是多么的折腾。采用HBase就简单了，只需要加机器即可，HBase会自动水平切分扩展，跟Hadoop的无缝集成保障了其数据可靠性（HDFS）和海量数据分析的高性能（MapReduce）</p></li>
</ol>


<h2>二. HTable一些基本概念</h2>

<ol>
<li><p>Row key</p>

<p> 行主键， HBase不支持条件查询和Order by等查询，读取记录只能按Row key（及其range）或全表扫描，因此Row key需要根据业务来设计以利用其存储排序特性（Table按Row key字典序排序如1,10,100,11,2）提高性能。</p></li>
<li><p>Column Family（列族）</p>

<p> 在表创建时声明，每个Column Family为一个存储单元。</p></li>
<li><p>Column（列）</p>

<p> HBase的每个列都属于一个列族，以列族名为前缀，如列article:title和article:content属于article列族，author:name和author:nickname属于author列族。</p>

<p> Column不用创建表时定义即可以动态新增，同一Column Family的Columns会群聚在一个存储单元上，并依Column key排序，因此设计时应将具有相同I/O特性的Column设计在一个Column Family上以提高性能。</p></li>
<li><p>Timestamp</p>

<p> HBase通过row和column确定一份数据，这份数据的值可能有多个版本，不同版本的值按照时间倒序排序，即最新的数据排在最前面，查询时默认返回最新版本。Timestamp默认为系统当前时间（精确到毫秒），也可以在写入数据时指定该值。</p></li>
<li><p>Value</p>

<p> 每个值通过4个键唯一索引，tableName+RowKey+ColumnKey+Timestamp=>value</p></li>
<li><p>存储类型</p>

<ul>
<li>TableName 是字符串</li>
<li>RowKey 和 ColumnName 是二进制值（Java 类型 byte[]）</li>
<li>Timestamp 是一个 64 位整数（Java 类型 long）</li>
<li>value 是一个字节数组（Java类型 byte[]）。</li>
</ul>
</li>
</ol>


<p>将HTable的存储结构理解为</p>

<p><img src="/images/blog_images/hbase_data.jpg" alt="hbase-data" /></p>

<p>即HTable按Row key自动排序，每个Row包含任意数量个Columns，Columns之间按Column key自动排序，每个Column包含任意数量个Values。理解该存储结构将有助于查询结果的迭代。</p>

<h2>三. 模式设计应遵循的原则</h2>

<ol>
<li><p>列族的数量以及列族的势</p>

<p> 列族的数量越少越好，牵扯到了hbase的flushing；同一个表中不同列族所存储的记录数量的差别也需要考虑（列族的势），会造成记录数量少的列族的数据分散在多个region上，影响查询效率。</p></li>
<li><p>行键的设计</p>

<p> 避免使用时序或者单调（递增/递减）行键，否则会导致连续到来的数据会被分配到统一region中。</p></li>
<li><p>尽量最小化行键和列族的大小</p>

<p> 避免hbase的索引过大，加重系统存储的负担</p></li>
<li><p>版本的数量</p>

<p> HColumnDescriptor设置版本的数量，避免设置过大，版本保留过多。</p></li>
</ol>

</div>
  
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/05/30/kafka-consumer/">Kafka学习笔记 - Consumer开发的一些关键点</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-05-30T14:00:18+00:00" pubdate data-updated="true">May 30<sup>th</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><p>Kafka的consumer是以pull的形式获取消息数据的。不同于队列和发布-订阅模式，kafka采用了consumer group的模式。通常的，一般采用一个consumer中的一个group对应一个业务，配合多个producer提供数据。</p>

<p><img src="/images/blog_images/kafka-consumer.jpg" alt="pic" /></p>

<h2>一. 消费过的数据无法再次消费</h2>

<p>在user level上，一旦消费过topic里的数据，那么就无法再次用同一个groupid消费同一组数据。如果想要再次消费数据，要么换另一个groupid，要么使用镜像：</p>

<p><img src="/images/blog_images/kafka-consumer-1.jpg" alt="pic" /></p>

<p>此外，low level的api提供了一些机制去设置partion和offset。</p>

<h2>二. offset管理</h2>

<p>kafka会记录offset到zk中。但是，zk client api对zk的频繁写入是一个低效的操作。0.8.2 kafka引入了native offset storage，将offset管理从zk移出，并且可以做到水平扩展。其原理就是利用了kafka的compacted topic，offset以consumer group,topic与partion的组合作为key直接提交到compacted topic中。同时Kafka又在内存中维护了<consumer group,topic,partition>的三元组来维护最新的offset信息，consumer来取最新offset信息的时候直接内存里拿即可。当然，kafka允许你快速的checkpoint最新的offset信息到磁盘上。</p>

<h2>三. stream</h2>

<p>This API is centered around iterators, implemented by the KafkaStream class. Each KafkaStream represents the stream of messages from one or more partitions on one or more servers. Each stream is used for single threaded processing, so the client can provide the number of desired streams in the create call. Thus a stream may represent the merging of multiple server partitions (to correspond to the number of processing threads), but each partition only goes to one stream.</p>

<p>根据官方文档所说，stream即指的是来自一个或多个服务器上的一个或者多个partition的消息。每一个stream都对应一个单线程处理。因此，client能够设置满足自己需求的stream数目。总之，一个stream也许代表了多个服务器partion的消息的聚合，但是每一个partition都只能到一个stream。</p>

<h2>四. consumer和partition</h2>

<ol>
<li>如果consumer比partition多，是浪费，因为kafka的设计是在一个partition上是不允许并发的，所以consumer数不要大于partition数</li>
<li>如果consumer比partition少，一个consumer会对应于多个partitions，这里主要合理分配consumer数和partition数，否则会导致partition里面的数据被取的不均匀</li>
<li>如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同</li>
<li>增减consumer，broker，partition会导致rebalance，所以rebalance后consumer对应的partition会发生变化</li>
<li>High-level接口中获取不到数据的时候是会block的</li>
</ol>


<p>负载低的情况下可以每个线程消费多个partition。但负载高的情况下，Consumer 线程数最好和Partition数量保持一致。如果还是消费不过来，应该在增加partition数的同时增加consumer数或者通过某些手段提升消息处理能力。需要注意的是，由于Kafka主要是磁盘读写，Partition的增多如果是单个磁盘那么在并发性能上会有瓶颈,可以通过增加磁盘来扩展并发能力。</p>

<h2>五. high-level的consumer工具</h2>

<ol>
<li><p>bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker &ndash;group pv</p>

<p> 可以看到当前group offset的状况。</p></li>
<li><p>bin/kafka-run-class.sh kafka.tools.UpdateOffsetsInZK earliest config/consumer.properties  page_visits</p>

<pre><code> 3个参数， 
 [earliest | latest]，表示将offset置到哪里 
 consumer.properties ，这里是配置文件的路径 
 topic，topic名，这里是page_visits
</code></pre></li>
</ol>


<h2>六. SimpleConsumer</h2>

<p>kafka的low-level接口，使用场景：</p>

<ol>
<li>读取一个消息多次。</li>
<li>在一个进程中仅仅消费某一个topic中几个partition的数据.</li>
<li>管理事务以确保一个消息处理且仅仅被处理一次。</li>
</ol>


<p>用这个接口需要注意一下几点：</p>

<ol>
<li>在应用中必须跟踪记录offset以确保能够确定上次消费到的位置。</li>
<li>必须设置哪一个broker是要操作的topic和partition的leader。</li>
<li>必须自己控制broker的leader的改变。</li>
</ol>


<p>使用步骤：</p>

<ol>
<li>找出一个active状态的broker并且找出哪一个broker是那些topic和partition的leader，必须知道读哪个topic的哪个partition。</li>
<li>找到负责该partition的broker leader，从而找到存有该partition副本的那个broker。</li>
<li>自己去写request并fetch数据。</li>
<li>获取数据。</li>
<li>需要识别和处理broker leader的改变。</li>
</ol>

</div>
  
  


      </article>
    
    
      <article class="post">
        
  <header>
    
      <h2 class="post-title"><a href="/blog/2015/05/30/kafka-usage/">Kafka学习笔记 - 使用与配置</a></h2>
    
    
      <p class="post-meta">
        








  


<time datetime="2015-05-30T13:01:18+00:00" pubdate data-updated="true">May 30<sup>th</sup>, 2015</time>
        
        
      </p>
    
  </header>


  <div class="post-content"><h2>目录</h2>

<ul>
<li><a href="#%E4%B8%80.%20%E4%BD%BF%E7%94%A8">一. 使用</a></li>
<li><a href="#%E4%BA%8C.%20%E5%85%B3%E9%94%AE%E9%85%8D%E7%BD%AE">二. 关键配置</a></li>
<li><a href="#%E4%B8%89.%20Storm-kafka%E4%BD%BF%E7%94%A8">三. Storm-kafka使用</a></li>
</ul>


<p>本文一、二部分内容主要来自官方文档。</p>

<h2><a name='一. 使用'></a>一. 使用</h2>

<ol>
<li><p>下载代码</p>

<p> <a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.0/kafka_2.10-0.8.2.0.tgz">https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.0/kafka_2.10-0.8.2.0.tgz</a></p>

<pre><code> tar -xzf kafka_2.10-0.8.2.0.tgz
 cd kafka_2.10-0.8.2.0
</code></pre></li>
<li><p>启动服务器</p>

<p> kafka依赖zookeeper，所以需要首先安装并启动zookeeper。可以使用kafka自带的zookeeper。</p>

<pre><code> bin/zookeeper-server-start.sh config/zookeeper.properties
</code></pre>

<p> 然后即可启动kafka</p>

<pre><code> bin/kafka-server-start.sh config/server.properties
</code></pre></li>
<li><p>创建topic</p>

<p> 消息传输需要指定topic。所以首先要创建一个topic。</p>

<pre><code> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
</code></pre>

<p> 之后，可以看到已经创建的topic.其中的replication-factor指的是复制因子，即log冗余的份数，这里的数字不能大于broker的数量。</p>

<pre><code> bin/kafka-topics.sh --list --zookeeper localhost:2181
</code></pre>

<p> 也可以不用手动创建topic，只需要配置broker的时候设置为auto-create topic when a non-existent topic is published to.</p></li>
<li><p>发送消息</p>

<p> kafka提供了一个命令行客户端，可以从一个文件或者标准输入里读取并发送到kafka集群。默认的，每一行都作为一个单独的消息。</p>

<pre><code> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 
</code></pre>

<p> 在命令行输入消息并回车即可发送消息。</p></li>
<li><p>启动一个消费者</p>

<p> kafka也提供了一个命令行消费者，接受消息并打印到标准输出。</p>

<pre><code> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
</code></pre></li>
<li><p>设置多broker集群</p>

<p> 首先需要为每一个broker创建一个配置文件。</p>

<pre><code> cp config/server.properties config/server-1.properties 
 cp config/server.properties config/server-2.properties

 config/server-1.properties:
     broker.id=1
     port=9093
     log.dirs=/tmp/kafka-logs-1

 config/server-2.properties:
     broker.id=2
     port=9094
     log.dirs=/tmp/kafka-logs-2  
</code></pre>

<p> 然后启动这两个结点：</p>

<pre><code> bin/kafka-server-start.sh config/server-1.properties &amp;
 bin/kafka-server-start.sh config/server-2.properties &amp;
</code></pre>

<p> 现在一共有了三个结点，三个broker，那么这样就可以形成一个集群。</p>

<p> 创建一个复制引子为3的topic</p>

<pre><code> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
</code></pre>

<p> 如果想查看目前这个topic的partion在broker上的分布情况</p>

<pre><code> bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
</code></pre></li>
</ol>


<h2><a name='二. 关键配置'></a>二. 关键配置</h2>

<h3>2.1 broker</h3>

<ul>
<li>broker.id: broker的唯一标识符，集群环境该值不可重复。</li>
<li>log.dirs: 一个用逗号分隔的目录列表，可以有多个，用来为Kafka存储数据。每当需要为一个新的partition分配一个目录时，会选择当前的存储partition最少的目录来存储。</li>
<li>zookeeper.connect：zookeeper访问地址，多个地址用’,’隔开</li>
<li>message.max.bytes: server能接收的一条消息的最大的大小。这个属性跟consumer使用的最大fetch大小是一致的，这很重要，否则一个不守规矩的producer会发送一个太大的消息。默认值：1000000。</li>
</ul>


<h3>2.2 producer</h3>

<ul>
<li>metadata.broker.list： kafka的broker列表，格式为host1:port1,host2:port2</li>
<li>request.required.acks：用来控制一个produce请求怎样才能算完成，准确的说，是有多少broker必须已经提交数据到log文件，并向leader发送ack，可以设置如下的值：

<ul>
<li>0，意味着producer永远不会等待一个来自broker的ack，这就是0.7版本的行为。这个选项提供了最低的延迟，但是持久化的保证是最弱的，当server挂掉的时候会丢失一些数据。</li>
<li>1，意味着在leader replication已经接收到数据后，producer会得到一个ack。这个选项提供了更好的持久性。</li>
<li>-1，意味着在所有的ISR都接收到数据后，producer才得到一个ack。这个选项提供了最好的持久性，只要还有一个replication存活，那么数据就不会丢失。</li>
</ul>
</li>
<li>producer.type：决定消息是否应在一个后台线程异步发送。async表示异步发送；sync表示同步发送。设置为async则允许批量发送请求，这回带来更高的吞吐量，但是client的机器挂了的话会丢失还没有发送的数据。</li>
<li>serializer.class: 消息的序列化使用的class，如kafka.serializer.StringEncoder</li>
</ul>


<p>更多细节参见kafka.consumer.ProducerConfig类。</p>

<h3>2.3 consumer</h3>

<ul>
<li>group.id: 唯一的指明了consumer的group的名字，group名一样的进程属于同一个consumer group。</li>
<li>zookeeper.connect: 通broker的配置</li>
<li>consumer.id：consumer的唯一标识符，如果没有设置的话则自动生成。</li>
<li><strong><em>fetch.message.max.bytes</em></strong>：每一个获取某个topic的某个partition的请求，得到最大的字节数，每一个partition的要被读取的数据会加载入内存，所以这可以帮助控制consumer使用的内存。这个值的设置不能小于在server端设置的最大消息的字节数，否则producer可能会发送大于consumer可以获取的字节数限制的消息。默认值：1024 * 1024。</li>
<li><strong><em>fetch.min.bytes</em></strong>：一个fetch请求最少要返回多少字节的数据，如果数据量比这个配置少，则会等待，直到有足够的数据为止。默认值：1。</li>
<li><strong><em>fetch.wait.max.ms</em></strong>：在server回应fetch请求前，如果消息不足，就是说小于fetch.min.bytes时，server最多阻塞的时间。如果超时，消息将立即发送给consumer。默认值：100。</li>
<li><strong><em>socket.receive.buffer.bytes</em></strong>: socket的receiver buffer的字节大小。默认值：64 * 1024。</li>
</ul>


<p>更多细节参见kafka.consumer.ConsumerConfig类。</p>

<h2><a name='三. Storm-kafka使用'></a>三. Storm-kafka使用</h2>

<p>Kafka很多使用场景是输出消息到Storm的，Storm本身也提供了storm-kafka的包，在使用Storm的KafkaSpout时需要注意以下几点：</p>

<ul>
<li><p>在采用基于SimpleConsumer的消费端实现时，我们遇到过一个情况是大量的轮询导致整个环境网络的流量异常，原因是该topic一直没有新消息，consumer端的轮询没有设置等待参数，也没有在client线程里判断进行一个短暂的sleep。几乎是以死循环的方式不断跟server端通讯，尽管每次的数据包很小，但只要有几个这样的消费端足以引起网络流量的异常。这里需要设置maxWait参数，但是此参数必须与minBytes配合使用才有效。但是在storm-kafka的KafkaUtils中的fetchMessages方法中对minBytes没有设置，因此即使设置了maxWait也没有效果。这里需要自己重写KafkaUtils来解决。</p>

<pre><code>  FetchRequest fetchRequest = builder.addFetch(topic, partitionId, offset, config.fetchSizeBytes).                    clientId(config.clientId).maxWait(config.fetchMaxWait).minBytes(1).build(); // 此处是修复了原来代码里没有设置minBytes
</code></pre></li>
<li><p>修复了上述问题后，后来还是遇到网络流量异常的情况，后来在追踪KafkaSpout源码的过程中，发现当kafka中的消息过大时，如果不设置合适的bufferSizeBytes以及fetchSizeBytes(至少要大于kafka中最大消息的大小)，那么很容易造成客户端由于bufferSizeBytes或者fetchSize设置过小，无法将消息放入buffer中也不能成功fetch而不停地去轮询服务端，从而导致网络流量异常。</p></li>
</ul>

</div>
  
  


      </article>
    
      <div class="page-navigator">
        
        
            <a href="/blog/posts/6" class="prev"><<上一页</a>
        
        
            <a href="/blog/posts/8" class="next">下一页>></a>
        
        <div class="center"><a href="/blog/archives">所有文章</a></div>
      </div>
     </div>
  </div>
    
  <aside id="secondary">
  <div id="sidebar">
  
    <section class="widget" style="font-size:9pt" id="copyright">
<p><span style="font-weight:bold">版权声明：</span>本博客所有文章为博主原创或翻译文章，采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">知识共享署名-非商业性使用-相同方式共享4.0</a> 国际许可协议共享，转载请注明作者和原文链接。</p>
</section><section class="widget">
    <form action="http://cn.bing.com/search" method="get" target="_blank" onsubmit="return doSearch(this)">
    <div class="content">
      <input type="text" class="textfield searchtip" name="s" placeholder="请输入关键字" size="24" value="">
    </div>
    </form>
    <form action="http://cn.bing.com/search" method="get" target="_blank" style="display:none" name="frmSearch">
    <div class="content">
      <input type="hidden" name="q" value="">
    </div>
    </form>
</section>
<script type="text/javascript">
  function doSearch(o){
    var $s = $(o).find("input[name=s]");
    var $q = $(o).next("form").find("input[name=q]");
    $q.val($s.val() + " site:rowkey.me");
    $(o).next("form").submit();
    return false;
  }
</script><!--公告-->
<section class="widget" id="notice">
	<div style="margin-bottom: 10px" >
		<span>出版图书：</span><h4 style="margin: 0px !important;display:inline"><a href="https://github.com/superhj1987/pragmatic-java-engineer/tree/master/book" target="_blank">《Java工程师修炼之道》</a></h4>
	</div>
	<p>中华万年历/微鲤看看技术团队长期求<a href="https://m.zhipin.com/weijd/v2/job/0cdf0b4c4c3029521nN5392-FFc~" style="font-weight: bold" target="_blank">各研发职位</a>，感兴趣者可发送简历到<a href="mailto:hang@weli.cn">hang@weli.cn</a>。</p>
	<div style="margin-bottom: 10px">
	原博客：<a href="http://srhang.iteye.com/" target="_blank">http://srhang.iteye.com/</a>
	</div>
</section><section class="widget" id="social">
		
		<a class="weibo" href="http://weibo.com/superhj1987" title="Weibo" target="_blank">Weibo</a>
		
		
			<a class="github" href="https://github.com/superhj1987" title="GitHub" target="_blank">GitHub</a>
		
		
		
		
			<a class="linkedin" href="http://www.linkedin.com/in/superhj1987" title="LinkedIn" target="_blank">LinkedIn</a>
		
		
		
		
		
		
		
    	
    	
			<a class="rss" href="/atom.xml" title="RSS" target="_blank">RSS</a>
		
</section><section class="widget">
	<h3 class="widget-title">最新文章</h3>
	<ul class="widget-list">
		
     	<li>
      	  <a href="/blog/2019/09/28/restful/">数据传输之RESTful</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/08/23/solve-problem/">如何培养解决问题的意识</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/07/27/springboot/">使用Spring Boot快速开发</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/06/29/log/">Java开发框架之日志</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/05/30/msa/">微服务杂谈</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/04/22/upforprogrammer/">这些知识决定了程序员的上限（PPT版）</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/04/13/netflix/">技术 in Netflix</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/03/08/interview-basic/">技术面试的应该与不应该</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/02/25/cache/">缓存这些事</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2019/01/26/my2018/">我的2018</a>
      	</li>
    	
	</ul>
</section>
<section class="widget" style="margin-bottom: 0px !important">
	<h3 class="widget-title">最新评论</h3>
	<div id="recent-comments">暂无</div>
</section>


<section>
  <h3 class="widget-title">GitHub Repos</h3>
  <ul id="gh_repos" class="widget-list">
    <li class="loading">数据读取中&#8230;</li>
  </ul>
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'superhj1987',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section class="widget">
	<h3 class="widget-title">技术酷站</h3>
	<ul class="widget-list">
     	<li><a href="http://toutiao.io/" target="_blank">开发者头条</a></li>
     	<li><a href="https://dzone.com/java-jdk-development-tutorials-tools-news" target="_blank">DZone - Java Zone</a></li>
		<li><a href="http://ifeve.com/" target="_blank">并发编程网</a></li>
	</ul>
</section>
  
  </div>
  </aside>
      	</div>
    </div>
  </div>
  <footer id="footer">
  	<div class="container">
	Copyright &copy; 2019 - 飒然Hang -
  <span class="credit">Powered by <a rel="nofollow" href="http://octopress.org">Octopress</a></span>
  - <span class="credit">Theme by <a rel="nofollow" href="http://pagecho.com">Cho</a></span>


</div>
<link href="/stylesheets/scrollUp.min.css" media="screen, projection" rel="stylesheet" type="text/css">
<script type="text/javascript" src="/javascripts/libs/jquery.scrollUp.min.js"></script>
<script src="//cdn.staticfile.org/marked/0.3.6/marked.min.js"></script>
<script src="//cdn.staticfile.org/timeago.js/3.0.1/timeago.min.js"></script>
<script src="//cdn.staticfile.org/spin.js/2.3.2/spin.min.js"></script>
<script src="//cdn.staticfile.org/highlight.js/9.10.0/highlight.min.js"></script>
<script type="text/javascript">
  marked.setOptions({
  highlight: function (code, lang) {
     return hljs.highlightAuto(code).value;
  }
  });
  function Highlighting(){
    var markdowns = document.getElementsByClassName('markdown');
    for(var i=0;i<markdowns.length;i++){
       if(markdowns[i].innerHTML) markdowns[i].innerHTML =marked(markdowns[i].innerHTML);
    }
  }
  window.addEventListener('DOMContentLoaded', Highlighting, false);
  window.addEventListener('load', Highlighting, false);
</script>
<script src="/javascripts/comment.js"></script>
<script type="text/javascript">
$(function(){
	$.scrollUp({
		appendId: 'footer'
	});
});
var opt = {
   type: "github",
   user: "superhj1987",
   repo: "superhj1987.github.io",
   no_comment: "还没有评论",
   go_to_comment: "点击评论",
   issue_title: "",
   btn_class: "btn_primary",
   comments_target: "#comment-thread",
   loading_target: "#loading-spin",
   client_id: "528dd6945e3a48c2a954",
   client_secret: "e71312e081ef3dd87cc3425ada7080cd3b296f0d"
};
getComments(opt);
opt = {
   type: "github",
   user: "superhj1987",
   repo: "superhj1987.github.io",
   recent_comments_target: "#recent-comments",
   count: 5,
   client_id: "528dd6945e3a48c2a954",
   client_secret: "e71312e081ef3dd87cc3425ada7080cd3b296f0d"
};
getRecentCommentsList(opt);
</script>

  </footer>
  











</body>
</html>
