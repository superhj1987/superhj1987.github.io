<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2021-02-04T13:14:44+00:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[我的2020]]></title>
    <link href="http://www.rowkey.me/blog/2021/01/13/my2020/"/>
    <updated>2021-01-13T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2021/01/13/my2020</id>
    <content type="html"><![CDATA[<p>最近因为新业务的事情一直没有写文章，发现已经4个月没有产出。年初给自己定的每个月至少产出一篇文章的目标算是啪啪打自己脸了。不过虽然2021年已经过去大半个月了，2020年的总结还是要补上的。</p>

<!--more-->


<p>2020年整体的印象就是疫情了，从年初武汉疫情的愈演愈烈，到年底的死灰复燃，新冠这个事情感觉就没消停过。上半年由于疫情和各种因素的影响，公司在组织和业务上都发生了很大的变动。对我自己负责的部分来说，整年的一个目标就是降低技术成本，而与降本经常被一起提的增效在业务目前的形势下，则显得没那么重要了。从全年来看，整个技术团队在技术成本上有了明显的降低，提高效能的交付流水线、代码分析平台、DevOps平台、Flutter上也都有明显的进展和效果。总体来看，整个技术团队的成绩还是在期望中，但是鉴于目前公司的形式和状况，很多事情的优先级和重要性则还需要进一步的调整和优化。</p>

<p>还是按照工作、学习和生活三个方面来总结我自己的2020年。</p>

<h2>工作</h2>

<p>如上面所说，今年工作上主要围绕降低成本、提高效能来展开，尤其是降低成本。而今年让我感触最深的可能是“业务价值”这个词。对于一个商业公司来说，其本质就是寻求产生更多的净利润，所以衡量技术的价值根本就是看他能不能产生业务价值。以前做技术选型或者引入，都是以技术价值优先，而今年公司的状况，更应该是先看是否有业务价值，再去考虑技术实现。比较明显的一个例子就是19年引入的APM系统，当时看来是觉得要紧跟业界趋势，为后续的微服务做好基础建设，而如果以业务价值来看，对于今年的业务状况，性能并不是关键问题，这种系统的价值就很低。</p>

<h3>降本</h3>

<p>在业务高速发展的时候，对于技术服务、资源的使用是比较粗暴的，甚至一些Redis都达到了1T的大小。而有了降本的前提，需要围绕资源做以下工作。</p>

<ul>
<li>资源的价格优惠：通过框架协议或者商务谈判来争取更低的折扣，从而实现价格的降低。</li>
<li>提高资源的利用率：通过梳理监控各个资源的使用率，对于使用率较少的资源进行缩容；引入容器技术，弹性分配资源，提高资源利用率；在申请资源时做好充分的量化和预估，减少资源的浪费。</li>
<li>减少不再使用或者价值不高的资源：梳理公司的资源，理清有哪些资源，是否存在闲置无流量的资源。对比业务产出和业务技术成本，对于业务价值无法覆盖技术成本的业务及时反馈，及时决定是否下线。</li>
<li>梳理出成本占比高的资源，评估其是否有性价比更高的方案。</li>
<li>构建业务中台、技术平台、技术组件化，提高资源复用率，避免重复建设，减少浪费。</li>
</ul>


<p>随着业务的调整，也经过一年的努力，最终技术成本降低到了年初的1/3，是今年可圈可点的一部分工作。</p>

<h3>增效</h3>

<p>在提高效能这方面，今年有明显进展的包括以下几部分</p>

<ul>
<li>DevOps平台：研发完全可以通过平台来申请资源，自动生成部署流水线，大大解放了运维的生产力，并且进一步推进了公司所有后端服务的容器化，实现了资源的弹性调度和使用。</li>
<li>Flutter技术：实现了初步的引入，后续需要通过更有效的措施进行推广。从而改变一个功能需要两端开发的现状，降低开发成本。</li>
<li>持续交付流水线：接入了自动化测试环节，同时在客户端得到了有效的推进，使得公司的交付基本完全进入了自动化阶段，有效提高了交付速度和质量。</li>
<li>大数据上云：旨在利用云的弹性特点，减少运维工作量。在综合考虑了运维成本、团队发展、云服务质量、配合度、稳定性、性能等因素后，最终选择了华为云做为多云方案中的第二家供应商。目前已经逐步在实施中。</li>
</ul>


<h3>平台业务</h3>

<p>技术中心的工作还有很大一部分是在平台业务上，包括支撑市场投放的平台、支撑消费品业务的消费品助理平台、支撑数据分析的大数据平台、支撑内部效率的WeOKR平台等。今年这几个平台都有不小的进展。</p>

<ul>
<li>Wolves市场投放系统完成了2.0大版本的开发。</li>
<li>消费品助理平台实现了打款助手、供货商管理、财务结算、数据大盘、选品助手等功能。</li>
<li>WeOKR系统支撑了今年公司考核机制的转型。</li>
<li>Lepoard的事件分析功能已经完成了书签、概览等功能的开发。</li>
</ul>


<p>区别于底层的技术平台，这一块偏向于业务，但又不直接服务于业务。其业务价值也是我一直在思考的事情。
如何量化出其业务价值是非常难的事情。但在公司目前的状况下，却也不得不去思考。目前采取的方式就是根据业务的需求提出量和调用量来分摊人力成本和业务价值。可能更好的思路是采用类似于内部虚拟货币结算的方式来体现业务价值，这也是打算尝试的方案。</p>

<h3>游戏</h3>

<p>12月份左右决定开始启动游戏业务的尝试做为公司的另一个利润增长点。对于我自己来说，不管是直接负责一个业务还是游戏本身这个领域，都是迈出了自己的舒适区。不知道这个行业的现状，不知道一个游戏团队的组成，不知道该不该去做，不知道该怎么做。从决定进入这个行业开始，自己就处于一种既兴奋又紧绷的状态，是一种很久未感受到的压力。</p>

<p>一开始通过去拜访一些游戏行业的公司和参加游戏行业的会议去学习。差不多花了将近两周的时间，在很多朋友的帮助下，基本摸清了游戏行业的一个大概情况。再综合公司目前的状况，确定了团队的构成和游戏的方向。到目前为止，团队基本成型，第一款游戏也快出来了。期间从0到1，自己一个一个人去面试，去沟通，去规划工作，去协调公司和外部的资源，目前看来结果还在期望中。但后续的游戏发行和游戏的立项才是重中之重，紧绷的状态估计还得一直持续下去。</p>

<p>希望游戏业务能有一个好的结果吧。</p>

<h2>学习</h2>

<p>今年的学习，可能主要是对游戏行业的学习了，尤其是对于休闲游戏，自己在求教了很多朋友以及看了很多文章和新闻后，基本上有了自己一个比较客观的认识，也算是开始踏入了游戏这个行业。</p>

<p>而在书籍阅读方面，由于一些客观原因，完成的也有限。</p>

<ul>
<li><p>极客时间<a href="https://time.geekbang.org/column/intro/100034501">《研发效率破局之道》</a></p>

<blockquote><p>出自FaceBook的大神结合自己的实践给出的如何提升研发效率的经验总结。包括软件开发的本质是什么、如何定义和选择研发效率衡量指标。并从研发流程、工程方法、个人效能以及管理和文化四个方面来阐述了如何提高研发效率。其中的很多知识都具有实操性，自己已经借鉴用在了公司中。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/6862062/">持续交付: 发布可靠软件的系统方法</a></p>

<blockquote><p>这本书不同于去年读过的《持续交付2.0》，更侧重于持续交付实现的细节，尤其在自动化测试方面花费了很多笔墨。总体上，其从如何让团队达成持续交付的共识、基础设施和环境管理、配置管理、测试策略、数据管理、持续交付管理、部署流水线几部分对实现持续交付做了很详细的阐述。但由于出版时间的原因，某些内容如代码分支模式不是业界最新的内容。但对于想要实现部署流水线，这本书的实操性足够了。</p></blockquote></li>
<li><p>极客时间<a href="https://time.geekbang.org/column/intro/100038501">《项目管理实战20讲》</a>+<a href="https://time.geekbang.org/column/intro/100044301">《说透敏捷》</a></p>

<blockquote><p>虽然经历过前东家的项目管理流程，但一直缺乏对其系统的认识。《项目管理实战20讲》从项目管理的本质、管理角色的转变、十大领域五大过程方面阐述了项目管理。尤其对于五大过程的一些实践性阐述，很干货，我们也借鉴了不少在公司中。后面的《说透敏捷》则从敏捷的本质、敏捷的5条价值观、12原则以及如何推进敏捷上做了经验和实践的阐述，也非常具有借鉴意义。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/34960995/">发布！设计与部署稳定的分布式系统</a></p>

<blockquote><p>从上面说的《持续交付》那本书里被引导过来。读完之后总体的感觉是能够让读者对系统稳定性有系统认识和理解，但不够细节和执行。尤其感觉翻译的优点差，很多术语都是中式直译。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/2046281/">大道至简：软件工程实践者的思想</a></p>

<blockquote><p>内容主要是基于《愚公移山》故事中来讲述软件工程本质的。对我自己的启发就是，这世上万物很多本质都是一样的。软件工程类比于移山这个工程，其经历的事情和演进都有彼此想通之处。其中提出的软件工程层状模型（EHM）从程序、过程、工程、组织几个方面阐述了作者对软件工程的理解。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26901183/">我读管理经典</a></p>

<blockquote><p>这本书是作者对一些经典管理著作的学习心得的总结和思考。包括《科学管理原理》、《福利特论管理》、《工业管理与一般管理》、《社会组织与经济组织理论》、《管理行为》、《组织与管理》、《工业文明的社会问题》、《经理人员的职能》等等，梳理了管理学从科学管理到管理创新的发展历程。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/2230248/">人月神话</a></p>

<blockquote><p>重读这本经典著作，虽然其中有些东西稍显过时(如对软件开发时长的经验值，但其没有银弹、用外科手术团队类比软件开发团队仍然是延续至今可以使用的方法和认知。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26863413/">CEO说：人人都应该像企业家一样思考</a></p>

<blockquote><p>作者拿街头小贩和企业家做类比，阐述了企业的本质是商业智慧。从公司的本质、整体上理解公司、领导需要化繁为简、创造财富而不是赚钱、人岗匹配、打造齐心协力的团队等方面讲述了企业家如何思考和行动以及应该如何思考和行动。</p></blockquote></li>
</ul>


<p>以上是已经完成阅读的书籍，目前包括了2020年未完成以及新加入的待读书籍列表如下：</p>

<h3>工作</h3>

<ul>
<li>数据即未来</li>
<li>未来架构</li>
<li>极客时间《许世伟的架构课》</li>
<li>分布式系统概念与设计</li>
<li>大数据日知录</li>
<li>数据密集型系统设计</li>
</ul>


<h3>管理</h3>

<ul>
<li>别让猴子跳回背上</li>
<li>回归本源看绩效</li>
</ul>


<h3>企业</h3>

<ul>
<li>方舟：数字经济创新史</li>
<li>公司进化论</li>
<li>闪电式扩张</li>
<li>创新者的窘境</li>
<li>良性增长</li>
<li>定位：有史以来对美国营销影响最大观念</li>
<li>刷新：重新发现商业与未来</li>
<li>超级版图：全球供应链、超级城市与新商业文明的崛起</li>
</ul>


<h3>其他</h3>

<ul>
<li>程序员的三门课</li>
<li>程序员修炼之道</li>
<li>极简宇宙史</li>
<li>结构性思维：让思考和表达像搭积木一样有序省力</li>
<li>金字塔原理</li>
<li>模型思维</li>
<li>社会性动物</li>
<li>资本论</li>
<li>智慧的疆界：从图灵机到人工智能</li>
</ul>


<h2>生活</h2>

<p>生活上，每周五会和同事们一起去打两个小时篮球，然后隔一天在家里会利用杠铃、哑铃锻炼锻炼。令自己感到惊喜的是，突然有一天发现以前只能跪着做的健腹轮，现在可以站立做四五个了。但令自己失望的是，年底的体检自己以前的小毛病还是没怎么减少，都有点怀疑自己锻炼的效果了。看来必须同时控制饮食来让自己的各项指标回到以前了。另一方面，年底由于出差的次数越来越多，锻炼次数也受了不少影响。21年需要想办法在出差的时候也能够坚持锻炼。</p>

<p>其他的，生活上一切都在稳步向前，差强人意。</p>

<h2>总结</h2>

<p>以上是2020年的总结。整体来看，没有什么惊喜的一年。新的一年，自己的计划如下：</p>

<ul>
<li>重点的重点，找到游戏业务的突破方向，实现游戏业务的利润增长。</li>
<li>优化研发团队组织架构，提升业务价值，降低成本。</li>
<li>继续监控技术成本，控制成本支出，提高性价比。</li>
<li>有效推进Flutter等跨平台开发技术在公司的使用。</li>
<li>坚持锻炼身体！</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[研发效能杂谈]]></title>
    <link href="http://www.rowkey.me/blog/2020/08/13/dev-efficacy-talk/"/>
    <updated>2020-08-13T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/08/13/dev-efficacy-talk</id>
    <content type="html"><![CDATA[<p>研发效能是什么？为什么现在都在谈如何提高研发效能？研发效能对于一个企业到底有多重要？本文按照Why、What、How三步走沉淀梳理了研发效能相关的知识点。</p>

<!--more-->


<h2>一. 为什么要提升研发效能</h2>

<ul>
<li>传统的职能部门组织架构带来的效率竖井问题</li>
<li>人力的增加没有让项目进度加快</li>
<li>长久加班导致团队士气低落，后续的效率降低</li>
<li>上线前加班、熬夜，压力大</li>
<li>上线后Bug、事故频发，实现效果与需求不匹配</li>
<li>各种重复低效工作，疲于应付业务</li>
<li>想要有限的人力做更多的产出</li>
</ul>


<h2>二. 什么是研发效能</h2>

<p>对于一个企业来说，追求的是企业效能的最大化，包括：利润、用户规模、客户满意度、运营效率等。而对于需要研发自有产品的互联网公司来说，研发效能则是服务于企业效能的至关重要的因素。</p>

<p>一个软件研发的完整流程如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/dev/devprocess.png" alt="" /></p>

<p>此流程交付期望产品的效率和能力，即研发效能。更进一步的《研发效率破局之道》中将研发效能定义为团队能够持续地为用户产生有效价值的效率，包括 <strong>有效性（Effectiveness）、效率（Efficiency）和可持续性（Sustainability）</strong> 三个方面。其增加的可持续性指出研发效能应该着眼于长期效果。</p>

<p>一句话来讲，研发效能就是持续快速交付价值的能力。</p>

<h2>三. 如何提升研发效能</h2>

<p>对应于第一部分中讲述的软件开发流程，如果想要提升研发效能，那么需要落实到研发流程（组织结构、项目管理、持续交付）、工程方法、个人效能以管理和文化的实践上。本文重点从研发流程、工程方法两方面来讲。</p>

<p><img src="http://www.rowkey.me/post_images/dev/whole.png" width="800"/></p>

<h3>3.1 衡量指标</h3>

<p>评估一个组织持续快速交付价值的能力，需要一组可量化的数据或参数，用来跟踪和评估开发过程的“健康”状况。</p>

<h4>3.1.1 指标分类</h4>

<ul>
<li>持续发布能力

<ul>
<li>发布频率：单位时间内的有效发布次数</li>
<li>发布前置时间：从代码提交到功能上线花费的时间</li>
</ul>
</li>
<li>需求响应周期

<ul>
<li>交付周期时间：从确认用户提出的需求开始，到需求上线经历的平均时长。</li>
<li>开发周期时间：从开发团队理解需求开始，到需求可以上线所经历的平均时长。</li>
</ul>
</li>
<li>交付吞吐率

<ul>
<li>单位时间交付用户需求数量：单个团队的对比</li>
</ul>
</li>
<li>交付过程质量：质量内建

<ul>
<li>缺陷创建和修复时间分布：缺陷能够持续和及时地被发现，并在发现后尽快修复。</li>
<li>缺陷库存：开发过程控制缺陷库存量，让产品始终处于接近可发布状态，是持续交付的基础</li>
</ul>
</li>
<li>交付质量：系统的可用性

<ul>
<li>单位时间问题数目</li>
<li>线上问题解决时长</li>
</ul>
</li>
</ul>


<h4>3.1.2 通用目标</h4>

<ul>
<li>2：2周交付周期。从想法提出并确认到上线的时间。【跨职能、组织的协调一致和紧密协作】</li>
<li>1：1周开发周期。从需求设计完成（对开发就绪）到达到可上线的时间。【需求的拆分和管理，开发团队的分工协作模式，持续交付实践】</li>
<li>1：1小时的发布前置时间。代码提交后可以在1小时内完成发布。【持续交付流水线】</li>
</ul>


<h4>3.1.3 选择优化指标</h4>

<p>流程中总是有一个核心瓶颈。分析关键路径、定位瓶颈，针对优化</p>

<ul>
<li>使用指标来发现问题而不是做绩效考核</li>
<li>使用指标来检验优化效果</li>
<li>使用价值流图/累积流程图发现全局瓶颈，从而确定需要提升的度量指标</li>
</ul>


<h3>3.2 组织结构&amp;&amp;项目管理</h3>

<h4>3.2.1 组织结构</h4>

<p>避免“效率竖井”： 采用以业务为单位的组织架构，保证业务线全栈配齐，目标一致。并从全局定位瓶颈进而进行优化工作。</p>

<h4>3.2.2 项目管理</h4>

<p>使用敏捷开发来提升研发效率</p>

<ul>
<li>敏捷 = 价值观 + 原则 + 一系列符合价值观和原则的方法。

<ul>
<li>软件应该一直处于可工作状态</li>
<li>每个迭代都能将软件部署到一个类生产环境中，并向用户演示</li>
<li>迭代长度不超过两周</li>
<li>透明性、协作性、纪律性和持续改进</li>
</ul>
</li>
<li>使用MVP，度量驱动开发</li>
<li>流程尽快流动：工程方法支撑</li>
<li>发现整个流程中的瓶颈，并解决：可视化工作流、事故复盘</li>
<li>避免“小瀑布”

<ul>
<li>价值排序</li>
<li>满足客户需要</li>
<li>需求拆分成能够独立测试的需求！！！</li>
</ul>
</li>
<li>看板

<ul>
<li>从个人转变到关注价值流动：待开发->设计->开发->开发自测->代码评审->测试->完成</li>
<li>明确的“完成的定义”DoD，明确了状态迁移必须完成的活动</li>
</ul>
</li>
<li>从实际出发、以终为始：以实用主义的态度，从原则出发，灵活优化流程</li>
</ul>


<p>一个可供参考的项目管理标准动作可见：<a href="https://www.rowkey.cn/blog/2020/07/31/project-manage/">项目管理标准模板</a></p>

<h3>3.3 持续交付</h3>

<p>持续交付指的是在短周期内完成软件产品，以保证软件保持在随时可以发布的状态。让每一个变更都经过一条自动化的检验流水线，来检查每一个变更的质量，通过就进入下一个阶段。<strong>其不是一种工具，而是一种实践！</strong></p>

<ul>
<li><strong>不要阻塞开发人员</strong></li>
<li>每个团队指定构建负责人或者发布工程师：优化交付流水线，提升交付效率</li>
<li>项目状态，应该对参与整个过程（包括构建、部署、测试和发布）的所有人都是可见的</li>
<li>风险管理

<ul>
<li><strong>迭代增量式交付</strong>是有效风险管理的关键</li>
<li>手工测试环境、试运行环境和生产环境总是需要严格的访问控制</li>
<li>让风险识别成为每日立会的一部分</li>
</ul>
</li>
<li>审计

<ul>
<li>手工测试环境、试运行环境和生产环境总是需要严格的访问控制：指定谁能够访问“特权”环境。</li>
<li>要求每次部署都要进行审计，以确切知道到底修改了哪些内容。</li>
<li>文档自动化、自文档</li>
</ul>
</li>
</ul>


<p>具体可见：<a href="https://www.rowkey.cn/blog/2020/06/15/cd/">持续交付这点事</a></p>

<h3>3.3 工程方法</h3>

<h4>3.3.1 技术债</h4>

<p>在开发产品或者功能的过程中，没有使用最佳的实现方法而引入的技术问题。需要持续关注业务和技术债。对业务机会敏感，敢放手一搏大量借贷，也知道什么时候必须偿还技术债。</p>

<ul>
<li>利用技术债的好处，必要时要大胆“举债前行”</li>
<li>控制技术债，在适当的时候偿还适当部分的技术债。</li>
</ul>


<h4>3.4.2 云计算</h4>

<p>利用好云计算带来的<strong>服务化、自助化和弹性伸缩</strong>三大优势。初创公司在业务刚起步时，使用 SaaS 或者 PaaS 快速开发业务；业务成长到一定规模之后，再逐步转到 IaaS 以及私有云降低成本。</p>

<ul>
<li>细节抽象得越多，云服务商负责的部分就越多，我们就越能够聚焦自己的业务，从而提高研发效能</li>
<li>使用云资源时，通过工具或者 API 调用来完成工作，减少人工参与，达到自动化</li>
<li>资源共享、弹性伸缩</li>
<li>容器：不可变基础设施；基于K8S建设PaaS</li>
</ul>


<p>在使用云计算时，要妥善处理它带来的挑战，比如分布式系统带来的安全和控制方面的问题。</p>

<ul>
<li>自治和集中管理相结合：信息可视化（系统整体的质量看板、调用链追踪）</li>
<li>错误处理</li>
</ul>


<h4>3.4.3 测试机制</h4>

<p>上文持续交付一部分中最关键的其实就是测试部分，只有具有完善、可靠的测试机制，才能保证研发质量和交付效果，才能从根本上提高研发效能。</p>

<ul>
<li>测试左移：质量内建，即持续交付中的测试机制。

<ul>
<li>按照功能的维度管理团队，让整个功能团队对产品负责；改变团队成员对测试工作的认知</li>
<li>把测试添加到开发和产品需求步骤中</li>
<li>频繁测试，快速测试：提升测试运行的速度，并行运行、提高构建速度、精准测试、分层测试、减少不必要的用例</li>
</ul>
</li>
<li>测试右移

<ul>
<li>利用线上的真实环境测试：需要有完备的数据隔离机制</li>
<li>测试人员介入线上监控和预警，及时发现问题并跟进解决</li>
<li>混沌工程：即在真实环境中通过模拟各种不可预期的故障来验证系统稳定性</li>
</ul>
</li>
</ul>


<h4>3.4.4 平台化</h4>

<p>通过抽象共性组件、功能，达到代码、功能复用，从而减少重复开发，提高研发效能。</p>

<ul>
<li>技术平台：技术设施的复用</li>
<li>数据中台：数据沉淀和输出能力</li>
<li>移动中台：前端组件、跨平台开发、插件化、热加载</li>
<li>业务中台

<ul>
<li>业务能力的复用</li>
<li>赋能业务</li>
</ul>
</li>
</ul>


<p>相关资料可见：<a href="https://www.rowkey.cn/blog/2019/11/23/middle-talk/">中台简谈</a></p>

<h3>3.5 个人效能</h3>

<p>如何提高开发人员自身的开发效率，除了每个人自身的天赋能力外，也有一些可以刻意使用的高效工具和方法。</p>

<ul>
<li>高效工作方法

<ul>
<li>抽象和分而治之</li>
<li>快速迭代</li>
<li>DRY</li>
<li>番茄工作法</li>
</ul>
</li>
<li>高效开发工具

<ul>
<li>好的IDE</li>
<li>操作系统快捷键</li>
<li>思维导图软件</li>
<li>学习笔记软件</li>
<li>文档撰写工具</li>
</ul>
</li>
<li>持续学习：不断地学习新的开发技能，从而提升自己的开发效率</li>
</ul>


<p>此外，还可以通过技术管理从外部驱动个人效能的提升，这在下面的技术管理部分会讲。</p>

<h3>3.6 管理和文化</h3>

<h4>3.6.1 技术管理</h4>

<p>管理包括：看方向、管人、管事。做好技术管理是提高研发效能的关键部分。其中，3.4节个人效能部分的数字驱动也是技术管理的一部分。主要步骤包括：</p>

<ul>
<li>制定目标：兼顾业务目标和技术目标</li>
<li>目标管理：使用OKR等目标管理方案</li>
<li>计划并执行去实现目标</li>
</ul>


<p>此外，技术管理中一个很难的问题是如何进行考核。这里可以使用数字化的方式，以驱动个人效能的提升。</p>

<ul>
<li>选择个人效能度量指标</li>
<li>根据代码提交日志自动生成工作日报和周报、个人贡献值</li>
<li>综合多维数据构建个人的数据画像

<ul>
<li>社会地位：用排名、榜单来实现；</li>
<li>工作本身：用复合型报告去综合评价，告知员工究竟做得好不好</li>
<li>自我改变：通过雷达图，进行多维度的数据分析，精准提炼员工的优点与不足，员工可以有针对性的取长补短。</li>
</ul>
</li>
</ul>


<p>需要说明的是，如果指标不能全方面的衡量，就不要做为考核指标，仅仅用于发现问题，解决问题！</p>

<p>一个可参考的技术管理标准动作模板见：<a href="https://www.rowkey.cn/blog/2020/04/25/tech-leader-manage/">技术管理标准模板</a></p>

<h4>3.6.2 团队文化</h4>

<p>团队文化是团队成员共同认可的价值观和行为准则，良好且有效的文化是保障团队高效产出的关键部分。很多互联网公司都是工程师文化主导的，包括Facebook、Google、百度等。他们也都具有自己独特的企业文化价值观，如百度的简单可依赖、谷歌的不作恶、Netflix的自由和责任。建立团队文化的步骤如下：</p>

<ul>
<li>定义：总结、明确自己团队的文化，提炼出简单易记的文字。</li>
<li>主张：各种形式的传播。从我自己的经历来看，不断地念经是其中最有效的方式。</li>
<li>追求：在奖惩中体现出文化价值观的作用。如对于文化价值观贯彻优秀的同学给与公开的肯定与奖励。</li>
</ul>


<h2>四. 参考资料</h2>

<ul>
<li><a href="https://book.douban.com/subject/6862062/">《持续交付》</a></li>
<li><a href="https://book.douban.com/subject/30419555/">《持续交付2.0》</a></li>
<li><a href="https://time.geekbang.org/column/intro/100034501">《研发效率破局之道》</a></li>
<li><a href="https://developer.aliyun.com/article/690725">如何衡量研发效能？阿里资深技术专家提出了5组指标</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[项目管理标准模板]]></title>
    <link href="http://www.rowkey.me/blog/2020/07/31/project-manage/"/>
    <updated>2020-07-31T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/07/31/project-manage</id>
    <content type="html"><![CDATA[<p>之前写了一篇<a href="https://www.rowkey.cn/blog/2020/04/25/tech-leader-manage/">《技术管理标准模板》</a>，其中项目管理部分并没有具体深入，而这一技能不仅仅是对于技术Leader的要求，从我的经验看来，只要是程序员，具有项目管理能力都是如虎添翼的，即使你走的是专业路线。本文即基于自己的经验，从项目的启动和迭代阶段总结了敏捷项目管理的一些标准动作。</p>

<!--more-->


<h2>启动阶段</h2>

<ul>
<li><p>相关干系人沟通，同步项目背景、业务价值等</p></li>
<li><p>启动会议：召集相关干系人，明确业务相关信息，确定相关流程制度等</p></li>
<li><p>需求收集和分析-><strong>总体需求文档</strong>，概括性的功能与非功能需求列表</p></li>
<li><p>初步的产品规划-><strong>每一轮迭代的需求列表、发布时间</strong></p></li>
<li><p>创建项目基础设施-><strong>可持续交付到测试环境的基础项目</strong>，包括各个端的代码库、到测试环境的流水线等。</p></li>
</ul>


<h2>迭代阶段</h2>

<p>两周为一迭代，包括需求、设计、开发、测试、发布。关键点在于需求的拆分、优先级以及并行化。</p>

<h3>1. 需求评审</h3>

<p>对本轮迭代的需求尽心评审确认。</p>

<p><strong>前置条件</strong>：产品经理对此轮迭代进行需求确认，产出需求条目，按<strong>优先级</strong>排列；需求需要拆的足够小，把大需求拆成一个个<strong>能够独立开发测试发布</strong>的小需求</p>

<h3>2. 工作规划</h3>

<p>根据本轮迭代需求做WBS任务分解</p>

<ul>
<li><p>WBS工作项分解: 甘特图</p></li>
<li><p>里程碑结点: 表格或者里程碑图</p></li>
<li><p>风险管理：风险点预估、严重程度、可能性、应对措施</p></li>
</ul>


<h3>3. 设计/技术评审</h3>

<p>分别对交互设计和技术设计进行评审</p>

<p><strong>前置条件</strong>：设计师需要输出设计图；技术部分做概要设计和系统设计，随着每一轮迭代进行更新维护</p>

<h3>4. 测试用例评审</h3>

<p>由QA安排，会前需要提前将测试用例文档发给产品经理与研发，提前标注有疑问的用例。</p>

<h3>5. 开发、测试过程的监控</h3>

<p>持续交付：开发和迭代测试，需求开发完成后即测试并进行缺陷跟踪。</p>

<p><strong>会议</strong></p>

<ul>
<li><p>每日站会：全员站会，了解整体状况，对暴露出的风险和问题作出集体决策。</p></li>
<li><p>项目周会：10人以上团队。解决整体计划层面、跨团队协同配合的问题。</p></li>
</ul>


<p><strong>项目周报</strong></p>

<p>汇总项目总体状况，回答三个问题</p>

<ul>
<li><p>项目的整体进展状态到底如何？</p></li>
<li><p>风险可控吗？</p></li>
<li><p>目标达成有没有问题？</p></li>
</ul>


<h3>6. 版本全量测试</h3>

<p>对所有已经开发完的功能进行交叉测试、全量测试、埋点测试、回归测试、第三方云测。</p>

<h3>7. 验包发布</h3>

<p>此迭代所有功能开发测试完成后，提交审核流程，各流程审核人验收通过后发布。</p>

<h3>8. 复盘</h3>

<p>项目复盘会：有意识地向过去的行为经验学习</p>

<ul>
<li><p>团队做对了哪些事？</p></li>
<li><p>做错了哪些事？</p></li>
<li><p>再来一次，如何做得更好？</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[你要成为什么样的人？]]></title>
    <link href="http://www.rowkey.me/blog/2020/06/27/mytalk/"/>
    <updated>2020-06-27T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/06/27/mytalk</id>
    <content type="html"><![CDATA[<p>今天参加了TGO鲲鹏会的小组会议，其中ksyun提了一个问题挺发人深思的，大体的意思就是你什么时候才明确地知道以后要成为什么样的人？</p>

<p>对于这个问题，自己挺有感触的。自己在这方面算是开悟比较早的，现在从事的事情也是自己在初中时候就确定的，虽然细节略有不同。</p>

<!--more-->


<p>还记得是97年上小学4年级，学校买了一些电脑（好像是浪潮牌的），让每个班学习比较好的学生上微机兴趣班。那时的我学习还算拔尖，也是其中一员。但那时懂计算机的老师也没有几个，我们每次上计算机课都是在那里对着DOS黑色的命令行在乱敲键盘。很多细节都记不清了，但那确实是自己计算机的启蒙。</p>

<p>后来上了初中，学校里开设了正规的计算机课，系统也成了Win 3.2、Win 95、Win 98这些。我们那个沿海小城已经有很多家里条件不错的同学有了自己的电脑。自己当时的几个好朋友都是其中一员，他们应该算是自己走上计算机这条路非常关键的人物。和大部分人一样，对电脑的频繁接触都是从游戏开始的。从网吧用软盘拷超级玛丽到学校的电脑上玩，在网吧里玩鹿鼎记、沙丘2000、红警95、雷神之锤、魔兽争霸贯穿了我整个初中生涯。当然，初中的计算机课还是很正规的，老师开始教我们使用Word、Excel、PowerPoint、Frontpage这些软件制作文档、PPT、网页。尤其当时家里条件好的同学会把制作的网页传到免费空间上去，然后还有自己的域名（网易的yeah.net免费域名和空间），在学校里都是风云人物。我看到那些网页真的是挺激动的，觉得就那么几行代码就能出来一个可以让很多人访问的东西真的很神奇。自己也就从编写网页开始了自己的程序员生涯。再加上当时互联网领域的世界首富比尔.盖茨和国内网络三剑客丁磊、王志东、张朝阳在财富榜上的崛起，我在心里默默决定选择程序员做为我以后的职业。这里还要提的是，我们那时候小学是五年，初中是四年，而初三的时候会有一个考高中微机实验班的机会，就是我们市的两所省重点高中会提前录取一批学习比较好的学生，集中在初四这年给大家上计算机相关课程。没什么意外的，自己进入了一中的实验班，这一年应该是自己网页编程技术进步最快的一年，包括给自己班级建立主页、维护学校主页这些。</p>

<p>小学和初中应该是自己计算机的启蒙阶段了。而到了高中，由于学业压力的原因，自己的计算机技术也就停留在能做个静态网页、能用js做点简单的动画效果的地步。说起来，我们高中当时在山东省算是信息学竞赛比较厉害的学校，每年都有不少人靠着这个竞赛保送一些名校。而自己当时由于眼界和胆量的问题是不敢赌这条路的，还是在安安稳稳地好好学习、参加高考。值得欣慰的是，最终自己高考的成绩还算不错，在选择学校时坚持了学计算机的想法，综合考虑选择了西电这所电子领域比较强的学校，以至于很多人在知道我高考的分数和省内的位次后都是很不解我为什么不选一些更好的学校的。这也许就是我很早就知道“要成为什么样的人”促使自己在人生一个关键的转折上做的一个抉择吧。</p>

<p>而后来上了大学直到现在工作多年也就一直沿着这条路走了下来。也挺感谢自己能够那么早就能知道自己想成为一个什么样的人的。至少很多事情都是自己的选择，即使后面有失败、有挫折、有失落，也是自己要对自己负责的事情。</p>

<p>“知道自己想成为什么样的人”延伸出来的，就是现在很多人都会疑惑人生该如何规划？我周围也有不少人会问我这个问题，包括还没上大学的、大学毕业即将进入社会的、在社会打拼好多年仍然迷茫的。基于自己的经历，我想说的是：如果你知道自己想成为什么样的人，那么就根据这个目标去筹划自己的人生就好；如果你不知道，那么在学校就好好学习，学习好会是一个最保险最稳妥的人生路径，在社会上就选择最热的行业，至少就业不成问题，经济收入也比较可观。看看这个社会上普遍意义上的成功人士，除了少数那些单纯靠运气发财的，即使是没有高学历的那些人，他们也都是明确知道自己想成为什么样的人，然后追随这个目标付出有效的努力最终才有了成功的结果。</p>

<p>越早知道自己要成为什么样的人，那么就会越早有自己的规划，从而就会越早地为这个目标付出有效的努力和资源。即使最后的结局没那么完美，自己也不会后悔的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[持续交付这点事]]></title>
    <link href="http://www.rowkey.me/blog/2020/06/15/cd/"/>
    <updated>2020-06-15T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/06/15/cd</id>
    <content type="html"><![CDATA[<p>持续交付指的是在短周期内完成软件产品，以保证软件保持在随时可以发布的状态。让每一个变更都经过一条自动化的检验流水线，来检查每一个变更的质量，通过就进入下一个阶段。<strong>其不是一种工具，而是一种实践！</strong></p>

<!--more-->


<p>持续交付的共识和管理机制如下：</p>

<ul>
<li><strong>不要阻塞开发人员</strong>，这是实现持续交付的本质理念</li>
<li>为每个团队指定构建负责人或者发布工程师：优化交付流水线，提升交付效率</li>
<li>项目状态应该对参与整个过程（包括构建、部署、测试和发布）的所有人都是可见的</li>
<li>做好风险管理

<ul>
<li><strong>迭代增量式交付</strong>是有效风险管理的关键</li>
<li>手工测试环境、试运行环境和生产环境总是需要严格的访问控制</li>
<li>让风险识别成为每日立会的一部分</li>
</ul>
</li>
<li>做好审计

<ul>
<li>手工测试环境、试运行环境和生产环境总是需要严格的访问控制：指定谁能够访问“特权”环境。</li>
<li>要求每次部署都要进行审计，以确切知道到底修改了哪些内容。</li>
<li>文档自动化、自文档</li>
</ul>
</li>
</ul>


<p>接下来先说明实现持续交付的一些基础设施和准备工作，然后从本地开发和自动化构建/部署流水线两方面说明持续交付的具体实现。</p>

<h2>一. 基础设施和准备工作</h2>

<h3>1.1 基础设施和环境管理</h3>

<p>让所有测试环境（包括持续集成环境）都要与生产环境相似</p>

<ul>
<li>开发人员要把运维人员当做重要用户</li>
<li>切忌吞噬错误信息</li>
<li>使用运维团队熟悉的技术：开发人员最早负责创建部署脚本，后面移交给运维团队负责维护</li>
<li>把创建和维护基础设施需要的所有内容都进行版本控制</li>
<li>以自动化方式进行配置和部署！</li>
<li>像对待生产环境一样对待测试环境！</li>
<li>容器化技术实现不可变基础设施</li>
</ul>


<h3>1.2 配置管理</h3>

<p>版本控制、依赖管理、软件配置管理</p>

<ul>
<li>各个环境的手工配置 -> 自动化配置</li>
<li>对所有内容进行版本控制</li>
<li>指定依赖库的确切版本，不要用快照或者模式匹配版本</li>
<li>配置文件与二进制文件分离</li>
</ul>


<h3>1.3 测试策略</h3>

<ul>
<li>创建全面的自动化测试套件：单元测试、组件测试、验收测试，每一种测试的代码覆盖率都高于80%以上</li>
<li>每次修改都能运行一次自动化测试集合</li>
<li>分层测试</li>
</ul>


<h3>1.4 数据管理</h3>

<ul>
<li>把创建和迁移数据库全部变成自动化过程，是部署流程的一个组成部分</li>
<li>让测试自己创建它们所需的状态，并确保每个测试都独立于其他测试</li>
<li>对数据库进行版本管理，使用DbDeploy这样的工具管理数据迁移过程的自动化。</li>
<li>在大多数据情况下，不要在测试中使用生产数据集的副本。?</li>
<li>数据库回滚和无停机发布

<ul>
<li>蓝绿部署</li>
<li>大多数修改应该是增加操作（比如向数据库中增加新表或字段），尽可能不修改已存在的结构</li>
</ul>
</li>
<li>测试数据

<ul>
<li>测试的独立性、原子性</li>
<li>其他类型的测试，一定不要使用生产数据库的一个dump，除非有特殊情况</li>
</ul>
</li>
<li>部署流水线中的数据管理

<ul>
<li>提交测试：快速运行，避免复杂的数据准备</li>
<li>验收测试：后续阶段可以复用</li>
<li>容量测试：为测试提供足够的输入数据，可以看做验收测试的重复利用</li>
</ul>
</li>
</ul>


<h3>1.5 主干开发</h3>

<p>主干开发的分支模式实现持续交付最好的模式，但为了在主干模式下保持应用可发布，需要做到</p>

<ul>
<li>每次创建分支，都要认识到它带来的成本</li>
<li>频繁提交代码合并到主干</li>
<li>新功能隐藏：功能开关统一管理达到特性隐藏的目的(Togglz?)</li>
<li>增量开发：将所有的变更都变成一系列的增量式小修改，而且每次小的修改都是可发布的。</li>
<li>抽象模拟分支（无法使用增量开发）：修缮者模式，使用门面模式隔离待改造代码。</li>
<li>使用组件，根据不同部分修改的频率对应用程序进行解耦。</li>
</ul>


<h2>二. 本地开发</h2>

<p><strong>让开发者不受阻塞、不受不必要的干扰 -> 持续开发</strong></p>

<p><img src="http://www.rowkey.me/post_images/dev/localdev.png" alt="" /></p>

<ul>
<li>确保自动化测试、构建部署脚本都能够在开发机上运行</li>
<li>本地自动化测试：预测试提交pretested commit/个人构建personal build/试飞构建preflight build<strong>【保证本地开发所有验证方式与流水线上的验证方式一致，提高开发人员在本地发现问题的能力】</strong></li>
<li>提交前在本地运行所有的提交测试，等提交测试通过后再继续工作</li>
<li>在可控的环境上部署开发的应用程序</li>
<li>修复破坏应用程序的任意修改是最高优先级的任务，<strong>构建失败后不要提交新代码</strong></li>
</ul>


<h3>2.1 六步提交法</h3>

<p>规范开发习惯。主动提前集成；小步提交、完整代码、不影响已有功能；关注代码规范、动静态扫描问题</p>

<ul>
<li>检出最近成功的代码</li>
<li>修改代码</li>
<li>第一次个人构建</li>
<li>第二次个人构建： 拉取主干代码集成后本地测试</li>
<li>提交代码到主干</li>
<li>提交构建</li>
</ul>


<p>提交不影响已有功能！！</p>

<ul>
<li>增量迭代开发</li>
<li>抽象模拟分支</li>
<li>特性隐藏</li>
</ul>


<h3>2.2 规范化、自动化核心步骤</h3>

<p><img src="http://www.rowkey.me/post_images/dev/localdev-detail.png" alt="" /></p>

<ul>
<li>提高开发环境的效率: 环境获取的服务化、自助化；环境的一体化、一致性

<ul>
<li>本地开发环境

<ul>
<li>共享机器池</li>
<li>Git提交日志插入截图：Share Bucket+Google Drive</li>
<li>远程开发机器/Web IDE</li>
<li>依赖的服务

<ul>
<li>维护一个单独的环境，让开发环境接入</li>
<li>服务虚拟化工具来模拟依赖的服务，Mountbank、WireMock</li>
</ul>
</li>
</ul>
</li>
<li>联调环境：提供机器池，确保有两套空闲环境，自助化提供给开发者使用</li>
</ul>
</li>
<li>规范化、自动化本地检查

<ul>
<li>语法检查、规范检查、单元测试：Maven/Gradle插件</li>
</ul>
</li>
<li>建设并自动化代码入库前的检查流程

<ul>
<li>持续集成前的必要工作</li>
<li>代码审查</li>
</ul>
</li>
</ul>


<h3>2.3 代码审查</h3>

<p>人工代码检查</p>

<ul>
<li>统一并明确代码审查标准</li>
<li>统一并明确日志提交规范</li>
<li>传达团队的代码规则、质量基准</li>
<li>LGTM（Looks good to me）</li>
</ul>


<p><strong>方式</strong></p>

<ul>
<li>代码入库前的设计时检查：在设计阶段进行代码审查

<ul>
<li>代码入库前门禁检查，需要考虑灵活性，提供绕过机制</li>
<li>代码入库后检查</li>
</ul>
</li>
<li>工具辅助的线下异步审查：依赖于Gitlab、Gerrit、Code Climate Engines，一对一审查</li>
<li>面对面审查：架构问题、结对编程</li>
<li>代码增量审查/代码全量审查</li>
<li>团队审查：适合专项讨论</li>
<li>代码审查计入工作量和绩效考评</li>
</ul>


<p><strong>代码提交规范</strong></p>

<ul>
<li>原子提交</li>
<li>提交日志规范</li>
</ul>


<p><strong>原则</strong></p>

<ul>
<li>互相尊重</li>
<li>基于讨论</li>
</ul>


<p>相关资料可见：<a href="https://github.com/google/eng-practices/blob/master/review/index.md">谷歌代码审查指南</a></p>

<h3>2.4 快速反馈、增量开发</h3>

<blockquote><p>边开发边验证</p></blockquote>

<ul>
<li>提高运行静态检查和测试的方便性、灵活性：Maven/Gradle插件</li>
<li>提供沙盒环境方便验证和测试

<ul>
<li>容器</li>
<li>小范围的增量构建和验证？</li>
<li>测试数据：直接使用生产环境、生产数据的导出并脱敏</li>
</ul>
</li>
<li>实时检验工具：IDE实时检验、Liveload</li>
</ul>


<h2>三. 自动化构建/部署流水线</h2>

<p>部署流水线就是对软件交付流程的建模。</p>

<p><img src="http://www.rowkey.me/post_images/dev/deploy-pipeline.png" alt="" /></p>

<p>实现部署流水线的一些共识如下：</p>

<ul>
<li><strong>流水线建设原则</strong>

<ul>
<li>测试尽量完整，保证产品质量->完备的测试机制</li>
<li>运行速度够快->尽早反馈、提高交付速度</li>
<li>使用的所有环境尽量和生产环境一致->复现问题</li>
</ul>
</li>
<li>所有相关角色提供构建状态可视化：持续交付流水线大屏显示</li>
<li>存储构建结果报告</li>
<li>只要有环节失败，就停止整个流水线！</li>
<li>制品库是特殊的版本控制系统，不需要保存所有版本。</li>
<li>为部署流水线的每个阶段创建脚本：脚本是系统中的一等公民</li>
<li>增量式实现流水线：如果流程中有手工操作部分，就在流水线中为它创建一个占位符。</li>
</ul>


<p>接下来从流水线的各个阶段分别说明。</p>

<h3>3.1 提交阶段</h3>

<p>从技术角度上断言整个系统是可以工作的。</p>

<ul>
<li><strong>编译、单元测试、组装打包、代码分析</strong></li>
<li>少于五分钟，一定不要超过十分钟</li>
<li>提交测试：单元测试、组件测试</li>
<li>只有在某个错误让提交阶段的其他任务无法执行时，才停下来否则就直至提交阶段全部运行完后，汇总所有的错误和失败报告</li>
<li>此阶段的结果：结果报告、二进制包、元数据</li>
</ul>


<h3>3.2 自动化验收测试</h3>

<p>验证一个用户故事或需求的验收条件是否被满足。针对业务！</p>

<ul>
<li><strong>配置环境、部署二进制文件、冒烟测试、验收测试</strong></li>
<li>令验收测试失败的构建版本不能被部署</li>
<li>先部署再测试，重用部署脚本。</li>
<li>类生产环境运行验收测试：大部分是功能验收测试，关注功能正确性</li>
<li>开发人员能够在自己的开发环境中运行自动化验收测试</li>
<li>测试的关注点在系统的行为，而非数据本身。所以抵制使用生产数据的备份做为验收测试</li>
<li>验收测试的性能不是主要考虑问题，重点在测试的全面性。</li>
<li>正确地做验收测试：不要幼稚地对照着验收测试条件，盲目地把所有东西都自动化。</li>
<li>验收测试可以看作所有后续测试阶段（包括容量测试）的某种模板：从部署准备开始，然后核实环境和应用程序都已被正确配置和部署，最后执行测试。</li>
</ul>


<h3>3.3 后续测试</h3>

<ul>
<li>手工测试：探索性测试、易用性测试</li>
<li>非功能测试：性能、安全、可维护、可扩展</li>
</ul>


<h3>3.4 部署发布</h3>

<p>此阶段的触发不需要自动，测试或者运维人员可以做到自服务即可</p>

<ul>
<li>对不同环境采用同一部署方式：使用同样的脚本向所有环境部署，包括开发机器</li>
<li>一键式部署是对环境进行修改的唯一途径。</li>
<li>部署测试：对部署进行冒烟测试，验证部署是否成功，证明其部署的可靠性</li>
<li>确保部署流程是幂等的</li>
<li>只有通过了自动化构建、测试和部署的那些修改才能发布！</li>
<li>明确每个环境的部署和发布都是由谁负责</li>
<li>发布计划：第一次发布，产出一些文档、自动化脚本或其他形式的流程步骤</li>
<li>首次部署：首个迭代的主要目标之一就是在迭代结束时，让部署流水线的前几个阶段可以运行，实现部署流水线的“抽水泵”。

<ul>
<li>部署流水线的提交阶段。</li>
<li>一个用于部署的类生产环境。</li>
<li>通过一个自动化过程获取在提交阶段中生成的二进制包，并将其部署到这个类生产环境中。</li>
<li>一个简单的冒烟测试，用于验证本次部署是正确的，并且应用程序正在运行。</li>
</ul>
</li>
<li>对发布过程进行建模并让构建晋级

<ul>
<li>为了达到发布质量，一个构建版本要通过哪些测试阶段</li>
<li>每个阶段需要设置什么样的晋级门槛或需要什么样的签字许可。</li>
<li>对于每个晋级门槛来说，谁有权批准让某个构建通过该阶段。</li>
</ul>
</li>
<li>将每次已通过验收测试的变更版本部署在试运行环境中</li>
<li>紧急修复: 紧急修复版本也要走完标准的部署流水线，与其他代码变更没什么区别。

<ul>
<li>结对做！</li>
<li>有时候回滚比部署新的修复版本更划算。</li>
</ul>
</li>
<li>持续部署：每当有版本通过自动化测试之后，就将其部署到生产环境中。【需要依赖强大的自动化测试机制】</li>
</ul>


<h3>3.5 度量</h3>

<p>每次提交后都产生关于这些度量的报告和可视化效果并保存起来</p>

<ul>
<li>周期时间（cycle time），从决定要做某个特性开始，直到把这个特性交付给用户的这段时间</li>
<li>自动化测试覆盖率</li>
<li>代码库特征</li>
<li>缺陷数量</li>
<li>交付速度</li>
<li>提交版本库次数</li>
<li>构建次数</li>
<li>构建失败次数</li>
<li>构建所花时间</li>
</ul>


<h2>四. 其他</h2>

<h3>4.1 DevOps</h3>

<p>Devops是这些年很流行的一个概念，其目的就是打通研发和运维环节，以达到全员目标一致，保障软件高效交付。</p>

<p><img src="http://www.rowkey.me/post_images/dev/devops.png" alt="" /></p>

<ul>
<li>职能团队提供平台和工具，让全栈工程师能够自己处理端到端的工作，实现DevOps。</li>
<li>全栈开发：工程师不再只是对某一个单一职能负责，而是对最终产品负责。</li>
</ul>


<h3>4.2 信息溯源</h3>

<p>打通研发流程中流动的多种标识信息，以方便相关人员快速获取需要的信息，提高工作效率。包括任务工单、代码提交号、版本号、代码审查 ID、测试用例 ID、Bug ID。</p>

<ul>
<li>制品与源代码版本管理：放置在制品包中的元数据，体现源代码版本号。</li>
<li>源代码与需求/Bug的版本关联: 提交代码时需要在注释里注明需求ID、测试用例ID等。</li>
</ul>


<h2>五. 参考资料</h2>

<ul>
<li><a href="https://book.douban.com/subject/6862062/">《持续交付》</a></li>
<li><a href="https://book.douban.com/subject/30419555/">《持续交付2.0》</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《清教徒的礼物》学习笔记]]></title>
    <link href="http://www.rowkey.me/blog/2020/05/31/qjt/"/>
    <updated>2020-05-31T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/05/31/qjt</id>
    <content type="html"><![CDATA[<p>同学推荐的一本管理书籍，主要是讲的美国的管理文化在世界各地的普及，尤其是日本和中国。阐述了清教徒（第一批欧洲移民，起源于英国，在北美殖民地得以实践与发展）的一些特质，也是美国能够打赢两次世界大战的原因，包括：建造“人间天国”的坚定信念；亲力亲为的技师精神；集体主义；组织能力：善于协调各种财力、物力和人力的组织能力。并且在书的最后给出了管理黄金时代优秀实务背后的25条原理。看完这本书，对于其中的一些东西很有共鸣，比如：自下而上的管理、专家（职业经理人）崇拜的危害等。</p>

<!--more-->


<p><img src="http://www.rowkey.me/post_images/qjt-notes.png" alt="" /></p>

<ul>
<li>清教的四个特点

<ul>
<li>建造“人间天国”的坚定信念</li>
<li>亲力亲为的技师精神：重视技术、重视技术人员</li>
<li>集体主义：集体大于个人</li>
<li>组织能力：善于协调各种财力、物力和人力的组织能力</li>
</ul>
</li>
<li>自下而上的管理

<ul>
<li>逐步去中心化</li>
<li>在十分正式的组织上面强加一个高度非正式的组织</li>
<li>把决策权沿指挥链下放至愿意承担又能够承担的最低层级</li>
<li>火线管理者从事基本的管理工作，上级管理层的工作是派生的</li>
<li>所有权力和责任都集中在火线管理者，只有火线管理者独立完成不了的，才交给上级管理者</li>
</ul>
</li>
<li>专家崇拜的危害：不懂业务的管理专家会带来诸多负面影响，包括各种强制量化，唯数据论等。</li>
<li>指导下属自学是自下而上管理的基本方法之一<strong>【杠杆率高的工作】</strong></li>
<li>优秀实务背后的25个原理

<ul>
<li>所有成功组织，不管多么简单，都由系统嵌套而成。</li>
<li>所有系统都离不开常规工作的补充，这些常规要定期审查和更新。</li>
<li>任何组织最重要的子系统都是层级，其基础很有可能是某种形式的直线职能制。</li>
<li>最好的层级形式是“自下而上”。</li>
<li>”集体决策“带来正确的决定<strong>【集体决策是风险最小的决策，但不一定是最正确的决策】</strong></li>
<li>领导层应尽量实行集体决策制或“共治“</li>
<li>中层管理者是管理的”拱心石“</li>
<li>一人一上司<strong>【混血型组织一般是多重汇报机制】</strong></li>
<li>会议是”管理工作的媒介“</li>
<li>计划应该分为短期（1-4年）、中期（5-8年）和长期（9年以上）。</li>
<li>研究前人的成败，从前人的经验中学习。</li>
<li>各个方向尤其是向上的信息流动畅通无阻，对组织的成功非常必要。</li>
<li>管理者在实际意义和道德意义上都应该是领导者</li>
<li>应该保守地使用顾问；应该把顾问”放在手边“而非”供在头上“</li>
<li>管理者应该清楚自己的社会责任，包括把员工当人而非商品对待</li>
<li>不要等坏了才修，要注意保养和改进。</li>
<li>像回避瘟神一样回避债务，如果不可能做到完全回避，那么尽可能少借债。</li>
<li>管理者应该拥有或获得”领域知识“，即深刻了解公司的技术和业务，这种知识只能通过在公司或公司所在行业长期实践才能获得</li>
<li>对管理者的考核和培训应该是实用的、连续的。</li>
<li>任何想晋升到顶层的管理者都该从底层做起。</li>
<li>工作轮换有利于打造”全才型“经理人。</li>
<li>用人应该持长期导向，这个长期至少8年，最好是10年。</li>
<li>互补是任命的关键之一。</li>
<li>薪酬制度应该奖励并促进合作。</li>
<li>像回避瘟神一样回避炫耀和张扬。</li>
</ul>
</li>
</ul>


<p>&ndash;</p>

<p>书籍链接：<a href="https://book.douban.com/subject/26760576/">https://book.douban.com/subject/26760576/</a></p>

<p><img src="http://www.rowkey.me/post_images/qjt.png" width="300"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技术管理标准模板]]></title>
    <link href="http://www.rowkey.me/blog/2020/04/25/tech-leader-manage/"/>
    <updated>2020-04-25T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/04/25/tech-leader-manage</id>
    <content type="html"><![CDATA[<p>对于技术团队新晋升的一些研发Leader，即使在大公司具有完善的培训机制，大多数人在一开始还是会手足无措，不能很好地做到从个人贡献者到团队贡献者角色的转变。于是根据自己以及公司内部很多技术管理者的工作经验梳理出了一些技术管理者的管理模板，可以作为管理工作的实践参考。</p>

<!--more-->


<p><img src="http://www.rowkey.me/post_images/tech-manage.png" alt="" /></p>

<h2>看方向</h2>

<ul>
<li><p>向上级明确团队的职责</p></li>
<li><p>基于职责确定团队的使命、目标</p></li>
<li><p>把职责、使命向团队成员传达清楚</p></li>
<li><p>做好团队规划，包括：规模、分工、梯队、资源盘点等</p></li>
<li><p>建立团队的WIki，包括：职责、使命、目标、团队规划、人员分工、规章制度等</p></li>
</ul>


<h2>管事</h2>

<ul>
<li><p>OKR</p>

<ul>
<li><p>制定团队OKR，对齐公司和部门OKR</p></li>
<li><p>跟进团队成员的个人OKR制定和进度跟踪</p></li>
<li><p>跟踪OKR进展，识别高绩效人才</p></li>
</ul>
</li>
<li><p>技术管理</p>

<ul>
<li><p>参与技术方向决策，将研发规范、例会等信息明确传达给团队成员并推进</p>

<ul>
<li><p>技术评审规范</p></li>
<li><p>代码风格规范</p></li>
<li><p>代码开发规范</p></li>
<li><p>代码管理规范</p></li>
<li><p>CodeReview规范</p></li>
</ul>
</li>
<li><p>组织技术评审、CodeReview</p></li>
<li><p>制定学习分享机制并切实推行</p></li>
<li><p>团队所负责维护的系统的周期巡检</p></li>
<li><p>公司层面基础技术以及成熟开源项目的引入和推进</p></li>
<li><p>了解技术方向相关技术的技术采纳生命周期，根据公司现状知道何时引入相应的技术</p></li>
</ul>
</li>
<li><p>项目管理</p>

<ul>
<li><p>技术方案确定</p>

<ul>
<li><p>技术选型</p></li>
<li><p>技术架构</p></li>
<li><p>技术难点</p></li>
<li><p>性能瓶颈</p></li>
<li><p>上下游系统</p></li>
<li><p>功能模块</p></li>
</ul>
</li>
<li><p>根据技术评审的结果预估开发工期并做好关键时间点的把控</p>

<ul>
<li><p>系统、模块、功能的设计以及简述</p></li>
<li><p>参与的研发人员以及分工</p></li>
<li><p>预估工时</p></li>
<li><p>预计完成时间</p></li>
<li><p>关键时间点、里程碑</p></li>
<li><p>确定会议机制：晨会、周会</p></li>
</ul>
</li>
<li><p>创建并保持项目文档的更新</p>

<ul>
<li><p>技术调研文档</p></li>
<li><p>方案选型文档</p></li>
<li><p>需求文档</p></li>
<li><p>系统设计文档</p></li>
</ul>
</li>
<li><p>项目风险管理</p></li>
<li><p>项目质量管理，包括代码质量把控和监控告警设施的接入</p></li>
<li><p>协调资源推进项目进展</p></li>
</ul>
</li>
<li><p>技术产品运营</p>

<ul>
<li><p>提炼团队项目的公共抽象部分，组件化和平台化</p></li>
<li><p>组件、技术平台的推广</p></li>
</ul>
</li>
<li><p>成本管理</p>

<ul>
<li><p>技术选型时把成本做为重要考量项</p></li>
<li><p>提升团队资源的利用率</p></li>
<li><p>关注团队的人力成本和技术成本</p></li>
<li><p>关注团队的产出价值</p></li>
</ul>
</li>
<li><p>流程改进</p>

<ul>
<li><p>定位阻碍研发的流程节点，寻找有效的解决方案</p></li>
<li><p>寻求有效工具或者方案提升关键流程效率</p></li>
</ul>
</li>
<li><p>制度建设</p>

<ul>
<li><p>明确公司和部门的规章制度并推进实行</p></li>
<li><p>根据团队需要，制定团队规章制度</p></li>
<li><p>制定SOP，保障下限水准</p></li>
<li><p>明确团队例会制度</p></li>
</ul>
</li>
</ul>


<h2>管人</h2>

<ul>
<li><p>定期的一对一沟通</p>

<ul>
<li><p>你所负责业务的完成情况到现在怎么样？目标完成情况怎么样？</p></li>
<li><p>这段时间自我评价绩效如何？什么原因？</p></li>
<li><p>你个人有没有什么你觉得我应该知道的？</p></li>
</ul>
</li>
<li><p>关注团队成员职业规划和能力成长，给与指导和建议</p></li>
<li><p>关注团队成员工作状态</p></li>
<li><p>组织团建，提高团队凝聚力</p></li>
</ul>


<h2>管理仪表盘</h2>

<p>建立自己的管理仪表盘，关注关键数据</p>

<ul>
<li><p>系统监控数据（QPS、硬件资源使用率、错误数等） -> 提前发现系统瓶颈，消除隐患；提高资源利用率，降低成本</p></li>
<li><p>项目构建报告（单元测试覆盖率报告、代码质量报告、构建失败与成功概况） -> 关注项目研发质量，保障持续交付</p></li>
<li><p>项目/任务进度 -> 保证项目/任务正常进行</p></li>
<li><p>业务关键数据指标 -> 关注业务价值，提升团队成员成就感</p></li>
<li><p>OKR进度 -> 关注OKR实现状况，识别高绩效人员</p></li>
<li><p>团队成员的每日/周的工作状况 -> 关注团队成员状况</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java工程师应该知道的Web安全]]></title>
    <link href="http://www.rowkey.me/blog/2020/03/10/web-security/"/>
    <updated>2020-03-10T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/03/10/web-security</id>
    <content type="html"><![CDATA[<p>Java开发很大的一个应用场景就是Web，即使不是Web, 很多时候也是采用的和Web类似的处理方式。因此了解目前常见的Web安全问题并做防范是非常关键的。</p>

<p>Web安全问题，从大的方面可以分为：</p>

<ul>
<li>客户端安全：通过浏览器进行攻击的安全问题。</li>
<li>服务端安全：通过发送请求到服务端进行攻击的安全问题。</li>
</ul>


<p>常见的客户端安全问题有：</p>

<ul>
<li>跨站脚本攻击</li>
<li>跨站点请求伪造</li>
</ul>


<p>常见的服务端安全问题有：</p>

<ul>
<li>SQL注入</li>
<li>基于约束条件的SQL攻击</li>
<li>DDOS攻击</li>
<li>Session fixation</li>
</ul>


<p>本文主要针对这些问题进行讲述。</p>

<!--more-->


<h2>跨站脚本攻击</h2>

<p>跨站脚本攻击，全称Cross Site Script（XSS），故名思议是跨越两个站点的攻击方式。一般指的是攻击方通过“HTML”注入的方式篡改了网页，插入了恶意的脚本，从而在用户浏览网页或者移动客户端使用WebView加载时，默默地做了一些控制操作。</p>

<p>XSS可以说是客户端安全的首要问题，稍有不注意就会漏出相关接口被利用。</p>

<p>一个XSS攻击的例子，如下：</p>

<ul>
<li>一个Java应用提供了一个接口可以上传个人动态，动态内容是富文本的。</li>
<li><p>攻击者上传的内容如下：</p>

<p>  <code>&lt;img src="1" onerror="alert('attack')"/&gt;</code></p></li>
<li><p>在服务端和客户端程序未做任何过滤的情况下，其他用户访问这个动态的页面时，就会执行这个脚本。</p></li>
</ul>


<p>如果脚本不是一个alert，而是换成跳转到一个具有删除操作的URL或者脚本获取用户的Cookie然后发送到远程服务器上，可想而知危害有多大。</p>

<p>防范此种攻击的常用方式有以下几种：</p>

<ul>
<li>对任何允许用户输入的地方做检查，防止其提交脚本相关特殊字符串，如script、onload、onerror等。客户端和服务端都要做检查。</li>
<li>做输入过滤，即将特殊字符都过滤掉或者换成HTML转义后的字符。Java中可以使用Apache commons-lang中的StringEscapeUtils的escape前缀的方法来做转义。</li>
<li>给Cookie属性设置上HttpOnly，可以防止脚本获取到Cookie。</li>
<li>对输出内容做过滤。这个可在客户端做，也可在服务端做。服务端主要就是转义HTML字符，客户端可以使用escape方法来过滤。</li>
</ul>


<h2>跨站点请求伪造</h2>

<p>跨站点请求伪造，全称Cross Site Request Forgery,简称CSRF。也是一种常见的攻击方式。</p>

<p>此种攻击方式，主要是通过诱导用户点击某些链接，从而隐含地发起对其他站点的请求，进而进行数据操作。</p>

<p>一个攻击示例如下：</p>

<ul>
<li>一个用户登录了一个站点，访问<a href="http://xx/delete_notes?id=xx%E5%8D%B3%E5%8F%AF%E5%88%A0%E9%99%A4%E4%B8%80%E4%B8%AA%E7%AC%94%E8%AE%B0%E3%80%82">http://xx/delete_notes?id=xx%E5%8D%B3%E5%8F%AF%E5%88%A0%E9%99%A4%E4%B8%80%E4%B8%AA%E7%AC%94%E8%AE%B0%E3%80%82</a></li>
<li><p>攻击者在它的站点中构造一个页面，HTML页面含有以下内容：</p>

<p>  <code>&lt;img src="http://xx/delete_notes?id=xx"/&gt;</code></p></li>
<li><p>当用户被诱导访问攻击者的站点时就发起了一个删除笔记的请求。</p></li>
</ul>


<p>对于CSRF攻击的常用解决方案有以下几种：</p>

<ul>
<li>对重要请求要求验证码输入,这样就能防止在用户不知情的情况下，被发送请求。</li>
<li>使用类似防盗链的机制，对header的refer进行检验以确认请求来自合法的源。</li>
<li>对重要请求都附带一个服务端生成的随机token, 提交时对此token进行验证。这也是业界一个很普遍的做法。</li>
</ul>


<h2>SQL注入</h2>

<p>SQL注入攻击是一个很常见的攻击方式，原理是通过发送特殊的参数，拼接服务端的SQL字符串，从而达到改变SQL功能的目的。</p>

<p>一个攻击例子如下：</p>

<ul>
<li><p>服务端登录验证使用下面的方式,其中userName和userPwd都是用户直接上传的参数</p>

<pre><code class="``">  String sql = "select * from user where user_name = '" + userName + "' and pwd = " + userPwd;
</code></pre></li>
<li>用户提交userName为admin&#8217;&ndash;,userPwd随便字符串xxx</li>
<li>拼接好之后的SQL语句变成了：<code>select * from user where user_name = 'admmin'--' and pwd = 'xxx'</code>（&ndash;为SQL语句的注释）, 这样只要存在user_name为admin的用户，此语句就能成功执行并返回admin用户的信息。</li>
</ul>


<p>这里需要说明的是，如果服务器的请求错误信息没有做进一步封装，直接把原始的数据库错误返回，那么有经验的攻击者通过返回结果多次尝试就会有机会找出SQL注入的机会。</p>

<p>防范此种攻击的方案有以下几个：</p>

<ul>
<li>在Java中构造SQL查询语句时，杜绝拼接用户参数，尤其是拼接SQL查询的where条件。全部使用PreparedStatement预编译语句, 通过？来传递参数。</li>
<li>在业务层面，过滤、转义SQL特殊字符，Apache commons-lang中的StringEscapeUtil提供了escapeSQL的功能（最新的lang3已经删除此方法，因为其只是简单的替换&#8217;为&#8217;&lsquo;）。</li>
</ul>


<h2>基于约束条件的SQL攻击</h2>

<p>基于约束条件的SQL攻击基于的原理如下：</p>

<ul>
<li>在处理SQL中的字符串时，字符串末尾的空格字符都会被删除，包括WHERE子句和INSERT语句，但LIKE子句除外。</li>
<li>在任意INSERT查询中，SQL会根据varchar(n)来限制字符串的最大长度，即超过n的字符串只保留前n个字符。</li>
</ul>


<p>如此，我们设计一个用户表（暂且忽略设计的合理性），对其中的用户名和密码字段都设置为25个字符限制：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE TABLE test_user (
</span><span class='line'>    `user_name` varchar(25),
</span><span class='line'>    `pwd`  varchar(25)
</span><span class='line'>);</span></code></pre></td></tr></table></div></figure>


<p>有一个user_name为<code>user_test</code>的用户注册，于是向数据库添加一条记录。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>insert into test_user values("user_test","111111");</span></code></pre></td></tr></table></div></figure>


<p>接着，一个user_name为&#8217;user_test              1&#8217;(中间留有25个空格)的用户再来注册。一般的业务逻辑如下：</p>

<ul>
<li><p>判断用户名是否存在</p>

<pre><code class="``">  select * from test_user where user_name = 'user_test              1'
</code></pre>

<p>  因为查询语句不会截断字符串，因此这样获取不到记录，表示用户不存在。</p></li>
<li><p>用户名不存在，那么插入新用户。</p>

<pre><code class="``">  insert into test_user values("user_test              1","123456")
</code></pre></li>
</ul>


<p>这样，由于<code>user_name</code>约束为25个字符，那么新用户的<code>user_name</code>成为了&#8217;user_test      &lsquo;（后面是16个空格字符）。现在数据库记录如下（第二个记录后面是16个空格）：</p>

<table>
<thead>
<tr>
<th>user_name </th>
<th> pwd</th>
</tr>
</thead>
<tbody>
<tr>
<td>user_test               </td>
<td> 111111</td>
</tr>
<tr>
<td>user_test               </td>
<td> 123456</td>
</tr>
</tbody>
</table>


<p>这样，当使用<code>user_name='user_test'</code>和<code>pwd='123456'</code>登录时，能匹配到第二条记录，登录是成功的。但是用户信息使用的第一条的记录，于是攻击者就获取到了第一个用户的操作权限。</p>

<p>防范此种攻击的措施如下：</p>

<ul>
<li>为具有唯一性的那些列添加UNIQUE索引。</li>
<li>在数据库操作前先将输入参数修剪为特定长度。</li>
</ul>


<h2>DDOS攻击</h2>

<p>DDOS，全称Distributed Denial of Service, 分布式拒绝服务攻击。攻击者利用很多台机器同时向某个服务发送大量请求，人为构造并发压力，从而使得服务被冲垮，无法为正常用户提供服务。常见的DDOS攻击包括：</p>

<ul>
<li>SYN flood</li>
<li>UDP flood</li>
<li>ICMP flood</li>
</ul>


<p>其中SYN flood是最为经典的DDOS攻击。其利用了TCP连接三次握手时需要先发送SYN的机制，通过发送大量SYN包使得服务端建立大量半连接，消耗非常多的CPU和内存。针对这种攻击，很多解决方案就是在TCP层就使用相关算法识别异常流量，直接拒绝建立连接。但是，如果攻击者控制很多机器对一个资源消耗比较大的服务接口发起正常访问请求，那么这个方式就无效了。</p>

<p>由于难于区分是否是正常用户的请求，因此DDOS是非常难以防范的，但仍有一些措施能够尽量地减少DDOS带来的影响，如下：</p>

<ul>
<li>合理使用缓存、异步等措施提高应用性能。应用抗并发的能力越强，就越不容易被DDOS冲垮服务。</li>
<li>合理使用云计算相关组件，自动识别高峰流量并做自动扩容。</li>
<li><p>在应用中限制来自某一IP或者某一设备ID的请求频率。超过此频率就将其放入黑名单，下次请求直接拒绝服务。Java中可以通过Redis的incr和expire操作来达到。如下：</p>

<pre><code class="``">  String ip = NetworkUtil.getClientIP(request, false); //获取客户端ip地址
  String key = "ddos." + ip;
  long count = suishenRedisTemplate.incr(key); //incr不会影响expire
  if (count &gt; 10000) {
      throw new AccessException("access too frequently with ip: "
           + StringUtils.defaultString(ip));
  } else {
      if (count == 1) {
          suishenRedisTemplate.expire(key, 10);
      }
      return true;
  }
</code></pre>

<p>  上述代码即可将同一IP的请求限制在十秒钟10000次。</p>

<p>  此逻辑越靠近访问链路的前面效果越好，比如直接在Nginx中拦截效果就要比在业务应用中做要好。</p></li>
</ul>


<p>还需要提到的是DDOS一个新的变种，反射型DDOS攻击，也被称为放大攻击。原理如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/reflect-ddos.png" alt="" /></p>

<p>此种攻击，攻击者并不直接攻击目标服务IP，而是伪造被攻击者的IP，发送请求包到网上一些开放的特殊服务的服务器（放大器。这些服务器由于协议的特点并不会验证源IP的真伪，于是会将数倍于请求报文的回复数据发送到被攻击者的IP，从而对后者间接形成DDOS攻击。任何设计不完善的、基于UDP请求的协议或者ICMP协议都能形成放大器，包括DNS请求、Ping请求、NTP monlist请求、SSDP协议（简单服务发现协议）等。此种攻击不需要大量的肉鸡、难以追踪，正变得越来越流行。防范此种攻击通常的手段就是进行DDOS流量清洗和增加ACL过滤规则。</p>

<h2>Session fixation</h2>

<p>Session fixation攻击，故名思议就是会话固定攻击。在我们平时的Web开发中都是基于Session做用户会话管理的。在浏览器中，Session的ID一般是存储在Cookie中的，甚至直接附带在query参数中。如果Session在未登录变为登录的情况下不发生改变的话，Session fixation攻击就形成了。</p>

<p>一个攻击示例如下：</p>

<ul>
<li>攻击者进入网站<a href="http://xx.com%E3%80%82">http://xx.com%E3%80%82</a></li>
<li>攻击者发送<a href="http://xx.com?JSESSIONID=123456%E7%BB%99%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7%E3%80%82">http://xx.com?JSESSIONID=123456%E7%BB%99%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7%E3%80%82</a></li>
<li>用户点击此链接进入网站，由于URL后面有JSESSIONID，因此直接使用此做为Session的ID。</li>
<li>用户成功登陆后，攻击者就可以利用伪造的Session ID获取用户的各种操作权限。</li>
</ul>


<p>此种攻击的关键点就在于Tomcat使用JSESSIONID做为Session ID。因此，防范此种攻击的核心之一就在于不能使用客户端传来的Session ID。此外还有以下方法：</p>

<ul>
<li>不要接受由GET或者POST参数指定的Session ID值。</li>
<li>针对每一个请求都生成新的Session。</li>
<li>只接受服务端生成的Session ID。</li>
<li>为Session指定过期时间。</li>
</ul>


<p>Java Web项目中,可以实现一个拦截器, 将使用query参数传递JSESSIONID的请求的Session删除掉：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public void doFilter(ServletRequest request, ServletResponse response,
</span><span class='line'>                         FilterChain chain) throws IOException, ServletException
</span><span class='line'>    ...
</span><span class='line'>    
</span><span class='line'>    if (httpRequest.isRequestedSessionIdFromURL()) {
</span><span class='line'>        HttpSession session = httpRequest.getSession();
</span><span class='line'>        if (session != null) {
</span><span class='line'>            session.invalidate();
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>    ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>此外，对于每一次登录后的Session都重新生成ID, 并设置合理的失效期。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public JSONResult login(@RequestBody LoginRequestBody requestBody,
</span><span class='line'>                            HttpServletRequest request)
</span><span class='line'>    ...
</span><span class='line'>    boolean loginResult = doLogin();
</span><span class='line'>    if(loginResult){
</span><span class='line'>        request.changeSessionId(); //重新生成Session ID
</span><span class='line'>        request.getSession().setMaxInactiveInterval(1800); //30分钟失效
</span><span class='line'>    }
</span><span class='line'>    ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>隐私数据存储</h2>

<p>随着市面上发生一次次数据库被脱导致用户隐私数据被泄漏的事情，越来越多的人意识到了隐私的重要性，在选择一个应用的时候也越来越在意对自己隐私数据的保护。这里所说的隐私数据包括：手机号、实名、身份证号、家庭住址、单位地址、家庭情况、密码等等。那么在技术层面如何存储这些隐私数据来保障用户的隐私安全呢？</p>

<ol>
<li><p>使用单向散列算法</p>

<p> 此种方式对明文进行加密后是无法恢复明文的，因此仅仅适用于密码这种不需要恢复明文只需要做验证的场景。</p></li>
<li><p>使用加密算法</p>

<p> 此种方式，在存储和使用用户数据的时候都进行加/解密运算，能够在一定程度上保护数据的安全性。但每次都要进行加解密使得代价有点高，而如果使用简单的算法则无法面对穷举或者字典攻击。并且加密的数据对于SQL等数据库查询语句优化是不友好的，操作都得通过程序进行。此外，算法所使用的密钥的安全也是一个问题，存储在哪里都有被拿到的机会。而如果进一步对于每个用户或者每条数据都使用不同的密钥，那么就会提高程序的逻辑复杂性。</p>

<p> 还得考虑到日志采集、数据分析等非具体业务场景，这些隐私数据最终还是要变为明文进行流通，无法从根本上保证隐私数据的安全。</p></li>
</ol>


<p>综上分析，可以采取以下这种方案：</p>

<ol>
<li><p>每一个用户都有自己的密钥，对其手机号、身份证等隐私信息使用加密算法来混淆其中的几位。如：159efadsc2681。如此，在只是需要展示这些信息的地方无须解密，直接使用即可。只有诸如发送短信、用户信用验证时才需要解密。</p></li>
<li><p>密钥存储在另一个库中，由另外一个团队维护、独立管理，具有最高级别的访问权限，访问QPS也受严格控制。</p></li>
<li><p>如果给数据分析部门提供数据，则提供隐私数据转换后的数据。例如：对用户的归属地分析，那么可以提供身份证转化为地区归属地后的信息而不是直接提供身份证号。</p></li>
</ol>


<p>如此，即使脱库也无法解密所有数据。而且密钥库和业务库独立，单独脱一个库是没有意义的。密钥库的访问权限和访问频率也都受限制，即使是内部人员脱库都很容易被发现。</p>

<p>总之，对诸如身份证号、通讯录、支付宝账号等隐私信息要注意加密或者散列存储，一定不要明文发送到客户端，展示也不要明文展示，只有当真正使用的时候再去获取明文。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java工程师应该知道的RPC]]></title>
    <link href="http://www.rowkey.me/blog/2020/02/17/rpc/"/>
    <updated>2020-02-17T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/02/17/rpc</id>
    <content type="html"><![CDATA[<p>RPC, Remote Procedure Call,故名思议就是远程过程调用，一般都有跨语言支持。大规模分布式应用中普遍使用RPC来做内部服务、模块之间的数据通信，还有助于解耦服务、系统的垂直拆分，使得系统可扩展性更强，并能够让Java程序员用与开发本地程序一样的语法与方式去开发分布式应用程序。</p>

<p>RPC分为客户端（服务调用方）和服务端（服务提供方），都运行在自己的JVM中。客户端只需要引入要使用的接口，接口的实现和运行都在服务端。RPC主要依赖的技术包括序列化、反序列化和数据传输协议。是一种定义与实现相分离的设计：</p>

<p><img src="http://www.rowkey.me/post_images/rpc/rpc.png" alt="" /></p>

<p>目前Java使用比较多的RPC方案主要有RMI、Hessian、Dubbo以及Thrift。</p>

<p>这里需要提出的一点就是，这里的RPC主要指的内部服务之间的调用，因此虽然RESTful也可以用于内部服务间的调用（跨语言、跨网段、跨防火墙），但其主要用途还是为外部系统提供服务，因此本文没有将其包含在内。</p>

<!--more-->


<h2>RMI</h2>

<p>RMI，remote method invoke, 远程方法调用。是JAVA自带的远程方法调用工具，其基于TCP连接，可以使用任意端口，不易跨网段调用，不能穿越防火墙。但它是JAVA语言最开始时的设计，后来很多框架的原理都基于RMI。其调用逻辑如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/rpc/rmi.png" alt="" /></p>

<ol>
<li>服务注册：服务端注册服务绑定到注册中心registry。</li>
<li>服务查找：客户端根据服务名从注册中心查询要使用的接口获取引用。</li>
<li>服务调用：Stub序列化调用参数并将其发送给Skeleton，后者调用服务方法，并将结果序列化返回给Stub。</li>
</ol>


<p>其序列化和反序列化使用的都是JDK自带的序列化机制。</p>

<p>这里服务注册管理中心是在服务端的。其实这个可以完全独立出来作为一个单独的服务，其他的RPC框架很多都是选择zookeepr充当此角色。</p>

<p>可以使用Spring那一节讲的RmiServiceExporter和RmiProxyFactoryBean来使用RMI。</p>

<h2>Hessian</h2>

<p>Hessian是一个基于HTTP协议的RPC方案，其序列化机制是自己实现的，负载均衡和容错需要依赖于Web容器/服务。其体系结构和RMI类似，不过并没有注册中心Registry这一角色，而是通过使用地址来显式调用。其中需要使用HessianProxyFactory根据配置的地址create一个代理对象。使用此代理对象去调用服务。</p>

<p><img src="http://www.rowkey.me/post_images/rpc/hessian.png" alt="" /></p>

<p>和RMI一样，可以使用Spring那一节讲的HessianServiceExporter和HessianProxyFactoryBean来使用。</p>

<h2>Thrift</h2>

<p>Thrift是Facebook开源的RPC框架，现已进入Apache开源项目。其采用接口描述语言（IDL）定义 RPC 接口和数据类型，通过编译器生成不同语言的代码（支持 C++，Java，Python，Ruby等），数据传输采用二进制格式，是自己实现的序列化机制。没有注册中心的概念。</p>

<p><img src="http://www.rowkey.me/post_images/rpc/thrift.png" alt="" /></p>

<p>Thrift的使用需要先编写接口的IDL，然后使用它自带的工具生成代码。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>namespace java me.rowkey.pje.datatrans.rpc.thrift
</span><span class='line'>
</span><span class='line'>typedef i32 int
</span><span class='line'>service TestService
</span><span class='line'>{
</span><span class='line'>    int add(1:int n1, 2:int n2),
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>//代码生成
</span><span class='line'>thrift --gen java TestService.thrift</span></code></pre></td></tr></table></div></figure>


<p>以上即可在gen-java目录下生成TestService的Java代码TestService.java, 其中的核心是接口TestService.Iface，实现此类即可提供服务。需要注意的是Thrift有一个问题就是在接口比较多的时候，生成的Java代码文件太大。</p>

<p>服务提供方：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>TProcessor tprocessor = 
</span><span class='line'>  new TestService.Processor&lt;TestService.Iface&gt;(new TestServiceImpl());
</span><span class='line'>
</span><span class='line'>TServerSocket serverTransport = new TServerSocket(8088);
</span><span class='line'>TServer.Args tArgs = new TServer.Args(serverTransport);
</span><span class='line'>tArgs.processor(tprocessor);
</span><span class='line'>tArgs.protocolFactory(new TBinaryProtocol.Factory());
</span><span class='line'>
</span><span class='line'>// 简单的单线程服务模型
</span><span class='line'>TServer server = new TSimpleServer(tArgs);
</span><span class='line'>server.serve();</span></code></pre></td></tr></table></div></figure>


<p>服务消费方：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>TTransport transport = new TSocket("localhost", 8088, TIMEOUT);
</span><span class='line'>TestService.Client testService = 
</span><span class='line'>  new TestService.Client(new TBinaryProtocol(transport));
</span><span class='line'>transport.open();
</span><span class='line'>
</span><span class='line'>int result = testService.add(1,2);
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>这里需要说明的一点就是，Thrift提供了多种服务器模型、数据传输协议以及传输层供选择：</p>

<ul>
<li><p>服务提供者的服务模型除了上面用的TSimpleServer简单单线程服务模型，还有几个常用的模型：</p>

<ul>
<li>TThreadPoolServer：线程池服务模型，使用标准的阻塞式IO，预先创建一组线程处理请求。</li>
<li>TNonblockingServe：非阻塞式IO。</li>
<li>THsHaServer: 半同步半异步的服务端模型。</li>
</ul>
</li>
<li><p>数据传输协议除了上面例子使用的BinaryProtocol二进制格式，还有下面几种：</p>

<ul>
<li>TCompactProtocol : 压缩格式。</li>
<li>TJSONProtocol : JSON格式。</li>
<li>TSimpleJSONProtocol : 提供JSON只写协议, 生成的文件很容易通过脚本语言解析。</li>
</ul>
</li>
<li><p>传输层除了上面例子的TServerSocket和TSocket，还有</p>

<ul>
<li>TFramedTransport：以frame为单位进行传输，非阻塞式服务中使用。</li>
<li>TFileTransport：以文件形式进行传输。</li>
<li>THttpClient: 以HTTP协议的形式进行传输。</li>
</ul>
</li>
</ul>


<h2>Dubbo</h2>

<p>Dubbo是阿里开源的服务治理框架。与前面讲的几个RPC协议相比，Dubbo不仅仅是一个RPC框架，还包含了服务治理方面的很多功能：</p>

<ul>
<li>服务注册</li>
<li>服务自动发现</li>
<li>负载均衡</li>
<li>集群容错</li>
</ul>


<p>这里仅仅针对Dubbo的RPC协议来讲，其传输是基于TCP协议的，使用了高性能的NIO框架Netty，序列化可以有多种选择，默认使用Hessian的序列化实现。Dubbo默认使用Zookeeper作为服务注册、管理中心。</p>

<p><img src="http://www.rowkey.me/post_images/rpc/dubbo.png" alt="" /></p>

<p>一个基于Spring XML配置的使用例子如下：</p>

<ul>
<li><p>服务提供者XML配置</p>

<pre><code class="``">  &lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt;
  &lt;dubbo:application name="test_server"/&gt;

  &lt;!-- 使用zk注册中心暴露服务地址 --&gt;
  &lt;dubbo:registry address="zookeeper://zk1.dmp.com:2181?backup=zk2.dmp.com:2181,zk3.dmp.com:2181" file="${catalina.base}/logs/eservice/dubbo.cache"/&gt;

  &lt;dubbo:service path="emailService" interface="me.rowkey.pje.rpc.test.service.IEmailService" ref="emailApiService" /&gt;
</code></pre></li>
<li><p>服务消费者XML配置</p>

<pre><code class="``">  &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt;
  &lt;dubbo:application name="test_consumer"/&gt;

  &lt;!-- 使用zk注册中心 --&gt;
  &lt;dubbo:registry address="zookeeper://zk1.dmp.com:2181?backup=zk2.dmp.com:2181,zk3.dmp.com:2181" /&gt;

  &lt;dubbo:reference id="emailService" interface="me.rowkey.pje.rpc.test.service.IEmailService"/&gt;
</code></pre>

<p>  在相关bean中注入emailService即可使用。</p></li>
</ul>


<h2>序列化</h2>

<p>序列化是RPC的一个很关键的地方，序列化、反序列的速度、尺寸大小都关系着RPC的性能。包括上面提到的几个序列化协议，现在使用较为普遍的Java序列化协议有以下几种：</p>

<ol>
<li><p>Java Serialiazer</p>

<p> JDK自带的序列化机制, 使用起来比较方便。但是其是对象结构到内容的完全描述，包含所有的信息，因此速度较慢，占用空间也比较大，且只支持Java语言。一般不推荐使用。</p>

<p> 需要注意的是字段serialVersionUID的作用是为了在序列化时保持版本的兼容性，即在版本升级时反序列化仍保持对象的唯一性。否则如果你在序列化后更改/删除了类的字段，那么再反序列化时就会抛出异常;而如果设置了此字段的值，那么会将不一样的field以type的预设值填充。</p>

<pre><code class="`"> //序列化
 ByteArrayOutputStream bout = new ByteArrayOutputStream();
 ObjectOutputStream out = new ObjectOutputStream(bout);
 out.writeObject(obj);
 byte[] bytes = bout.toByteArray();

 //反序列化
 ObjectInputStream bin = new ObjectInputStream(new ByteArrayInputStream(bytes));
 bin.readObject();
</code></pre></li>
<li><p>Hessian</p>

<p> 底层是基于List和Hashmap实现的，着重于数据，附带简单的类型信息的方法，支持多种语言，兼容性比较好, 与JDK序列化相比高效且空间较小；但其在序列化的类有父类的时候，如果有字段相同，父类的值会覆盖子类的值，因此使用Hessian时一定要注意子类和父类不能有同名字段。</p>

<p> 需要注意的一点，Hessian的实现里有v1和v2两种版本的协议支持，并不兼容，推荐使用Hessian2相关的类。</p>

<p> 与后来出现的其他二进制序列化工具相比，其速度和空间都不是优势。</p>

<pre><code class="`"> //序列化
 ByteArrayOutputStream os = new ByteArrayOutputStream();
 Hessian2Output out = new Hessian2Output(os);
 out.startMessage();
 TestUser user = new TestUser();
 out.writeObject(user);
 out.completeMessage();
 out.flush();
 byte[] bytes = os.toByteArray();
 out.close();
 os.close();

 //反序列化
 ByteArrayInputStream ins = new ByteArrayInputStream(bytes);
 Hessian2Input input = new Hessian2Input(ins);
 input.startMessage();
 TestUser newUser = (TestUser)input.readObject();
 input.completeMessage();
 input.close();
 ins.close();
</code></pre></li>
<li><p>MsgPack</p>

<p> MsgPack是一个非常高效的对象序列化库，支持多种语言，有点像JSON，但是非常快，且占用空间也较小，号称比Protobuf还要快4倍。</p>

<p> 使用MsgPack需要在序列化的类上加@Message注解；为了保证序列化向后兼容，新增加的属性需要加在类的最后面，且要加@Optional注解，否则反序列化会报错。</p>

<p> 此外，MsgPack提供了动态类型的功能，通过接口Value来实现动态类型，首先将字节数组序列化为Value类型的对象，然后用converter转化为本身的类型。</p>

<p> MsgPack不足的一点就是其序列化和反序列都非常消耗资源。</p>

<pre><code class="`"> //TestUser.java
 @Message
 public class TestUser{
     private String name;
     private String mobile;
     ...
 }

 TestUser user = new TestUser();
 MessagePack messagePack = new MessagePack();

 //序列化
 byte[] bs = messagePack.write(user);

 //反序列化
 user = messagePack.read(bs, TestUser.class);
</code></pre></li>
<li><p>Kryo</p>

<p> Kryo是一个快速高效的Java对象图形序列化框架，使用简单、速度快、序列化后体积小。实现代码非常简单，远远小于MsgPack。但其文档较少，跨语言支持也较差，适用于Java语言。目前Kryo的版本到了4.x, 对于之前2.X之前版本的很多问题都做了修复。</p>

<pre><code class="`"> Kryo kryo = new Kryo();

 // 序列化
 ByteArrayOutputStream os = new ByteArrayOutputStream();
 Output output = new Output(os);
 TestUser user = new TestUser();
 kryo.writeObject(output, user);
 output.close();
 byte[] bytes = os.toByteArray();

 // 反序列化
 Input input = new Input(new ByteArrayInputStream(bytes));
 TestUser newUser = kryo.readObject(input, TestUser.class);
 input.close();
</code></pre></li>
<li><p>Thrift</p>

<p> 上面讲的Thrift RPC框架其内部的序列化机制可以单独使用，主要是对TBinaryProtocol的使用。和接口的生成方式类似，需要先定义IDL，再使用Thrift生成。其序列化性能比较高，空间占用也比较少。但其设计目标并非是单独做为序列化框架使用的，一般都是整体作为RPC框架使用的。</p>

<p> 定义IDL:</p>

<pre><code class="`"> //TestUser.thrift
 namespace java me.rowkey.pje.datatrans.rpc.thrift

 struct TestUser {
     1: required string name
     2: required string mobile
 }

 thrift --gen java TestUser.thrift
</code></pre>

<p> 使用生成的TestUser类做序列化和反序列化：</p>

<pre><code class="`"> TestUser user = new TestUser(); //由thrift代码生成引擎生成

 //序列化
 ByteArrayOutputStream bos = new ByteArrayOutputStream();
 user.write(new TBinaryProtocol(new TIOStreamTransport(bos)));
 byte[] result = bos.toByteArray();
 bos.close();

 //反序列化
 ByteArrayInputStream bis = new ByteArrayInputStream(result);
 TestUser user = new TestUser();
 user.read(new TBinaryProtocol(new TIOStreamTransport(bis)));
 bis.close();
</code></pre>

<p> 需要注意的是由于Thrift序列化时,丢弃了部分信息，使用ID+Type来做标识，因此对新增的字段属性, 采用ID递增的方式标识并以Optional修饰来添加才能做到向后兼容。</p></li>
<li><p>Protobuf</p>

<p>Protobuf是Google开源的序列化框架，是Google公司内部的混合语言数据标准，用于RPC系统和持续数据存储系统，非常轻便高效，具有很好的可扩展性、也具有良好的向后兼容和向前兼容性。与上述的几种序列化框架对比，序列化数据紧凑、速度快、空间占用少、资源消耗较低、使用简单，但其缺点在于需要静态编译生成代码、可读性差、缺乏自描述、向后兼容有一定的约束限制。</p>

<p>这里需要注意目前ProtoBuf的版本到了3.x，比2.x支持更多语言但更简洁。去掉了一些复杂的语法和特性，更强调约定而弱化语法。因此，如果是首次使用就直接使用3.x版本。这里也针对Protobuf 3来讲。</p>

<p>首先需要编写.proto文件,并使用Protobuf代码生成引擎生成Java代码。</p>

<pre><code class="`"> //TestUser.proto
 syntax = "proto3";
 option java_package = "me.rowkey.pje.datatrans.rpc.proto";
 option java_outer_classname = "TestUserProto";
 message TestUser
 {
     string name=1;
     string mobile=2;
 }

 protoc --java_out=./ TestUser.proto
</code></pre>

<p>即生成TestUserProto.java，使用此类，即可完成序列化和反序列化：</p>

<pre><code class="`"> //序列化
 TestUserProto.TestUser testUser = 
           TestUserProto.TestUser.newBuilder()
           .setMobile("xxx")
           .setName("xxx")
           .build();

 byte[] bytes = testUser.toByteArray();

 //反序列化
 testUser = TestUserProto.TestUser.parseFrom(bytes);
</code></pre></li>
</ol>


<p>综上，对以上几个序列化框架做对比如下：</p>

<p> | 优点 | 缺点
&mdash;-|&mdash;&ndash;|&mdash;&mdash;
Java | JDK自带实现，包含对象的所有信息| 速度较慢，占用空间也比较大，只支持Java语言
Hessian | 支持语言比较多，兼容性较好 | 较慢
MsgPack | 使用简单，速度快，体积小| 兼容性较差，耗资源
Kryo | 速度快，序列化后体积小 | 跨语言支持较差，文档较少
Thrift | 高效 | 需要静态编译；是Thrift内部序列化机制，很难和其他传输层协议共同使用
Protobuf | 速度快 | 需要静态编译</p>

<p>在兼顾使用简单、速度快、体积小且主要使用在Java开发的场景下，Kryo是比较好的方案；如果特别要求占用空间、性能，那么Protobuf则是更好的选择。此外，JSON其实也是一种序列化方式，如果比较关注阅读性的话，那么JSON是更好的选择。</p>

<h2>提示</h2>

<p>面对这些RPC框架，选择的时候应该从以下几方面进行考虑：</p>

<ul>
<li>是否允许代码侵入：即是否需要依赖相应的代码生成器生成代码，比如Thrift需要，而Dubbo、Hessian就不需要。</li>
<li>是否需要长连接、二进制序列化获取高性能：如果需要性能比较高，那么果断选取基于TCP的Thrift、Dubbo。</li>
<li>是否需要跨网段、跨防火墙：这种情况一般就需要选择基于Http协议的，Hessian和Thrift的HTTP Transport。</li>
<li>是否需要跨语言调用：Thrift、Hessian对于语言的支持是比较丰富的，而Dubbo目前只支持Java语言。</li>
</ul>


<p>此外，除了上述框架之外，Google推出的基于HTTP 2.0的gRPC框架也开始得到了应用，其序列化协议基于Protobuf, 网络框架使用了Netty4。但其需要生成代码，可扩展性也比较差。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我是科蜜，20年的...]]></title>
    <link href="http://www.rowkey.me/blog/2020/01/27/kobe/"/>
    <updated>2020-01-27T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/01/27/kobe</id>
    <content type="html"><![CDATA[<p>5：30左右突然惊醒，拿起手机一看有同学给我发微信说科比挂了。我大大的问号，赶快看了一下朋友圈和网易新闻，已经有人发出了国外网站正式的报道。。。心里顿时五味陈杂，一时不知道如何是好。一个陪伴了自己整个少年时代的偶像说没就没了，还是以这种意外的方式，相信好胜心那么强的他也是非常不甘心的。也许有人会说，人家这么一个超级巨星，你们这些粉丝矫情啥，人家都不认识你。确实，我的存在对他来说是无所谓的，但是他对我的意义却是不一般，我也相信他对于无数他的粉丝都有不一样的意义。</p>

<!--more-->


<p>记得2000年我上初中，在同学家里玩NBA Live游戏，同学跟我说这个湖人队8号投篮真准，那是我第一次认识科比。那时候电视只有中央2台每周会播一次nba比赛，每到湖人比赛我都必看。也到处搜集科比的各种贴画，家里贴满了他的海报。那时候自己的爱好就是搜集科比的各种资料。也是因为科比，我开始喜欢上打篮球，虽然受限于身高，水平一直不咋样，但好胜心和他差不多，经常为了赢不了球，摸不到球，上不了场而特别难受。</p>

<p>后来上了初四实验班（相当于高中提前录取），由于是微机实验班，学习比较轻松，有很多时间来做一些自己喜欢的事情。而对我自己来说，除了摆弄一些电脑的事情，就是看各种体育新闻、看科比的新闻。那时候班里同学们会经常一起买篮球报、当代体育、篮球先锋报，然后换着看。当然，青春时代，少不了的就是“比”，经常和同学争论是科比厉害还是艾佛森、卡特、麦迪厉害。而2003年的科比闹出了鹰郡性侵案，迎来了人生的谷底，自己看到了他的各种无助和无奈，感觉全世界都开始抛弃他。不过最终他还是挣脱了出来，有了单场62分、单场81分、赛季场均35.4分的神迹，也把自己的球衣号码换成了24号，那意味着每天每个小时都要努力，也意味着他蜕变成了一个领袖。那时候的我也已经正式开始了高中生涯，和以前不一样的是，学习压力开始变得巨大，每天就是做题考试，生活也开始变得枯燥，一周半天假，一个月一天半假，休息时间也开始变得多余，而且我们班还禁止打篮球。。。自己只能靠去看科比的各种新闻作为调节剂，他每一次表现好，我也就状态好，也就考的好。那时真的以为自己和他有某种关联了。。。也会和同学见缝插针的去打球，即使是课间休息的那十分钟。和他这段经历类似的是，我小学初中一直是年级第一第二，但高中在班级里一直处于十几名的位置，是包括我后面大学的所有学生生涯的谷底，但高考我发挥还不错，第一次考了班级第一，虽然是因为班里几个学神发挥不太好，但是分数我也是比较满意的。</p>

<p>后来上了大学，依然热情不减，宿舍的墙上都是科比的海报，鼠标也是湖人款的。也看着湖人慢慢组建齐了冠军阵容，直到09年夺冠，那一刻我当时就哭了。从巅峰到谷底再到巅峰，那种经历想想就令人动容。尤其是10年，还记得总决赛最后一场的上半场已经落后将近20分，当时我心灰意冷，再加上早起看比赛，实在忍不住困意倒头就睡了。在睡梦中突然听到全宿舍楼的人在欢呼，我心想不会逆转了吧，打开电视看到科比在欢呼，那一刻就感觉自己拿了总冠军一样。那年的我正式本科毕业，专业第一保送了研究生，也算是和科比的巅峰关联吧。</p>

<p>再后面，湖人的夺冠班底逐渐散了，从此一蹶不振。科比也一次次遭遇伤病从而无奈退役。我自己也从研究生毕业开始走上社会，也慢慢变得没时间没兴趣看nba比赛，尤其是科比退役之后，真的是觉得nba这些比赛没啥意思。科比退役后的各种新闻还是会让我激动，他拿了奥斯卡最佳短片动画奖，他开公司，他和马云在企业峰会上高谈阔论，他来中国参加综艺节目，他参加雪碧慈善邀请赛，我真觉得他退役后的成就有可能超越他的篮球成就。记得离他最近的一次就是14年科比受马云的邀请来阿里，虽然是在隔壁的公司里，虽然自己还是没见到。。。我自己一直以来的梦想之一就是有一天可以变得足够优秀能够和他成为朋友，能够在洛杉矶做他的邻居。可惜这一切再也不可能实现。。。也可能成为我这一生最大的遗憾之一。</p>

<p>就是这个人，凌晨四点的洛杉矶、对队友的严格要求、右手受伤就把左手投篮练出来、手指扭了硬生生掰回去继续比赛，他的好胜心、偏执和努力激励我的进步，他是我的青春。这就是科比对一个20年科蜜的意义。</p>

<p>谢谢你，科比！祝福你在天堂里可以继续你的精彩。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我的2019]]></title>
    <link href="http://www.rowkey.me/blog/2020/01/23/my2019/"/>
    <updated>2020-01-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/01/23/my2019</id>
    <content type="html"><![CDATA[<p>和去年一样，本文来自自己给部门的公开信。内容经过脱敏。</p>

<hr />

<p>2020年已经过去了快一个月。回顾2019年，真的感谢大家，总体来看，部门的全年产出是符合预期的，也获得了其他需求部门的高度好评。不仅仅支撑了微鲤看看、广告平台、用户增长等业务相关系统的快速迭代，也不断地在探索运维基础设施、前端基础设施、大数据平台、推荐系统、公共组件、技术中间件并取得了一些令人印象深刻的成果。</p>

<p>要求了大家做全年的总结和新的一年的规划，我自己也从工作、学习和生活三个方面来总结一下我自己的2019年。</p>

<!--more-->


<h2>工作</h2>

<p>说到工作，特别想跟大家说一下加班的问题。由于公司战略的要求，公司在年底的几个月开始了大小周，目的是为了增加产出，也是为了让大家能够有一种创业公司的心气。也有部门的同事跟我反映过说部门不怎么加班，感受不到创业公司的气氛。这一点非常值得称赞。我在这里再讲一下我对加班的看法。</p>

<ul>
<li>加班的目的并不是加班，而是提高产出，那么产出是由效率和时间决定的。如果时间增加，但是效率下降，大部分情况下，产出也是下降的。</li>
<li>对于脑力工作者，每天能够高效工作5、6小时就很了不起了，再多的时间其实是低效劳动，太过疲劳反而容易出错。</li>
<li>很多人工作散漫，干活拖拖拉拉，心想着干不完就加会儿班。在合理的时间内干不完活而加班，是工作能力低的表现，这种行为并不值得提倡。</li>
<li>根据我自己的经验看，长期加班，根源问题基本都是“项目失控”。由于技术中心的特殊性，很多项目都是没有产品经理也基本面向的都是内部人员，项目的排期安排一直以来都是让每个人来定的。只要合理，我一般都不会有什么意见，有问题也一直欢迎大家跟我提意见。如果你定了deadline，却经常需要加班来赶进度，明显的就是在评估工时、项目管控上有问题。当然，我过去做的不好的一点就是只给进度要求，不给资源，这一点我会注意改进。</li>
<li>死守自己的deadline-高标准、准时、保质保量、不给其他同事挖坑。最好的团队合作，不是你整天对别人的工作指手画脚，整天看着各种客观原因，而是把自己的事情做到位，做到极致。这也是我今年讲的最多的要具有“owner意识”：把交给自己的任务当成自己的东西，追求极致，最后受益的不仅仅是公司，你自己也会得到最大的成长和他人的认可。</li>
<li>少加班，多动脑。和我之前听到过的说法“脑子要比手快”是一个道理。做事之前，先想想有没有更好的办法，比立即就闷头苦干，最终带来的效果可能是千差万别的。而且，作为一个公司、一个商业组织来说，最终看的只能是功劳，不会是苦劳。</li>
<li>脑力工作者想要划水摸鱼，很难被发现。我并不想给大家营造一种加班的氛围，非得大家每天在公司待到九点十点才行。我希望的是大家都是志同道合的人，是即使不加班，也会在业余时间思考、学习的人。</li>
</ul>


<p>还有一点需要提的是一个概念叫“情绪自由”。怎么说呢？之前，有同事跟我讨论了这个“情绪自由”的问题。就是说你所处的位置有时候决定了你敢不敢发泄你的情绪？比如说，你是一个没有管理职权的开发工程师，那么大部分情况下，即使你心里有情绪也不会发泄出来，因为你知道发泄出来也没用。而如果你是一个Leader，在你团队成员面前，很多时候就会随意让情绪宣泄出来。这个其实非常不好，尤其是对于一个公司的管理层来说，如果总是“情绪自由”，那么大家就会越来越不敢提问题，隐藏在看不到的地方的问题也就越来越多，累积起来一旦爆发那么后果也会严重的多。</p>

<p>接下来，从部门管理、架构、技术团队管理三个部分来讲一下2019年我完成的工作。</p>

<h3>部门管理</h3>

<p>2019年部门发生了一些组织架构改动，组织架构的改动服务于公司的整体目标，随之而来的则是人员的变动，再加上持续的有人加入有人离开，人员的变动带来了一系列问题：如何让大家知道并深刻理解部门的文化，如何融入部门，如何更有凝聚力。对于这些，做的一些工作包括：</p>

<ul>
<li>重新定义了部门的文化：<strong>极客创新、及时反馈</strong>，对之前的“件件有着落、事事有回音”做了简化的同时，还增加了极客创新，目的就是让大家意识到“技术中心”应该是一个创新部门，是一个用创新提升业务的部门。</li>
<li>重新梳理了部门的月度例会流程，包括：

<ul>
<li>不断念经，让大家能够深刻理解并贯彻部门文化</li>
<li>同步OKR进度，让大家随时了解部门的OKR进度，知道关键目标在哪</li>
<li>增加了“每月分享”环节，让大家分享自己工作、生活中的心得，给大家带来启发</li>
</ul>
</li>
<li>探索除了聚餐之外的团建形式，实践形式包括：switch游戏比赛、组队知识竞赛、巅峰故事会等。</li>
</ul>


<p>部门的梯队建设也有了一定程度的起色，在各个团队Leader的共同努力之下，每个团队都有增员。</p>

<p>此外，今年由于某些原因，自己承担了行政人事事务决策的工作，帮助行政人事部门做了一些工作。</p>

<h3>架构</h3>

<p>架构组是今年才正式成立的。也引入了公司第一个专职架构师，从最终的结果来看，大大分担了我自己在架构方面的工作，在业务的保障上也达到了预期，证明了架构师机制的有效性。此外，在公共组件、技术中间件的引入和开发上，相比之前在速度和效果上都有提升。我自己这方面的工作主要集中于上半年。</p>

<p>此外，针对目前公司的技术Leader架构能力欠缺的问题，聘请了外部的技术顾问来做架构方面的培训。</p>

<h3>技术团队管理</h3>

<p>随着业务的增长，2019年公司的技术团队规模也在激增。2019年自己的重心是在技术团队的整体管理上。</p>

<p>首先，一直困扰我的是，做为公司的CTO，职责是什么？重点工作是什么？如果换成一个人来代替我，他会做什么？针对这个，我看了不少书，也问了不少朋友和前同事。最后基本上是扫清了自己的困惑，明确了自己的重点工作。可以分为四个部分：</p>

<ol>
<li>业务支撑：公司是一个产品驱动的公司，因此业务肯定是最重要的。保证业务的稳定性，支撑业务的快速迭代，这些都是重点工作。</li>
<li>工程效率提升：技术团队的规模增大，带来的并不一定是产出提高。必须有相应的配套研发流程、基础设施才能使得人员规模的增大带来整体产能的提高。今年组织技术Leader学习了《持续交付2.0》一书，并结合公司目前的实际情况，针对持续交付流水线进行了升级优化。也针对工程效率专门成立了“工程效率”小组，来识别研发流程的瓶颈，进行针对性优化。此外，今年也着重强调了全端工程化的问题，尤其全端监控体系的建设。</li>
<li>科技能力提升：和第一点有所关联。需要去识别公司业务发展上的一些技术瓶颈，做技术预研。</li>
<li>梯队建设：针对2018年的梯队现状，2019年定的招人基调是“资深带队、高级为主、中级可成长”，主要招聘高级开发，初中级招实习生培养。年底梳理了新的研发岗位职级要求，从最终的定级结果来看，研发梯队的层次基本达到了目标。此外，由于公司的很多技术Leader都是在公司成长起来的，缺乏成熟的管理经验，下半年举办了几次技术管理的培训课，以加强技术管理者对管理的认知和管理技能的掌握。</li>
</ol>


<p>此外，2019年公司强调了横向委员会的横向协同职能。年初正式确认了技术委员会的运行机制，并切实推行了起来。自己也加强了对各个技术方向的工作把控。</p>

<h2>学习</h2>

<p>2019年年初定了将近30本书的阅读计划，到年底完成了大约14本。</p>

<ul>
<li><p><a href="https://book.douban.com/subject/26760576/">清教徒的礼物</a></p>

<blockquote><p>同学推荐的一本管理书籍，主要是讲的美国的管理文化在世界各地的普及，尤其是日本和中国。阐述了清教徒（第一批欧洲移民，起源于英国，在北美殖民地得以实践与发展）的一些特质，也是美国能够打赢两次世界大战的原因，包括：建造“人间天国”的坚定信念；亲力亲为的技师精神；集体主义；组织能力：善于协调各种财力、物力和人力的组织能力。并且在书的最后给出了管理黄金时代优秀实务背后的25条原理。看完这本书，对于其中的一些东西很有共鸣，比如：自下而上的管理、专家（职业经理人）崇拜的危害等。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/30419555/">持续交付2.0</a></p>

<blockquote><p>作者乔梁是《持续交付: 发布可靠软件的系统方法》的译者，同时也是此书作者在thoughtworks的同事，目前是腾讯等很多互联网公司的高级管理顾问。这本书称为2.0是在上述一书中加入了精益创业部分，形成双环模型。阐述了持续交付的概念以及具体到部署流水线各个环节的建立、优化等，涵盖了产品、研发、测试、运维等诸多方面。对于提高产研效率有非常大的帮助。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/30333919/">架构简洁之道</a></p>

<blockquote><p>作者是鼎鼎大名的Uncle Bob，自己之前一直在看此书的英文原版。此书虽然讲的是传统单体软件架构的一些设计模式、原则等，但是本质上和现在的SOA、微服务是一样的。阐述了什么是架构、如何衡量架构、三大编程范式的本质、架构设计原则、组件原则等。并着重阐述了区别与传统的MVC分层架构的简洁架构是如何解决无法展现具体的业务领域、不能防止跨层调用等问题的。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/30254993/">稻盛和夫哲学精要</a></p>

<blockquote><p>稻盛和夫是“盛和塾”（向企业家塾生义务传授经营哲学）的创始人，被称为日本经营之圣。他曾经创办过两家世界五百强企业，并曾经把日航从破产重建带到扭亏为盈。此书主要汇集了他的一些经营哲学。令我印象较深的有：小善大恶，大善小恶；仔细思考直到“看到结果”的状态；乐观构思，悲观计划，乐观实行；付出不亚于任何人的努力；现金与票据一一对应原则；时刻怀有谦卑之心；为别人的成就叫好。书的内容不多，就是一个小册子，时常翻阅能够不断有新的启发和认识。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/6749832/">复杂</a></p>

<blockquote><p>什么是复杂科学？其中包括哪些知识。这本书就是对复杂科学的一些讲解。横跨生物、技术和社会学等领域，并探寻复杂系统的普遍规律，此外还探讨了复杂性与进化、人工智能、计算、遗传、信息处理等领域的关系。令我印象深刻的包括遗传算法的普遍形式、自相似分形的意义、冯诺依曼的冯诺依曼计算机体系以及元胞自动机、无尺度网络幂次定律。其中适用于互联网领域的幂次定律能够揭示不少东西。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26895988/">学习之道</a></p>

<blockquote><p>阐述了学习并且能够让学习到的东西成为自己知识的一些高效方法和思维模式。令我印象深刻的有发散思维的3B方法: Bus、Bed、Bath。即专注思维下容易陷入思维定式，这时候试着转换到这三种场景下，能够切换到发散思维，有时候会有意想不到的思路。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/34812013/">中台战略：中台建设与数字商业</a>&amp;&amp;<a href="https://book.douban.com/subject/27039508/">企业IT架构转型之道</a>&amp;&amp;<a href="https://time.geekbang.org/column/intro/234">极客时间《说透中台》</a></p>

<blockquote><p>这三本书/课程放在一起，主要都是对中台这个2019年技术圈最流行的词的讲述，第一本是云栖科技基于这些年它们支撑过的企业中台建设经验沉淀出的方法论和实践，第二本则是阿里巴巴的共享业务中台的构建之路以及具体的实现策略，最后一个课程则是来源于thoughtworks的一些企业中台落地场景。综合对比其他各种博文、书籍来看，这三本书讲的比较符合我自己的理解。总体概括：中台是企业级能力复用平台，相比起平台，其更注重自助化、可配置、运营和业务；中台也不是银弹，并非所有企业都需要。对中台的概念以及中台的具体实施感兴趣的可以参考这三本书/课程。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/27040502/">CTO说</a></p>

<blockquote><p>此书来自于51CTO举办的CTO训练营的讲师们的课程。通过阅读此书，进一步提升了我对CTO这个角色的认知，包括职责、需要做好的事情、需要具有的能力等。也从中得到了不少可以在公司落地的想法，包括如何更好的做绩效管理、如何建立优秀技术团队、建立自己的管理仪表盘来密切关注数据、把事故复盘会改成宕机培训学校、建立新晋技术管理者的管理模板等等。总体来看，非常值得新的CTO们一读。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26901342/">管理的常识</a></p>

<blockquote><p>作者是陈春花，既是企业管理教授也有企业高管经历，是国内管理大师级的人物，写了非常多的管理著作，其公众号“春暖花开”会经常分享她对管理的一些思考，非常值得订阅。《管理的常识》此书引用了其他经典管理书籍/理论阐述了管理理论中的一些常识，包括了管理、组织、组织结构、领导、激励、决策等。让自己印象深刻的包括：管理最终只以成就做为衡量标准；有效的管理就是帮助同事（上级和下属）发挥长处并避免用到他们的短处；职能部门是不能具有权利的；没有不好的士兵，只有不好的将军，需要针对不同员工选用不同的领导风格；群体决策并不是最好的决策方式，而是风险较小的决策方式。推荐企业管理者阅读此书。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26953606/">人类简史</a></p>

<blockquote><p>认知革命使人类成为想象的共同体，农业革命使人类陷入奢侈生活的陷阱，科技革命终将使人类成为神一样的存在。人类通过想象和虚构的能力将彼此连接、有效合作，国家、宗教、企业都是想象和虚构的现实，人类依靠这种想象来寻找认同、开展合作，由此一步步登上食物链的顶端，抵达其他生物无法企及的地位。这本书从智人的角度回顾并理清影响人类发展的重大脉络，视角很广。概括起来就是人类和其他动物本质没任何区别，甚至基因复杂度还不如一些动物，需要在大历史中重新审视人类自己。宗教那一部分佛教主张在痛苦的时候，去想问题的本质忽略感受就能让自己不痛苦，让自己有所启发。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/33424487/">时间的秩序</a></p>

<blockquote><p>这本书主要讲述的是时间的本质，内容不多，但看完的感觉真是不明觉厉。包括：时间不是统一的，区别于海拔高度和速度，时间的快慢都不一样；微观世界不同于宏观世界，很多事情都反常识。感觉需要多看几遍才能不断有所理解。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26910621/">六项思考帽</a></p>

<blockquote><p>这本书讲的是一种简单高效的思考方式，只允许思考者同一时间做一件事情，学会将逻辑与情感、创造与信息区分开来。六项不同颜色的代表不同的思考方式，戴上某一项帽子，那么就要遵循当前的思考方式来思考问题，从而避免大家讨论问题时的各种冲突，以更好地引导集体智慧，从而解决问题，提高生产力。使用这种方法时，团队需要学会怎样把思考过程分为六个不同的方向。</p></blockquote></li>
</ul>


<p>以上是已经完成阅读的书籍，目前包括了2019年未完成以及新加入的待读书籍列表如下：</p>

<h3>工作</h3>

<ul>
<li>极客时间《研发效率破局之道》</li>
<li>持续交付: 发布可靠软件的系统方法</li>
<li>数据即未来</li>
</ul>


<h3>管理</h3>

<ul>
<li>我读管理经典</li>
<li>人月神话</li>
</ul>


<h3>技术</h3>

<ul>
<li>程序员的三门课</li>
<li>许世伟的架构课</li>
<li>未来架构</li>
<li>分布式系统概念与设计</li>
<li>分布式Java应用</li>
<li>大数据日知录</li>
<li>数据密集型系统设计</li>
</ul>


<h3>企业</h3>

<ul>
<li>公司进化论</li>
<li>闪电式扩张</li>
<li>创新者的窘境</li>
<li>良性增长</li>
<li>定位：有史以来对美国营销影响最大观念</li>
<li>刷新：重新发现商业与未来</li>
<li>超级版图：全球供应链、超级城市与新商业文明的崛起</li>
</ul>


<h3>其他</h3>

<ul>
<li>少有人走的路：每天十分钟，一学就会的心灵疗愈法</li>
<li>极简宇宙史</li>
</ul>


<p>需要额外说一下的是，这些书我以前倾向于看纸质书的，但2019年能够在微信读书APP上找到的基本都在上面看了。其中最大的好处就是当某个知识点记不太清楚的时候，很容易就可以搜索到，这个比纸质书籍方便太多了。但不好的就是缺少阅读纸质书的那种感觉，并且很多新书开始只有纸质版。</p>

<h2>生活</h2>

<p>生活上，上半年依然在坚持健身，下半年由于健身房的变动而停止。但是重新开启了篮球运动，基本上能够做到一周两个小时的运动量，自己也会隔几天在家里做俯卧撑、仰卧起坐等运动。整体状态上还算不错，但年底的体检还是一些小毛病，有点郁闷。so，开始从饮食方面来控制。最近感觉体重开始有所下降了。希望能坚持下去。</p>

<h2>总结</h2>

<p>以上就是2019年自己的总结。整体来看，是满意中夹杂着失望的。新的一年，自己的计划如下：</p>

<ul>
<li>加强自己的情绪管理，能够更理性地处理事情、解决问题。</li>
<li>继续弥补自身在业务和数据Sense、成本意识、商业谈判能力、产品管理能力这些方面能力的短板。</li>
<li>完成中台架构（组织和技术）在公司的落地或者不落地。</li>
<li>继续完善整个技术团队的顶层技术体系建设。</li>
<li>重点跟进企业效能提升工作，包括工程效率和内部IT系统建设。</li>
<li>全面优化技术成本，包括提高资源利用率、降低无效成本。</li>
<li>进一步探索并完善架构师机制，保证业务稳定性和技术先进性。</li>
<li>建立客户端架构组，统一把控客户端基础技术体系建设。</li>
<li>推进数据团队的融合，有效完成几个数据相关项目的开发和上线。</li>
<li>推进Devops平台的开发和上线。</li>
<li>完成2019年读书计划中剩下的书籍。</li>
<li>坚持锻炼，身体是最重要的。</li>
</ul>


<p>最后，最近武汉肺炎的事情正在愈演愈烈。大家务必注意自己和家人的安全，少出门，出门记得戴口罩。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《管理的常识》学习笔记]]></title>
    <link href="http://www.rowkey.me/blog/2019/12/20/manage-notes/"/>
    <updated>2019-12-20T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/12/20/manage-notes</id>
    <content type="html"><![CDATA[<blockquote><p>作者是陈春花教授，既是企业管理教授也有企业高管经历，是国内管理大师级的人物，写了非常多的管理著作，其公众号“春暖花开”会经常分享她对管理的一些思考，非常值得订阅。《管理的常识》此书主要讲了管理理论中的一些常识，包括了管理的概念、组织、组织结构、领导、激励、决策等。让自己印象深刻的包括管理最终只以成就做为衡量标准；职能部门是不能具有权利的；群体决策并不是最好的决策方式，而是风险较小的决策方式。推荐企业管理者阅读此书。</p></blockquote>

<p>今年随着公司人员规模的不断扩大，自己越发意识到了管理的重要性。尤其对于技术管理者来说，程序员的思维和管理者的思维有很多地方是截然不同的，如果不做好认知的改变和思维的转变，很容易用惯性思维来做事，那么一个非常优秀的研发工程师很可能会成为一个非常不合格的管理者。所以，自己一直在寻找管理的书籍、课程来学习。其中，《管理的常识》这本书是极客邦TGO寄来的礼物，仔细阅读了一下，还是有不少启发的。</p>

<!--more-->


<p>先给出自己笔记的思维导图，如下：</p>

<p><a href="http://www.rowkey.me/post_images/manage-notes.png" target="_blank"><img src="http://www.rowkey.me/post_images/manage-notes.png"/></a></p>

<p>其中让自己印象比较深刻的几点：</p>

<ul>
<li>管理最终只以成就做为衡量标准，需要知行合一</li>
<li>职能部门不能具有权利，因为其并不直接与业务相关</li>
<li>群体决策并不是最好的决策方式，而是风险较小的决策方式。当品质比成员接受程度高时，独断式决策；当接受程度比品质重要时，群体决策（共识）；品质和接受程度都高时，咨询式决策；品质和成员接受程度都不高时，哪个方便选择哪个</li>
</ul>


<p>&ndash;</p>

<p>书籍链接：<a href="https://book.douban.com/subject/26901342/">https://book.douban.com/subject/26901342/</a></p>

<p><img src="http://www.rowkey.me/post_images/manage.png" width="300"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技术琐话]]></title>
    <link href="http://www.rowkey.me/blog/2019/12/18/tech-talk/"/>
    <updated>2019-12-18T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/12/18/tech-talk</id>
    <content type="html"><![CDATA[<p>日常的工作学习中，经常会看到好的知识点，对自己有提示的一句话，或者是自己突然想通了一件事情。这里以“技术琐话”作为主题来聚合：<a href="http://www.rowkey.me/blog/talks/">技术琐话</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[中台简谈]]></title>
    <link href="http://www.rowkey.me/blog/2019/11/23/middle-talk/"/>
    <updated>2019-11-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/11/23/middle-talk</id>
    <content type="html"><![CDATA[<blockquote><p>面对新事物，先接纳，再判断。不要轻易就否定，即使经过自己的思考后确实没啥价值，这期间的思考过程也是一种知识梳理和思维锻炼。</p></blockquote>

<p>2019年技术圈最火的一个词非“中台”莫属了。联想到公司已经在持续做的平台化，其实会让人感到混乱。平台和中台有啥区别？有了中台，那么前台和后台又指的什么？本文是自己在调研中台概念中沉淀出来的一些思考。</p>

<!--more-->


<h2>中台是什么</h2>

<p>一种特殊形式的平台，抽象业务/系统的共性，支撑业务快速发展，是<strong>企业级共享能力平台</strong>。其核心在于对业务、数据、技术的抽象，对服务能力进行复用。解决重复开发、数据分散、试错成本高的问题。中台突出的是规划控制和协调的能力，前台强调的是创新和灵活多变。</p>

<ul>
<li>业务中台：多个前台业务应用共享的需求，关注如何支撑在线主营业务。一般来说业务中台由多个中心系统组成。</li>
<li>数据中台: 专用的数据处理平台，用技术连接大数据计算存储能力，用业务连接数据应用场景能力的平台。</li>
<li>技术中台：整合和包装了云基础设施以及在其上的各种技术中间件，并在此基础上建设和封装了简单易用的能力接口，提供了基础设施重用的能力。</li>
<li>研发中台：关注应用研发效率的管理平台，为应用的开发提供了流程、质量管控和持续交付的能力。</li>
<li>移动中台：平台级的移动端开发支持</li>
<li>AI中台：数据中台之上，模型的训练、发布，智能服务的构建自动化，统一的元数据管理体系，模型的全生命周期管理。</li>
<li>组织中台：与中台技术架构相匹配的组织架构</li>
</ul>


<p>众多的可复用能力只是中台的形，<strong>核心的业务数据和业务流程</strong>才是中台存在的本质。</p>

<h2>为什么要有中台</h2>

<p><strong>传统的烟囱式架构面临的问题</strong></p>

<ul>
<li>重复性建设对人力物力的浪费</li>
<li>系统间交互的集成和协作成本昂贵</li>
<li>不利于业务沉淀和持续发展</li>
</ul>


<p><strong>共享服务带来的优势</strong></p>

<ul>
<li>提高研发效能，赋予业务快速创新和试错能力</li>
<li>打通数据，真正发挥大数据的威力，共享数据价值</li>
<li>中台组织结构提升组织效能</li>
</ul>


<h2>怎么实现中台战略</h2>

<h3>思路的改变</h3>

<ul>
<li>提升自己的研发效率->提升别人的研发效率</li>
<li>从代码->需求，到代码->组件->需求，到代码->组件->可配置->需求</li>
<li>业务逻辑和平台逻辑分离，业务逻辑和业务逻辑隔离</li>
<li>集中配置，分布式运行</li>
</ul>


<h3>总体架构</h3>

<p><img src="http://www.rowkey.me/post_images/middle-office-arch.png" alt="" /></p>

<h3>建设思路</h3>

<ol>
<li><p>中台化改造</p>

<blockquote><p>对已有平台的中台化改造</p></blockquote>

<ul>
<li>平台不断对于自身治理演进、打破技术边界、逐渐拥抱业务、容纳业务、具备更强的业务属性的过程。</li>
<li>通过业务抽象以及可配置化和白屏化（给平台产品做一个配置界面实现自助式服务，没有UI要求，一般是一个白页面加一些配置项）的改造升级</li>
<li>技术平台->技术中台：对于技术平台的治理、安全、可用性和自助式的产品化包装，打造自助服务平台，关注业务的用户使用体验，让业务可以更快速更方便体验更好的使用企业内部的技术能力</li>
</ul>
</li>
<li><p>中台化：利用平台化的思维和手段梳理、识别、沉淀与复用企业级核心能力的过程。根据业务演进逐渐积累而成，<strong>分阶段逐步实施</strong>。多于一个前台业务需要某一种能力，那么此能力即可沉淀为中台能力。切忌大而全的建设中台。</p>

<ul>
<li><strong>资源集中管理->能力抽象->灵活性</strong></li>
<li><strong>共享服务：普通的服务能力->组件化服务，并提供良好的服务治理支持</strong>

<ul>
<li>找到一个合适的服务化对象：API as service，存量API升级成服务化平台的组件服务</li>
<li>建设对象服务化的基础设施：Product as Service，封装API服务</li>
<li>服务化实施阶段: Solution as Service</li>
<li>增强服务和基础设施实现服务的精细治理</li>
</ul>
</li>
</ul>
</li>
<li><p>运营</p>

<ul>
<li>运营前置：制定迭代计划及接入计划。中台产品推广、前台（用户）接入计划以及接入后的运营支持</li>
<li>根据用户分层制定SLA：不同的需求响应机制、不同的沟通管理机制、不同的服务质量控制机制、不同的问题处理及升级机制</li>
</ul>
</li>
<li><p>演进</p>

<ul>
<li>各种中台的逐渐建设</li>
<li>共享服务中心的不断增加</li>
</ul>
</li>
</ol>


<h3>建设要点</h3>

<ul>
<li>在“工具”与“完全为业务服务”之间寻找平衡点，既需要满足业务的需求，又不能过度参与业务。</li>
<li>重视中台的运营、持续治理以及演进</li>
<li>拆分整体应用形成业务组件：抽象程度越高，中台对业务的适配度越高。</li>
<li>可配置，自助白屏化</li>
<li>足够灵活的扩展点，支持定制化扩展</li>
<li>服务文档化</li>
<li>开放体系：对内对外</li>
</ul>


<h2>参考资料</h2>

<ul>
<li>《中台战略》</li>
<li>《企业IT架构转型之道》</li>
<li>极客时间《说透中台》</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何进行有效的技术分享（演讲）]]></title>
    <link href="http://www.rowkey.me/blog/2019/10/23/how-to-tech-share/"/>
    <updated>2019-10-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/10/23/how-to-tech-share</id>
    <content type="html"><![CDATA[<p>讲述如何准备一次技术分享（演讲）以及演讲中的注意事项。来自内部分享PPT，后续会发布<strong>详细版</strong>。</p>

<!--more-->


<h2>What-什么是有效的技术分享</h2>

<ul>
<li>演讲

<ul>
<li>知识/技能培训</li>
<li>组件/平台/系统使用培训</li>
<li>工作实践经验/教训</li>
</ul>
</li>
<li>写博客？</li>
</ul>


<p><strong>有效->满足听众的诉求</strong></p>

<h2>Why-存在的问题</h2>

<ul>
<li>语速太快</li>
<li>图解太少</li>
<li>缺乏实践案例</li>
<li>内容太多</li>
<li>内容都在ppt上</li>
</ul>


<h2>How-如何准备技术分享</h2>

<h3>目的</h3>

<ul>
<li>开阔眼界</li>
<li>培训</li>
<li>讨论</li>
</ul>


<p><strong>听众的组成；听众对领域的了解程度；听众的诉求</strong></p>

<h3>结构</h3>

<ul>
<li>Who</li>
<li>What</li>
<li>Why</li>
<li>How：重点选3、4点</li>
<li>Future</li>
<li>Recap</li>
</ul>


<h3>内容</h3>

<ul>
<li><strong>backlog</strong>: 收集、积累信息</li>
<li><strong>逐字稿</strong></li>
<li><strong>形式</strong>：

<ul>
<li>报告：精确的信息和枯燥的细节、事实和图表</li>
<li>故事：具体；强调说服和感染；<strong>赋比兴</strong></li>
<li>演讲：介于报告和故事之间</li>
</ul>
</li>
<li><strong>实践案例</strong>、经验 > 说教

<pre><code>  - Situation: 当时的情况
  - Target: 面临的任务/目标
  - Action: 采取的行动
  - Results: 取得的结果
</code></pre></li>
<li>内容量适可而止</li>
<li><strong>Demo</strong>: 关键特点、容错处理</li>
</ul>


<h3>PPT</h3>

<blockquote><p>烘托效果和提醒，<strong>配角</strong></p></blockquote>

<ul>
<li>How的几个重点，每一个点2-3页，共15-20页</li>
<li>精简文字+图表，多图少字</li>
<li><strong>简洁、干净、一致、跳脱</strong></li>
<li><strong>忌</strong>：交互式幻灯片、大片文字</li>
</ul>


<h3>练习</h3>

<hr />

<blockquote><p>多练出奇迹</p></blockquote>

<ul>
<li>自我练习</li>
<li>让别人听：公司/团队内部试讲</li>
<li>冥想：站在听众的角度去接受信息</li>
</ul>


<p><strong>根据反馈不断进行迭代改进</strong></p>

<h2>分享Tips</h2>

<ul>
<li>紧张

<ul>
<li>觉察：“只要不被听众察觉到紧张，那就不是紧张”。</li>
<li>充分准备</li>
<li>内容量适可而止</li>
<li>简洁PPT：留有自由发挥余地</li>
<li>练习</li>
</ul>
</li>
<li>节奏

<ul>
<li>语速放缓</li>
<li>多准备点内容：演讲时间固定的情况下讲不完比冷场要好</li>
<li>规划要点、时间</li>
</ul>
</li>
<li>目光：面对听众并熟视无睹；巡视听众</li>
<li>语调：有感情；抑扬顿挫</li>
<li>手势：忌手足无措</li>
<li>演讲设备/PPT的备份</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据传输之RESTful]]></title>
    <link href="http://www.rowkey.me/blog/2019/09/28/restful/"/>
    <updated>2019-09-28T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/09/28/restful</id>
    <content type="html"><![CDATA[<p>REST，全称表现层状态转移（Representational State Transfer）, 指的是资源在网络中以某种表现形式进行状态转移，是一种架构风格。其描述的是在网络中Client和Server的一种交互形式。简单来说就是用HTTP URL来定位资源，用HTTP的各种method来描述操作。其关键的三个概念如下：</p>

<ul>
<li>Resource: 资源，主要指的是数据。</li>
<li>Representational：数据的表现形式，如JSON、XML、HTML等。</li>
<li>State Transfer：状态变化, 通过HTTP method来描述。</li>
</ul>


<p>REST经常被用来规范API的设计以及数据传输的格式，可以统一给各种客户端提供接口,包括Web、iOS、Android和其他的服务。REST不需要显式的前端页面，只需要按照格式返回数据即可。符合REST风格的API称为RESTful API，符合RESTFul规范的架构称为RESTful架构。如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/restful/restful.png" alt="" /></p>

<!--more-->


<h2>一. 操作</h2>

<p>RESTful是基于HTTP协议的，其主要依赖于HTTP协议的几种method来表示CRUD（create、read、update和delete,即数据的增删查改）操作：</p>

<ul>
<li>GET: 从服务器上获取资源</li>
<li>POST: 创建新的资源</li>
<li>PUT： 更新服务器资源</li>
<li>DELETE： 删除服务器资源</li>
</ul>


<p>这里需要注意两点：</p>

<ul>
<li>GET、PUT和DELETE应该是幂等的，即相同的数据和参数下，执行一次或多次产生的效果是一样的。</li>
<li>对于POST和PUT操作，应该返回最新的资源，删除操作则一般不必要。</li>
<li>所有的操作都是无状态的，即所有的资源，都可以通过URL定位，这个定位与其他资源无关，也不会因为其他资源的变化而改变。</li>
</ul>


<p>除了上述方法之外，还有一个PATCH方法也用于更新资源的部分属性，但并用的并不多，用POST即可。</p>

<p>此外，HTTP 1.1的几个头部也是应该注意的：</p>

<ul>
<li>Accept: 客户端要求服务器返回什么样表现形式的数据。RESTFul API需要根据此头部返回合适的数据。</li>
<li>If-Match: 在对资源做更新和删除操作时，客户端提供If-Match头，值为服务端上次对此资源返回的Etag, 服务端对比Etag如果一致才做更新和删除，否则返回412。</li>
<li>If-None-Match: 和If-Match相反，如果不匹配上次的Etag才返回数据，匹配的话则返回304，多用于Get请求。</li>
<li>If-Modified-Since：值为时间，如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304，多用于Get请求。</li>
</ul>


<h2>二. 返回码</h2>

<p>HTTP本身已经提供了很多StatusCode来表示各种状态。RESTFul接口需要遵循这些定义，返回合适的状态码和数据。当然，如果是内部使用，统一返回200，在返回数据里自定义一套status code也是可以的。</p>

<p>HTTP的状态码大体分为几个区间：</p>

<ul>
<li>2XX：请求正常处理并返回。</li>
<li>3XX：重定向，请求的资源位置发生变化。</li>
<li>4XX：客户端发送的请求有错误。</li>
<li>5XX：服务器端错误。</li>
</ul>


<p>在自己设计返回码的时候最好也遵循此范围设计，以下是其中几个常用的状态码：</p>

<ul>
<li>200：表示请求成功。</li>
<li>301：资源已经永久移动到新的地址，新的URL会在响应头中返回。</li>
<li>302：资源临时被移动到新的地址，新的URL会在响应头中返回。</li>
<li>304：表明资源未改变。主要配合请求头中的If-None-Match和If-Modified-Since使用。</li>
<li>400：错误请求，表示请求中有语法错误。</li>
<li>401：请求的资源需要认证，请求没有提供认证信息或者认证错误。</li>
<li>403：资源被禁止访问。</li>
<li>404：资源不存在。</li>
<li>502：错误的网关，通常是作为代理的服务器无法收到远程服务器的正确响应。</li>
<li>503：服务不可用。</li>
</ul>


<h2>三. 资源</h2>

<p>资源是RESTful API的核心，其以URI（统一资源标识符）标识，而URL则不仅能够标识一个资源，还能够定位资源。RESTful中使用HTTP URL标识并定位一个资源。原则上只使用名词来指定资源，而且推荐使用复数。以对记事的CRUD API的设计为例：</p>

<ul>
<li>获取所有记事列表：GET /api/notes?page=1&amp;per_page=20</li>
<li>获取某人的所有记事列表：GET /api/users/{uid}/notes</li>
<li>获取标记为星的记事：GET /api/users/{uid}/notes?star=1</li>
<li>创建记事：POST /api/notes</li>
<li>删除某一个记事：DELET /api/notes/{note_id}</li>
<li>更新某一个记事：PUT /api/notes/{note_id}</li>
</ul>


<p>可知：</p>

<ul>
<li>资源分为单个资源和资源集合，尽量使用复数来表示资源，单个资源通过添加ID等标识符来表示。</li>
<li>资源使用嵌套结构，类似于目录路径的方式，可以体现出之间的关系。</li>
<li>一个资源可以有不同的URL，如上可以获取所有的记事列表，也可以获取某人的所有记事列表。</li>
<li>对于GET方法，一定不能设计为可以改变资源的操作。如get /api/deleteNote?id=xx。</li>
<li>URL是对大小写敏感的，尽量使用小写字母，单词间用下划线连接。</li>
<li>使用Query参数来控制返回结果，如上面返回星标记事的接口。此外，像排序方向、排序使用的字段都是可以放在query参数中的。</li>
<li>分页参数使用Query参数（page、per_page）控制，在返回数据中返回当前页、下一页、上一页、总页数等分页相关信息。</li>
</ul>


<p>如果需要区分版本号，可以放在路径中，如/api/v2/**，也可以放在header的Accept字段或者Query参数中:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Accept: version=2.0;...</span></code></pre></td></tr></table></div></figure>


<p>对于一些很难设计为CRUD操作的URL, 如登录、送礼物等，有以下处理方式：</p>

<ul>
<li>使用POST，如POST /api/login。</li>
<li>把动作转换成资源: 登录就是创建了一个Session或者Token，那么就可以设计为 POST /api/sessions。</li>
</ul>


<p>此外，对于数据的提交格式和返回格式，目前以JSON格式为主，其可读性、紧凑性、多语言支持都较好；数据提交的方式也应该使用application/JSON的内容格式并在body里放置JSON数据。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>...
</span><span class='line'>Content-type: application/json
</span><span class='line'>Accept: application/json
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>{
</span><span class='line'>    'title':'xxx',
</span><span class='line'>    'content':'xxx'
</span><span class='line'>    ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>四. 安全性</h2>

<p>HTTP本身是对数据不做任何安全处理的，因此建议首先从根本上使用HTTPS加强数据的安全性。此外，这里的安全性还要保证数据的完整性；保证接口的授权访问，保证接口只提供给授权过的应用访问以及过滤掉不必要的请求；保证数据的授权访问，只允许资源拥有者删除、更新自己的资源。</p>

<h3>数据的完整性</h3>

<p>数据完整性主要是指在对数据进行修改时，要保证要修改的数据和服务器数据是一致的。可以通过Etag这个HTTP中的头部字段来解决。</p>

<p>Etag表示的是资源的唯一版本号, 请求资源时，RESTful api应该把资源数据以及资源的Etag一起返回。api请求方修改资源时应该提交If-Match头，这样服务器通过对比Etag可以防止数据被错误修改，类似于并发中CAS的原理。但是要绝对保证数据的完整性，还得需要配合严格的并发控制才能做到。</p>

<h3>接口访问控制</h3>

<p>接口访问控制可以保证接口的授权访问，拒绝不合法的请求。可以通过以下几种方式：</p>

<ul>
<li>在Request headers中添加特殊的标识符，如果不含有此header的请求直接拒绝。这可以做简单的接口访问控制。</li>
<li>过滤Requst query和body, 做白名单验证，即只允许出现哪些参数，如果有非法参数，可以抛弃或者直接拒绝请求。</li>
</ul>


<p>上面只是比较简单的接口访问控制策略，无法彻底拒绝未授权的请求。我们可以通过为每一个授权应用分配app_secret（私有的，不公开），访问时对请求进行签名验证的方式实现更为严格的接口访问控制，这种方法也叫做HMAC。请求签名生成的一个例子如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>app_sign = MD5(METHOD & PATH & timestamp & app_secret)</span></code></pre></td></tr></table></div></figure>


<p>其中，METHOD指的是此次请求的方法，PATH指的URL中的path部分，timestamp是请求时间戳，app_secret是分配请求方的私钥，此外还有一个分配给请求方的app_id。这样，app_id、timestamp、app_sign随着请求一起发送（可以作为query参数也可以作为header），服务器接收到请求后使用同样的算法计算出app_sign进行对比，如果相同则正常请求，否则返回401 Unauthorized。由此既可以保证接口的授权访问，还能够基于时间戳防止重放攻击。当然，app_sign的生成算法可以加入更多的因子，如request_body、query等。但需要注意的是这个算法越复杂，对接口的性能影响就越大，需要做权衡。</p>

<h3>数据的授权访问-OAuth</h3>

<p>数据的授权访问其实也是接口访问控制的一部分。主要关注点在于对资源的操作权限做控制。基于HTTP做授权访问的核心就是验证一个请求是否是合法用户发起的，主要的有HTTP Basic Auth、OAuth。其中Basic Auth会把用户的用户名和密码直接暴露在网络中并不安全，因此RESTful api主要使用OAuth做数据的授权访问控制。</p>

<p>OAuth2.0的验证流程如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/restful/oauth.png" alt="" /></p>

<ul>
<li>得到授权码code。</li>
<li>使用授权码换取access_token和refesh_token，通常refresh_token比access_token有效期长。</li>
<li>使用access_token获取用户openid。</li>
<li>使用access_token和用户openid调用用户授权接口。</li>
<li>使用refresh_token获取新的access_token。</li>
</ul>


<p>当然，如果是提供给内部应用的API，可以做适当简化，比如用户登录直接返回access_token，凭借此access_token调用授权接口即可。</p>

<h2>五. 限流</h2>

<p>RESTful api应该有限流机制，否则会造成API被滥用甚至被DDOS攻击。可以根据不同的授权访问做不同的限流，以减少服务器压力。</p>

<p>限流的情况可以通过下面几个头部字段返回给请求方：</p>

<ul>
<li>X-RateLimit-Limit: 用户每个小时允许发送请求的最大值。</li>
<li>X-RateLimit-Remaining：当前时间窗口剩下的可用请求数目。</li>
<li>X-RateLimit-Rest: 时间窗口重置的时候，到这个时间点可用的请求数量就会变成 X-RateLimit-Limit 的值。</li>
</ul>


<p>对于未登录的用户根据IP或者设备ID来限流，对于登录用户根据用户标识。对于超过流量的请求，返回403 forbiden或者429 Too many requests都可以。</p>

<h2>六. 超文本API</h2>

<p>RESTful还有一个非常关键的特性就是超文本API（Hypermedia API），指的是服务器需要在每一个API接口的返回结果中都要提供与下一步操作相关的资源链接, 客户端借助这些实现表现层状态转移。这种设计也被称为 HATEOAS（Hypermedia as the Engine of Application State）。</p>

<p>除此之外，这样做还能够让客户端和服务端解耦，客户端只需要依次遍历返回结果中的超链接就能完成一系列业务逻辑；当服务端做了业务逻辑改动后，也只需要修改服务器返回的资源链接即可。</p>

<h2>七. 编写文档</h2>

<p>RESTful API一般是对接第三方的，因此，文档说明是非常必要的。因此对每一个接口都详细的说明参数含义、数据返回格式和字段意义并举出实际的例子都是非常关键的。</p>

<p>Java Web开发中，我们可以使用Swagger UI + Spring Fox来基于注释生成RESTful API文档。</p>

<h2>八. RESTful API实现</h2>

<p>Spring MVC、Jersey、Play Framework等主流的Web开发框架都支持RESTful的接口编写。这里我们以Spring MVC为例。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@RequestMapping(value = "/api/notes/{noteId}", method = RequestMethod.GET, headers = "Accept=application/json")
</span><span class='line'>@ResponseBody
</span><span class='line'>public UserNote getUserNoteInfo(@PathVariable long noteId) {
</span><span class='line'>
</span><span class='line'>   return ...;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>此外，OAuth的实现可以使用Spring Security OAuth, 其基于Spring Secutiry实现了OAuth服务。不过，Spring Security OAuth使用稍显复杂，完全可按照OAuth2.0的流程使用Spring MVC + Redis进行实现。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何培养解决问题的意识]]></title>
    <link href="http://www.rowkey.me/blog/2019/08/23/solve-problem/"/>
    <updated>2019-08-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/08/23/solve-problem</id>
    <content type="html"><![CDATA[<p>解决问题其实并不是最终的目的，需要加一个修饰词成为有效地解决问题，这才是最终的目的。那么如何有效地解决问题呢？这是有一些方法论做指导的。要培养解决问题的能力，需要首先掌握这些方法论。解决问题分为三步走：识别问题、分析问题、解决问题。</p>

<!--more-->


<ul>
<li>所谓识别问题，这一点尤其重要，因为很多时候提需求的人提的只是方案而非真正的问题，这时候如果不加思索就开始去做，最后反而达不到需求方的期望，举一个可能很多人听过的段子，程序员的妻子跟程序员说：把这些土豆削一半儿放到锅里，程序员很快就做完了，结果妻子发现所有土豆都下了锅，不过每一个土豆都被削掉了一半。哈哈一笑的同时，很多人觉得这是沟通的问题，其实从另一个角度来看，还是因为没有识别出真正的问题是什么。平时的工作中，也会有很多人在遇到问题和接到需求时，为了赶时间，想都不想就开始做，结果最终的结果解决不了问题或者满足不了需求方，这都是因为没有真正的识别问题而造成的。脑子总是比手慢也说的是这个意思。在识别问题的时候则可以通过5W2H提问来理解真正的问题，What，问题时什么；Why，为什么会发生问题；Who，谁造成的问题；When，何时发生的问题； Where，哪里的问题；How，问题时怎样发生的；How much，问题发生的频率，影响程度如何。</li>
<li>分析问题，需要依靠专业能力或者经验来找到所有可能的原因，然后可以通过冰山分析法、鱼骨法来分析问题的根本原因，这一点也特别重要，很多时候如果识别不出根本原因，那么只会是治标不治本，当然对于一些紧急事故，解决事故是紧急首要的，后续的问题管理则需要找出问题的根本原因，以防止后续问题的重复发生。</li>
<li>解决问题，需要根据分析出来的问题原因，给出解决方案，这个也需要专业能力和经验的支撑，如果有多个方案则可以使用理性决策的比较矩阵和决策矩阵支撑最终的方案的选择。</li>
</ul>


<p>以上是解决问题的三步走。支撑这个方法论的除了上面提到过的专业能力和经验支撑，我觉得还需要具有owner意识，即把问题当做自己的问题，主动积极的去寻求能更好解决问题的方案。</p>

<p>掌握了这些方法论后，则需要不断的模仿学习、实践，并且最重要的是多总结，要把平时工作中自己实践的、看到别人实践的不断的总结梳理，形成自己的知识体系，这样才能真正成为自己的技能，才能在遇到问题时做到有条不紊，从容应对，同时也能进一步完善自己解决问题的方法论、专业能力和经验，形成良性闭环。例如在很多公司都会有故障解决的一套指导流程，比如在碰到服务器响应变慢时，先通知受影响方，然后组织相关人员，如果有经验则第一时间修复，无经验则需要从最近的变动着手，先排查哪几方面问题，再排查哪几方面问题，这个流程即在实践过程中不断沉淀下来的知识体系。</p>

<p>总结来说，就是掌握解决问题的方法论，带着Owner意识多去实践解决问题，多去模范学习别人如何解决问题，多去总结沉淀成自己的知识体系和方法论形成闭环。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Spring Boot快速开发]]></title>
    <link href="http://www.rowkey.me/blog/2019/07/27/springboot/"/>
    <updated>2019-07-27T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/07/27/springboot</id>
    <content type="html"><![CDATA[<p>Java开发中常用的Spring现在变得越来越复杂，越来越不好上手。这一点Spring Source自己也注意到了，因此推出了Spring Boot，旨在简化使用Spring的门槛，大大降低Spring的配置工作，并且能够很容易地将应用打包为可独立运行的程序（即不依赖于第三方容器，可以独立以jar或者war包的形式运行）。其带来的开发效率的提升使得Spring Boot被看做至少近5年来Spring乃至整个Java社区最有影响力的项目之一，也被人看作是Java EE开发的颠覆者。另一方面来说，Spring Boot也顺应了现在微服务（MicroServices）的理念，可以用来构建基于Spring框架的可独立部署应用程序。</p>

<!--more-->


<h2>一. 使用</h2>

<p>一个简单的pom配置示例如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;parent&gt;        
</span><span class='line'>   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        
</span><span class='line'>   &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        
</span><span class='line'>   &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;
</span><span class='line'>&lt;/parent&gt;
</span><span class='line'>    
</span><span class='line'>...
</span><span class='line'>    
</span><span class='line'>&lt;dependencies&gt;        
</span><span class='line'>   &lt;dependency&gt;                
</span><span class='line'>       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                
</span><span class='line'>       &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        
</span><span class='line'>   &lt;/dependency&gt;
</span><span class='line'>&lt;/dependencies&gt;
</span><span class='line'>
</span><span class='line'>&lt;build&gt;
</span><span class='line'>    &lt;plugins&gt;
</span><span class='line'>       &lt;plugin&gt;
</span><span class='line'>           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
</span><span class='line'>           &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
</span><span class='line'>           &lt;configuration&gt;
</span><span class='line'>               &lt;executable&gt;true&lt;/executable&gt;
</span><span class='line'>            &lt;/configuration&gt;
</span><span class='line'>       &lt;/plugin&gt;
</span><span class='line'>    &lt;/plugins&gt;
</span><span class='line'>&lt;/build&gt;</span></code></pre></td></tr></table></div></figure>


<p>使用spring-boot-starter-parent作为当前项目的parent将Spring Boot应用相关的一系列依赖（dependency）、插件（plugins）等等配置共享；添加spring-boot-starter-web这个依赖，是为了构建一个独立运行的Web应用；spring-boot-maven-plugin用于将Spring Boot应用以可执行jar包的形式发布出去。</p>

<p>接着可以添加相应的Controller实现：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@RestController  
</span><span class='line'>public class MyController {
</span><span class='line'>@RequestMapping("/")
</span><span class='line'>   public String hello() {
</span><span class='line'>      return "Hello World!";
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>这里的RestController是一个复合注解，包括@Controller和@ResponseBody。</p>

<p>最后，要让Spring Boot可以独立运行和部署，我们需要一个Main方法入口， 比如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@SpringBootApplication
</span><span class='line'>public class BootDemo extends SpringBootServletInitializer{    
</span><span class='line'>   public static void main(String[] args) throws Exception {        
</span><span class='line'>       SpringApplication.run(BootDemo.class, args);    
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>使用mvn package打包后（可以是jar，也可以是war），java -jar xx.war/jar即可运行一个Web项目，而之所以继承SpringBootServletInitializer是为了能够让打出来的war包也可以放入容器中直接运行，其加载原理在3.4.4节的零XML配置中讲过。</p>

<p>这里需要注意上面spring-boot-maven-plugin这个插件将executable配置为了true，此种配置打出来的jar/war包其压缩格式并非传统的jar/war包，实际上是一个bash文件，可以作为shell脚本直接执行，解压的话需要使用unzip命令。</p>

<p>从最根本上来讲，Spring Boot就是一些库和插件的集合，屏蔽掉了很多配置加载、打包等自动化工作，其底层还是基于Spring的各个组件。</p>

<p>这里需要注意的是，Spring Boot推崇对项目进行零xml配置。但是就笔者看来，相比起注解配置是糅杂在代码中，每次更新都需要重新编译，XML这种和代码分离的方式耦合性和可维护性则显得更为合理一些，而且在配置复杂时也更清晰。因此，采用Java Config作为应用和组件扫描（component scan）入口，采用XML做其他的配置是一种比较好的方式。此外，当集成外部已有系统的时候， 通过XML集中明确化配置也是更为合理的一种方式。</p>

<h2>二. 原理浅析</h2>

<p><img src="http://www.rowkey.me/post_images/spring-boot-process.png" alt="" /></p>

<p>Spring Boot的基础组件之一就是4.1讲过的一些注解配置，除此之外，它也提供了自己的注释。其总体的运行流程如上图所示。</p>

<ol>
<li><p>@EnableAutoConfiguration</p>

<p> 这个Annotation就是Java Config的典型代表，标注了这个Annotation的Java类会以Java代码的形式（对应于XML定义的形式）提供一系列的Bean定义和实例，结合AnnotationConfigApplicationContext和自动扫描的功能，就可以构建一个基于Spring容器的Java应用了。</p>

<p> @EnableAutoConfiguration的定义信息如下 ：</p>

<pre><code class="`"> @Target(ElementType.TYPE)
 @Retention(RetentionPolicy.RUNTIME)
 @Documented
 @Inherited
 @AutoConfigurationPackage
 @Import(EnableAutoConfigurationImportSelector.class)
 public @interface EnableAutoConfiguration {
</code></pre>

<p> 标注了此注解的类会发生一系列初始化动作：</p>

<ul>
<li><p>SpringBoot扫描到@EnableAutoConfiguration注解时，就使用Spring框架的SpringFactoriesLoader去扫描classpath下所有META-INF/spring.factories文件的配置信息（META-INF/spring.providers声明了当前Starter依赖的Jar包）。其中包括一些callback接口（在前中后等不同时机执行）：</p>

<ul>
<li>org.springframework.boot.SpringApplicationRunListener</li>
<li>org.springframework.context.ApplicationContextInitializer</li>
<li>org.springframework.context.ApplicationListener</li>
</ul>
</li>
<li><p>然后Spring Boot加载符合当前场景需要的配置类型并供当前或者下一步的流程使用，这里说的场景就是提取以 org.springframework.boot.autoconfigure.EnableAutoConfiguration作为key标志的一系列Java配置类，然后将这些Java配置类中的Bean定义加载到Spring容器中。</p></li>
</ul>


<p> 此外，我们可以使用Spring3系列引入的@Conditional，通过像@ConditionalOnClass、@ConditionalOnMissingBean等具体的类型和条件来进一步筛选通过SpringFactoriesLoader加载的类。</p></li>
<li><p>Spring Boot启动</p>

<p> 每一个Spring Boot应用都有一个入口类，在其中定义main方法，然后使用SpringApplication这个类来加载指定配置并运行SpringBoot Application。如上面写过的入口类：</p>

<pre><code class="`   "> @SpringBootApplication
 public class BootDemo extends SpringBootServletInitializer{    
    public static void main(String[] args) throws Exception {        
        SpringApplication.run(BootDemo.class, args);    
    }
 }
</code></pre>

<p> @SpringBootApplication注解是一个复合注解，包括了@Configuraiton、@EnableAutoConfiguration以及@ComponentScan。通过SpringApplication的run方法，Spring就使用BootDemo作为Java配置类来读取相关配置、加载和扫描相关的bean。</p>

<p> 这样，基于@SpringBootApplication注解，Spring容器会自动完成指定语义的一系列工作，包括@EnableAutoConfiguration要求的东西，如：从SpringBoot提供的多个starter模块中加载Java Config配置（META-INF/spring.factories中声明的xxAutoConfiguration），然后将这些Java Config配置筛选上来的Bean定义加入Spring容器中，再refresh容器。一个Spring Boot应用即启动完成。</p></li>
</ol>


<h2>三. 模块组成</h2>

<p>Spring Boot是由非常多的模块组成的，可以通过pom文件引入进来。EnableAutoConfiguration机制会进行插件化加载进行自动配置，这里模块化机制的原理主要是通过判断相应的类/文件是否存在来实现的。其中几个主要的模块如下:</p>

<ol>
<li><p>spring-boot-starter-web</p>

<p> 此模块就是标记此项目是一个Web应用，Spring Boot会自动准备好相关的依赖和配置。</p>

<p> 这里Spring Boot默认使用Tomcat作为嵌入式Web容器，可以通过声明spring-boot-starter-jetty的dependency来换成Jetty。</p></li>
<li><p>spring-boot-starter-logging</p>

<p> Spring Boot对此项目开启SLF4J和Logback日志支持。</p></li>
<li><p>spring-boot-starter-redis</p>

<p>  Spring Boot对此项目开启Redis相关依赖和配置来做数据存储。</p></li>
<li><p>spring-boot-starter-jdbc</p>

<p>  Spring Boot对此项目开启JDBC操作相关依赖和配置来做数据存储。</p>

<p>  这里需要说明的是，Spring Boot提供的功能非常丰富，因此显得非常笨重复杂。其实依赖于模块插件化机制，我们可以只配置自己需要使用的功能，从而对应用进行瘦身，避免无用的配置影响应用启动速度。</p></li>
</ol>


<h2>四. 总结</h2>

<p>Spring Boot给大家使用Spring做后端应用开发带来了非常大的便利，能够大大提高搭建应用雏形框架的速度，只需要关注实现业务逻辑即可。其“黑魔法”一样的插件化机制使得能够根据自己的需要引入所需的组件，提供了非常好的灵活性。如果非遗留Spring项目，直接使用Spring Boot是比较好的选择；遗留项目也可以通过配置达到无缝结合。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java开发框架之日志]]></title>
    <link href="http://www.rowkey.me/blog/2019/06/29/log/"/>
    <updated>2019-06-29T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/06/29/log</id>
    <content type="html"><![CDATA[<p>日志在应用开发中是一个非常关键的部分。有经验的工程师能够凭借以往的经验判断出哪里该打印日志、该以何种级别打印日志。这样就能够在线上发生问题的时候快速定位并解决问题，极大的减少应用的运维成本。</p>

<!--more-->


<p>使用控制台输出其实也算日志的一种，在容器中会打印到容器的日志文件中。但是，控制台输出过于简单，缺乏日志中级别控制、异步、缓冲等特性，因此在开发中要杜绝使用控制台输出作为日志（System.out.println）。而Java中已经有很多成熟的日志框架供大家使用：</p>

<ul>
<li>JDK Logging</li>
<li>Apache Log4j</li>
<li>Apache Log4j2</li>
<li>Logback</li>
</ul>


<p>此外，还有两个用于实现日志统一的框架：Apache Commons-Logging、SLF4j。与上述框架的不同之处在于，其只是一个门面，并没有日志框架的具体实现,可以认为是日志接口框架。</p>

<p>对于这些日志框架来说，一般会解决日志中的以下问题：</p>

<ul>
<li>日志的级别: 定义日志级别来区分不同级别日志的输出路径、形式等，帮助我们适应从开发调试到部署上线等不同阶段对日志输出粒度的不同需求。</li>
<li>日志的输出目的地：包括控制台、文件、GUI组件，甚至是套接口服务器、UNIX Syslog守护进程等。</li>
<li>日志的输出格式：日志的输出格式（JSON、XML）。</li>
<li>日志的输出优化：缓存、异步等。</li>
</ul>


<p>这里需要说的是，目前有几个框架提供了占位符的日志输出方式，然而其最终是用indexOf去循环查找再对信息进行拼接的，会消耗CPU。建议使用正确估算大小的StringBuilder拼装输出信息，除非是实在无法确定日志是否输出才用占位符。</p>

<h2>一. JDK Logging</h2>

<p>JDK Logging就是JDK自带的日志操作类，在java.util.logging包下面，通常被简称为JUL。</p>

<h3>配置</h3>

<p>JDK Logging配置文件默认位于$JAVA_HOME/jre/lib/logging.properties中，可以使用系统属性java.util.logging.config.file指定相应的配置文件对默认的配置文件进行覆盖。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>handlers= java.util.logging.FileHandler,java.util.logging.ConsoleHandler
</span><span class='line'>.handlers = java.util.logging.FileHandler,java.util.logging.ConsoleHandler #rootLogger使用的Handler
</span><span class='line'>.level= INFO #rootLogger的日志级别
</span><span class='line'>
</span><span class='line'>##以下是FileHandler的配置
</span><span class='line'>java.util.logging.FileHandler.pattern = %h/java%u.log
</span><span class='line'>java.util.logging.FileHandler.limit = 50000
</span><span class='line'>java.util.logging.FileHandler.count = 1
</span><span class='line'>java.util.logging.FileHandler.formatter =java.util.logging.XMLFormatter #配置相应的日志Formatter。
</span><span class='line'>
</span><span class='line'>##以下是ConsoleHandler的配置
</span><span class='line'>java.util.logging.ConsoleHandler.level = INFO
</span><span class='line'>java.util.logging.ConsoleHandler.formatter =java.util.logging.SimpleFormatter #配置相应的日志Formatter。
</span><span class='line'>
</span><span class='line'>#针对具体的某个logger的日志级别配置
</span><span class='line'>me.rowkey.pje.log.level = SEVERE
</span><span class='line'>
</span><span class='line'>#设置此logger不会继承成上一级logger的配置
</span><span class='line'>me.rokey.pje.log.logger.useParentHandlers = false </span></code></pre></td></tr></table></div></figure>


<p>这里需要说明的是logger默认是继承的，如me.rowkey.pje.log的logger会继承me.rowkey.pje的logger配置，可以对logger配置handler和useParentHandlers（默认是为true）属性, 其中useParentHandler表示是否继承父logger的配置。</p>

<p>JDK Logging的日志级别比较多，从高到低为：OFF(2<sup>31</sup>-1)—>SEVERE(1000)—>WARNING(900)—>INFO(800)—>CONFIG(700)—>FINE(500)—>FINER(400)—>FINEST(300)—>ALL(-2<sup>31</sup>)。</p>

<h3>使用</h3>

<p>JDK Logging的使用非常简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public class LoggerTest{
</span><span class='line'>
</span><span class='line'>    private static final Logger LOGGER = Logger.getLogger(xx.class.getName());
</span><span class='line'>    
</span><span class='line'>    public static void main(String[] args){
</span><span class='line'>        LOGGER.info("logger info");
</span><span class='line'>    }
</span><span class='line'>}
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h3>性能优化</h3>

<p>JDK Logging是一个比较简单的日志框架，并没有提供异步、缓冲等优化手段。也不建议大家使用此框架。</p>

<h2>二. Log4j</h2>

<p>Log4j应该是目前Java开发中用的最为广泛的日志框架。</p>

<h3>配置</h3>

<p>Log4j支持XML、Proerties配置，通常还是使用Properties：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root_log_dir=${catalina.base}/logs/app/
</span><span class='line'>
</span><span class='line'># 设置rootLogger的日志级别以及appender
</span><span class='line'>log4j.rootLogger=INFO,default
</span><span class='line'>
</span><span class='line'># 设置Spring Web的日志级别
</span><span class='line'>log4j.logger.org.springframework.web = ERROR
</span><span class='line'>
</span><span class='line'># 设置default appender为控制台输出
</span><span class='line'>log4j.appender.default=org.apache.log4j.ConsoleAppender
</span><span class='line'>log4j.appender.default.layout=org.apache.log4j.PatternLayout
</span><span class='line'>log4j.appender.default.layout.ConversionPattern=[%-d{HH\:mm\:ss} %-3r %-5p %l] &gt;&gt; %m (%t)%n
</span><span class='line'>
</span><span class='line'># 设置新的logger，在程序中使用Logger.get("myLogger")即可使用
</span><span class='line'>log4j.logger.myLogger=INFO,A2
</span><span class='line'>
</span><span class='line'># 设置另一个appender为按照日期轮转的文件输出
</span><span class='line'>log4j.appender.A2=org.apache.log4j.DailyRollingFileAppender
</span><span class='line'>log4j.appender.A2.File=${root_log_dir}log.txt
</span><span class='line'>log4j.appender.A2.Append=true
</span><span class='line'>log4j.appender.A2.DatePattern= yyyyMMdd'.txt'
</span><span class='line'>log4j.appender.A2.layout=org.apache.log4j.PatternLayout
</span><span class='line'>log4j.appender.A2.layout.ConversionPattern=[%-d{HH\:mm\:ss} %-3r %-5p %l] &gt;&gt; %m (%t)%n
</span><span class='line'>
</span><span class='line'>log4j.logger.myLogger1 = INFO,A3
</span><span class='line'>
</span><span class='line'># 设置另一个appender为RollingFileAppender，能够限制日志文件个数
</span><span class='line'>log4j.appender.A3 = org.apache.log4j.RollingFileAppender
</span><span class='line'>log4j.appender.A3.Append = true
</span><span class='line'>log4j.appender.A3.BufferedIO = false
</span><span class='line'>log4j.appender.dA3.File = /home/popo/tomcat-yixin-pa/logs/pa.log
</span><span class='line'>log4j.appender.A3.Encoding = UTF-8
</span><span class='line'>log4j.appender.A3.layout = org.apache.log4j.PatternLayout
</span><span class='line'>log4j.appender.A3.layout.ConversionPattern = [%-5p]%d{ISO8601}, [Class]%-c{1}, %m%n
</span><span class='line'>log4j.appender.A3.MaxBackupIndex = 3 #最大文件个数
</span><span class='line'>log4j.appender.A3.MaxFileSize = 1024MB</span></code></pre></td></tr></table></div></figure>


<p>如果Log4j文件不直接在classpath下的话，可以使用PropertyConfigurator来进行配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PropertyConfigurator.configure("...");
</span></code></pre></td></tr></table></div></figure>


<p>Log4j的日志级别相对于JDK Logging来说，简化了一些：DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL。</p>

<p>这里的logger默认是会继承父Logger的配置（rootLogger是所有logger的父logger），如上面myLogger的输出会同时在控制台和文件中出现。如果不想这样，那么只需要如下设置:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>log4j.additivity.myLogger=false</span></code></pre></td></tr></table></div></figure>


<h3>使用</h3>

<p>程序中对于Log4j的使用也非常简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import org.apache.log4j.Logger;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>private static final Logger LOGGER = Logger.getLogger(xx.class.getName());
</span><span class='line'>...
</span><span class='line'>LOGGER.info("logger info");
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>这里需要注意的是，虽然Log4j可以根据配置文件中日志级别的不同做不同的输出，但由于字符串创建或者拼接也是耗资源的，因此，下面的用法是不合理的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LOGGER.debug("...");</span></code></pre></td></tr></table></div></figure>


<p>合理的做法应该是首先判断当前的日志级别是什么，再去做相应的输出，如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if(LOGGER.isDebugEnabled()){
</span><span class='line'>    LOGGER.debug("...");
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>当然，如果是必须输出的日志可以不做此判断，比如catch异常打印错误日志的地方。</p>

<h3>性能优化</h3>

<p>Log4j为了应对某一时间里大量的日志信息进入Appender的问题提供了缓冲来进一步优化性能：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>log4j.appender.A3.BufferedIO=true   
</span><span class='line'>#Buffer单位为字节，默认是8K，IO BLOCK大小默认也是8K 
</span><span class='line'>log4j.appender.A3.BufferSize=8192 </span></code></pre></td></tr></table></div></figure>


<p>以上表示当日志内容达到8k时，才会将日志输出到日志输出目的地。</p>

<p>除了缓冲以外，Log4j还提供了AsyncAppender来做异步日志。但是AsyncAppender只能够通过xml配置使用：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;appender name="A2"
</span><span class='line'>   class="org.apache.log4j.DailyRollingFileAppender"&gt;
</span><span class='line'>   &lt;layout class="org.apache.log4j.PatternLayout"&gt;
</span><span class='line'>       &lt;param name="ConversionPattern" value="%m%n" /&gt;
</span><span class='line'>   &lt;/layout&gt;
</span><span class='line'>   &lt;param name="DatePattern" value="'.'yyyy-MM-dd-HH" /&gt;        
</span><span class='line'>   &lt;param name="File" value="app.log" /&gt;
</span><span class='line'>   &lt;param name="BufferedIO" value="true" /&gt;
</span><span class='line'>   &lt;!-- 8K为一个写单元 --&gt;
</span><span class='line'>   &lt;param name="BufferSize" value="8192" /&gt;
</span><span class='line'>&lt;/appender&gt;
</span><span class='line'>
</span><span class='line'>&lt;appender name="async" class="org.apache.log4j.AsyncAppender"&gt;
</span><span class='line'>   &lt;appender-ref ref="A2"/&gt;
</span><span class='line'>&lt;/appender&gt;</span></code></pre></td></tr></table></div></figure>


<h2>三. Log4j2</h2>

<p>2015年8月，官方正式宣布Log4j 1.x系列生命终结，推荐大家升级到Log4j2，并号称在修正了Logback固有的架构问题的同时，改进了许多Logback所具有的功能。Log4j2与Log4j1发生了很大的变化，并不兼容。并且Log4j2不仅仅提供了日志的实现，也提供了门面，目的是统一日志框架。其主要包含两部分：</p>

<ul>
<li>log4j-api： 作为日志接口层，用于统一底层日志系统</li>
<li>log4j-core : 作为上述日志接口的实现，是一个实际的日志框架</li>
</ul>


<h3>配置</h3>

<p>Log4j2的配置方式只支持XML、JSON以及YAML，不再支持Properties文件,其配置文件的加载顺序如下：</p>

<ul>
<li>log4j2-test.json/log4j2-test.jsn</li>
<li>log4j2-test.xml</li>
<li>log4j2.json/log4j2.jsn文件</li>
<li>log4j2.xml</li>
</ul>


<p>如果想要自定义配置文件位置，需要设置系统属性log4j.configurationFile。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>System.setProperty("log4j.configurationFile", "...");
</span><span class='line'>或者
</span><span class='line'>-Dlog4j.configurationFile="xx"</span></code></pre></td></tr></table></div></figure>


<p>配置文件示例：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;!--log4j2.xml--&gt;
</span><span class='line'>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
</span><span class='line'>&lt;Configuration status="WARN" monitorInterval="30"&gt;
</span><span class='line'>&lt;Appenders&gt;
</span><span class='line'>  &lt;Console name="Console" target="SYSTEM_OUT"&gt;
</span><span class='line'>    &lt;PatternLayout pattern="%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n"/&gt;
</span><span class='line'>  &lt;/Console&gt;
</span><span class='line'>  &lt;File name="File" fileName="app.log" bufferedIO="true" immediateFlush="true"&gt;
</span><span class='line'>    &lt;PatternLayout&gt;
</span><span class='line'>      &lt;pattern&gt;%d %p %C{1.} [%t] %m%n&lt;/pattern&gt;
</span><span class='line'>    &lt;/PatternLayout&gt;
</span><span class='line'>  &lt;/File&gt;
</span><span class='line'>  &lt;RollingFile name="RollingFile" fileName="logs/app.log"
</span><span class='line'>                     filePattern="log/$${date:yyyy-MM}/app-%d{MM-dd-yyyy}-%i.log.gz"&gt;
</span><span class='line'>      &lt;PatternLayout pattern="%d{yyyy-MM-dd 'at' HH:mm:ss z} %-5level %class{36} %L %M - %msg%xEx%n"/&gt;
</span><span class='line'>      &lt;SizeBasedTriggeringPolicy size="50MB"/&gt;
</span><span class='line'>      &lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件，这里设置了20 --&gt;
</span><span class='line'>      &lt;DefaultRolloverStrategy max="20"/&gt;
</span><span class='line'>  &lt;/RollingFile&gt;
</span><span class='line'>&lt;/Appenders&gt;
</span><span class='line'>&lt;Loggers&gt;
</span><span class='line'>  &lt;logger name="myLogger" level="error" additivity="false"&gt;
</span><span class='line'>    &lt;AppenderRef ref="File" /&gt;
</span><span class='line'>  &lt;/logger&gt;
</span><span class='line'>  &lt;Root level="debug"&gt;
</span><span class='line'>    &lt;AppenderRef ref="Console"/&gt;
</span><span class='line'>  &lt;/Root&gt;
</span><span class='line'>&lt;/Loggers&gt;
</span><span class='line'>&lt;/Configuration&gt;</span></code></pre></td></tr></table></div></figure>


<p>上面的monitorInterval使得配置变动能够被实时监测并更新，且能够在配置发生改变时不会丢失任何日志事件;additivity和Log4j一样也是为了让Looger不继承父Logger的配置；Configuration中的status用于设置Log4j2自身内部的信息输出，当设置成trace时，你会看到Log4j2内部各种详细输出。</p>

<p>Log4j2在日志级别方面也有了一些改动：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL, 并且能够很简单的自定义自己的日志级别。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;CustomLevels&gt;
</span><span class='line'>    &lt;CustomLevel name="NOTICE" intLevel="450" /&gt;
</span><span class='line'>    &lt;CustomLevel name="VERBOSE" intLevel="550" /&gt;
</span><span class='line'>&lt;/CustomLevels&gt;</span></code></pre></td></tr></table></div></figure>


<p>上面的intLevel值是为了与默认提供的标准级别进行对照的。</p>

<h3>使用</h3>

<p>使用方式也很简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>private static final Logger LOGGER = LogManager.getLogger(xx.class);
</span><span class='line'>
</span><span class='line'>LOGGER.debug("log4j debug message");</span></code></pre></td></tr></table></div></figure>


<p>这里需要注意的是其中的Logger是log4j-api中定义的接口，而Log4j1中的Logger则是类。</p>

<p>相比起之前我们需要先判断日志级别，再输出日志，Log4j2提供了占位符功能：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LOGGER.debug("error: {} ", e.getMessage());</span></code></pre></td></tr></table></div></figure>


<h3>性能优化</h3>

<p>在性能方面，Log4j2引入了基于LMAX的Disruptor的无锁异步日志实现进一步提升异步日志的性能：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;AsyncLogger name="asyncTestLogger" level="trace" includeLocation="true"&gt;
</span><span class='line'>    &lt;AppenderRef ref="Console"/&gt;
</span><span class='line'>&lt;/AsyncLogger&gt;</span></code></pre></td></tr></table></div></figure>


<p>需要注意的是，由于默认日志位置信息并没有被传给异步Logger的I/O线程，因此这里的includeLocation必须要设置为true。</p>

<p>和Log4j一样，Log4j2也提供了缓冲配置来优化日志输出性能。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;Appenders&gt;
</span><span class='line'>  &lt;File name="File" fileName="app.log" bufferedIO="true" immediateFlush="true"&gt;
</span><span class='line'>    &lt;PatternLayout&gt;
</span><span class='line'>      &lt;pattern&gt;%d %p %C{1.} [%t] %m%n&lt;/pattern&gt;
</span><span class='line'>    &lt;/PatternLayout&gt;
</span><span class='line'>  &lt;/File&gt;
</span><span class='line'>&lt;/Appenders&gt;</span></code></pre></td></tr></table></div></figure>


<h2>四. Logback</h2>

<p>Logback是由Log4j创始人设计的又一个开源日志组件，相对Log4j而言，在各个方面都有了很大改进。</p>

<p>Logback当前分成三个模块：</p>

<ul>
<li>logback-core是其它两个模块的基础模块。</li>
<li>logback-classic是Log4j的一个改良版本。logback-classic完整实现SLF4J API使你可以很方便地更换成其它日志系统如Log4j或JDK Logging。</li>
<li>logback-access访问模块与Servlet容器集成提供通过HTTP来访问日志的功能。</li>
</ul>


<h3>配置</h3>

<p>Logback的配置文件如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;!--logback.xml--&gt;
</span><span class='line'>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>    &lt;property name="root_log_dir" value="${catalina.base}/logs/app/"/&gt;
</span><span class='line'>
</span><span class='line'>    &lt;appender name="ROLLING_FILE_APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
</span><span class='line'>       &lt;File&gt;${root_log_dir}app.log&lt;/File&gt;
</span><span class='line'>       &lt;Append&gt;true&lt;/Append&gt;
</span><span class='line'>       &lt;encoder&gt;
</span><span class='line'>           &lt;pattern&gt;%date [%level] [%thread] %logger{80} [%file : %line] %msg%n&lt;/pattern&gt;
</span><span class='line'>       &lt;/encoder&gt;
</span><span class='line'>       &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;
</span><span class='line'>           &lt;fileNamePattern&gt;${root_log_dir}app.log.%d{yyyy-MM-dd}.%i&lt;/fileNamePattern&gt;
</span><span class='line'>           &lt;maxHistory&gt;30&lt;/maxHistory&gt; #只保留最近30天的日志文件
</span><span class='line'>           &lt;TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt;#每天的日志按照100MB分割
</span><span class='line'>                &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt;
</span><span class='line'>            &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt;
</span><span class='line'>            &lt;totalSizeCap&gt;20GB&lt;/totalSizeCap&gt;#日志总的大小上限，超过此值则异步删除旧的日志
</span><span class='line'>       &lt;/rollingPolicy&gt;
</span><span class='line'>    &lt;/appender&gt;
</span><span class='line'>    
</span><span class='line'>    &lt;appender name="ROLLING_FILE_APPENDER_2" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
</span><span class='line'>       &lt;File&gt;${root_log_dir}mylog.log&lt;/File&gt;
</span><span class='line'>       &lt;Append&gt;true&lt;/Append&gt;
</span><span class='line'>       &lt;encoder&gt;
</span><span class='line'>           &lt;pattern&gt;%date [%level] [%thread] %logger{80} [%file : %line] %msg%n&lt;/pattern&gt;
</span><span class='line'>       &lt;/encoder&gt;
</span><span class='line'>       #下面的日志rolling策略和ROLLING_FILE_APPENDER的等价，保留最近30天的日志，每天的日志按照100MB分隔，日志总的大小上限为20GB
</span><span class='line'>       &lt;rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"&gt;
</span><span class='line'>            &lt;fileNamePattern&gt;mylog.log-%d{yyyy-MM-dd}.%i&lt;/fileNamePattern&gt;
</span><span class='line'>            &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt;
</span><span class='line'>            &lt;maxHistory&gt;30&lt;/maxHistory&gt;
</span><span class='line'>            &lt;totalSizeCap&gt;20GB&lt;/totalSizeCap&gt;
</span><span class='line'>        &lt;/rollingPolicy&gt;
</span><span class='line'>    &lt;/appender&gt;
</span><span class='line'>    
</span><span class='line'>     &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt;
</span><span class='line'>       &lt;encoder&gt;
</span><span class='line'>         &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;
</span><span class='line'>       &lt;/encoder&gt;
</span><span class='line'>     &lt;/appender&gt;
</span><span class='line'>        
</span><span class='line'>    &lt;logger name="myLogger" level="INFO" additivity="false"&gt;
</span><span class='line'>        &lt;appender-ref ref="ROLLING_FILE_APPENDER" /&gt;
</span><span class='line'>    &lt;/logger&gt;
</span><span class='line'>        
</span><span class='line'>     &lt;root level="DEBUG"&gt;          
</span><span class='line'>       &lt;appender-ref ref="STDOUT" /&gt;
</span><span class='line'>     &lt;/root&gt;  
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;</span></code></pre></td></tr></table></div></figure>


<p>Logback的配置文件读取顺序（默认都是读取classpath下的）：logback.groovy -> logback-test.xml -> logback.xml。如果想要自定义配置文件路径，那么只有通过修改logback.configurationFile的系统属性。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>System.setProperty("logback.configurationFile", "...");
</span><span class='line'>或者
</span><span class='line'>-Dlogback.configurationFile="xx"</span></code></pre></td></tr></table></div></figure>


<p>Logback的日志级别：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR。如果logger没有被分配级别，那么它将从有被分配级别的最近的祖先那里继承级别。root logger 默认级别是 DEBUG。</p>

<p>Logback中的logger同样也是有继承机制的。配置文件中的additivit也是为了不去继承rootLogger的配置，从而避免输出多份日志。</p>

<p>为了方便Log4j到Logback的迁移，官网提供了log4j.properties到logback.xml的转换工具：<a href="https://logback.qos.ch/translator/">https://logback.qos.ch/translator/</a>。</p>

<h3>使用</h3>

<p>Logback由于是天然与SLF4J集成的，因此它的使用也就是SLF4J的使用。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import org.slf4j.LoggerFactory;
</span><span class='line'>
</span><span class='line'>private static final Logger LOGGER=LoggerFactory.getLogger(xx.class);
</span><span class='line'>
</span><span class='line'>LOGGER.info(" this is a test in {}", xx.class.getName())</span></code></pre></td></tr></table></div></figure>


<p>SLF4J同样支持占位符。</p>

<p>此外，如果想要打印json格式的日志（例如，对接日志到Logstash中），那么可以使用logstash-logback-encoder做为RollingFileAppender的encoder。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;encoder class="net.logstash.logback.encoder.LogstashEncoder" &gt;
</span><span class='line'>...
</span><span class='line'>&lt;/encoder&gt;</span></code></pre></td></tr></table></div></figure>


<h3>性能优化</h3>

<p>Logback提供了AsyncAppender进行异步日志输出，此异步appender实现上利用了队列做缓冲，使得日志输出性能得到提高。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;appender name="FILE_APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
</span><span class='line'>      &lt;File&gt;${root_log_dir}app.log&lt;/File&gt;
</span><span class='line'>      &lt;Append&gt;true&lt;/Append&gt;
</span><span class='line'>      &lt;encoder&gt;
</span><span class='line'>          &lt;pattern&gt;%date [%level] [%thread] %logger{80} [%file : %line] %msg%n&lt;/pattern&gt;
</span><span class='line'>      &lt;/encoder&gt;
</span><span class='line'>      &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;
</span><span class='line'>          &lt;fileNamePattern&gt;${root_log_dir}app.log.%d&lt;/fileNamePattern&gt;
</span><span class='line'>      &lt;/rollingPolicy&gt;
</span><span class='line'>&lt;/appender&gt;
</span><span class='line'>&lt;appender name ="ASYNC" class= "ch.qos.logback.classic.AsyncAppender"&gt;  
</span><span class='line'>       &lt;discardingThreshold &gt;0&lt;/discardingThreshold&gt;  
</span><span class='line'>       
</span><span class='line'>       &lt;queueSize&gt;512&lt;/queueSize&gt;  
</span><span class='line'>       
</span><span class='line'>       &lt;appender-ref ref ="FILE_APPENDER"/&gt;  
</span><span class='line'>&lt;/appender&gt;  
</span><span class='line'>       </span></code></pre></td></tr></table></div></figure>


<p>这里需要特别注意以下两个参数的配置：</p>

<ul>
<li>queueSize：队列的长度,该值会影响性能，需要合理配置。</li>
<li>discardingThreshold：日志丢弃的阈值，即达到队列长度的多少会丢弃TRACT、DEBUG、INFO级别的日志，默认是80%，设置为0表示不丢弃日志。</li>
</ul>


<p>此外，由于是异步输出，为了保证日志一定会被输出以及后台线程能够被及时关闭，在应用退出时需要显示关闭logback。有两种方式：</p>

<ul>
<li><p>在程序退出的地方（ServletContextListener的contextDestroyed方法、Spring Bean的destroy方法）显式调用下面的代码。</p>

<pre><code class="``">  LoggerContext loggerContext = (LoggerContext) LoggerFactory.getILoggerFactory();
  loggerContext.stop();
</code></pre></li>
<li><p>在logback配置文件里，做如下配置。</p>

<pre><code class="``">  &lt;configuration&gt;

      &lt;shutdownHook class="ch.qos.logback.core.hook.DelayingShutdownHook"/&gt;
      .... 
  &lt;/configuration&gt;
</code></pre></li>
</ul>


<h2>五. 日志门面</h2>

<p>前面的四个框架是实际的日志框架。对于开发者而言，每种日志都有不同的写法。如果我们以实际的日志框架来进行编写，代码就限制死了，之后就很难再更换日志系统，很难做到无缝切换。</p>

<p>Java开发中经常提到面向接口编程，所以我们应该是按照一套统一的API来进行日志编程，实际的日志框架来实现这套API，这样的话，即使更换日志框架，也可以做到无缝切换。</p>

<p>这就是Commons-Logging与SLF4J这种日志门面框架的初衷。</p>

<h3>Apache Commons-Logging</h3>

<p>Apache Commons-Logging经常被简称为JCL，是Apache开源的日志门面框架。Spring中使用的日志框架就是JCL，使用起来非常简单。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import org.apache.commons.logging.LogFactory;
</span><span class='line'>
</span><span class='line'>private static final Log LOGGER = LogFactory.getLog(xx.class);
</span><span class='line'>
</span><span class='line'>LOGGER.info("...");</span></code></pre></td></tr></table></div></figure>


<p>使用JCL需要先引入JCL的依赖：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;dependency&gt;
</span><span class='line'>    &lt;groupId&gt;commons-logging&lt;/groupId&gt;
</span><span class='line'>    &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;
</span><span class='line'>    &lt;version&gt;xx&lt;/version&gt;
</span><span class='line'>&lt;/dependency&gt;</span></code></pre></td></tr></table></div></figure>


<p>再来看一下如何让JCL使用其他日志实现框架:</p>

<ol>
<li>这里当没有其他日志jar包存在的时候，JCL有自己的默认日志实现，默认的实现是对JUL的包装，即当没有其他任何日志包时，通过JCL调用的就是JUL做日志操作。</li>
<li>使用Log4j作为日志实现框架，那么只需要引入Log4j的jar包即可。</li>
<li><p>使用Log4j2作为日志实现，那么除了Log4j2的jar包，还需要引入Log4j2与Commons-Logging的集成包（使用SPI机制提供了自己的LogFactory实现）：</p>

<pre><code class="`"> &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-jcl&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Logback作为日志实现，那么由于Logback的调用是通过SLF4J的，因此需要引入jcl-over-slf4j包（直接覆盖了JCL的类），并同时引入SLF4J以及Logback的jar包。</p>

<pre><code class="`"> &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
</ol>


<h3>SLF4J</h3>

<p>SLF4J（Simple Logging Facade for Java）为Java提供的简单日志Facade。允许用户以自己的喜好，在工程中通过SLF4J接入不同的日志实现。与JCL不同的是，SLF4J只提供接口，没有任何实现（可以认为Logback是默认的实现）。</p>

<p>SLF4J的使用前提是引入SLF4J的jar包:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;!-- SLF4J --&gt;
</span><span class='line'>&lt;dependency&gt;
</span><span class='line'>   &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
</span><span class='line'>   &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
</span><span class='line'>   &lt;version&gt;xx&lt;/version&gt;
</span><span class='line'>&lt;/dependency&gt;</span></code></pre></td></tr></table></div></figure>


<p>再看一下SLF4J如何和其他日志实现框架集成。</p>

<ol>
<li><p>使用JUL作为日志实现，需要引入slf4j-jdk14包。</p>

<pre><code class="`"> &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Log4j作为日志实现，需要引入slf4j-log4j12和log4j两个jar包。</p>

<pre><code class="`"> &lt;!-- slf4j-log4j --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;

 &lt;!-- log4j --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Log4j2作为日志实现，需要引入log4j-slf4j-impl依赖。</p>

<pre><code class="`"> &lt;!-- log4j2 --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;
     &lt;version&gt;xx/version&gt;
 &lt;/dependency&gt;
 &lt;!-- log4j-slf4j-impl （用于log4j2与slf4j集成） --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Logback作为日志实现，只需要引入logback包即可。</p></li>
</ol>


<h2>六. 日志集成</h2>

<p>上面说到了四种日志实现框架和两种日志门面框架。面对这么多的选择，即便是一个刚刚开始做的应用，也会由于依赖的第三方库使用的日志框架五花八门而造成日志配置和使用上的烦恼。得益于JCL和SLF4J，我们可以很容易的把日志都统一为一种实现，从而可以进行集中配置和使用。这里就以用Logback统一日志实现为例：</p>

<ol>
<li><p>配置好Logback的依赖：</p>

<pre><code class="`"> &lt;!-- slf4j-api --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
 &lt;!-- logback --&gt;
 &lt;dependency&gt; 
     &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; 
     &lt;artifactId&gt;logback-core&lt;/artifactId&gt; 
     &lt;version&gt;xx&lt;/version&gt; 
 &lt;/dependency&gt;
 &lt;!-- logback-classic（已含有对slf4j的集成包） --&gt; 
 &lt;dependency&gt; 
     &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; 
     &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; 
     &lt;version&gt;xx&lt;/version&gt; 
 &lt;/dependency&gt;
</code></pre></li>
<li><p>切换Log4j到SLF4J</p>

<pre><code class="`"> &lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;
    &lt;version&gt;xx&lt;/verison&gt;
&lt;/dependency&gt;
</code></pre></li>
<li><p>切换JUL到SLF4J</p>

<pre><code class="`"> &lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt;
    &lt;version&gt;xx&lt;/verison&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>切换JCL到SLF4J</p>

<pre><code class="`"> &lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;
    &lt;version&gt;xx&lt;/verison&gt;
 &lt;/dependency&gt;
</code></pre></li>
</ol>


<p>这里需要注意的是，做了以上配置后，务必要排除其他日志包的存在，如Log4j。此外，在日常开发中经常由于各个依赖的库间接引入了其他日志库，造成日志框架的循环转换。比如同时引入了log4j-over-slf4j和slf4j-log4j12的情况，当使用SLF4J调用日志操作时就会形成循环调用。</p>

<p>笔者目前比较推崇的是使用SLF4J统一所有框架接口，然后都转换到Logback的底层实现。但这里需要说明的是Logback的作者是为了弥补Log4j的各种缺点而优化实现了SLF4J以及Logback，但不知为何作者又推出了Log4j2以期取代Log4j和Logback。所以，如果是一个新的项目，那么直接跳过Log4j和Logback选择Log4j2也是一个不错的选择, 官网也提供了Log4j到Log4j2的迁移说明。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[微服务杂谈]]></title>
    <link href="http://www.rowkey.me/blog/2019/05/30/msa/"/>
    <updated>2019-05-30T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/05/30/msa</id>
    <content type="html"><![CDATA[<p>这几年在Java工程师招聘时，会看到很多人的简历都写着使用了Spring Cloud做微服务实现，使用Docker做自动化部署，并且也会把这些做为自己的亮点。而比较有趣的这其中以小公司出来的人为绝大多数，大的公司出来的人简历上倒是很少提这些东西。</p>

<p>对于我自己来说，从15年就开始关注这一块，看过马丁.福勒最开始的关于微服务的论文、也看过不少对微服务的论证的英文文章和书，也研究过Spring Cloud、Sofa等开源实现以及Service mesh。考虑到我们公司研发团队人力不足、基础设施不完善，当初是没有推行微服务的。但随着看到上述的那种简历越来越多，有时候我也会疑问：难道真的不用微服务就落后了吗？公司的同事如果不掌握这些就真的没有竞争力了吗。而随着最近公司业务的逐步提升，研发人员越来越多，借着在梳理公司的微服务落地计划时，也梳理了一下微服务的相关知识点，也是本文的主要内容。</p>

<p>开篇之前先声明我对微服务的几点态度:</p>

<blockquote><ol>
<li>架构模式有很多，微服务不是唯一的选择也不是什么银弹。国内很多中小公司引入微服务都是在盲目追新，也能看出做此种技术选型的工程师基础架构素质的不足。</li>
<li>“你必须长的足够高才能使用微服务”。微服务基础设施，尤其是容器技术、自动化部署、自动化测试这些不完备，微服务形同虚设，不会带来什么质的提升。</li>
<li>微服务架构的关键不在于具体的实现，而在于如何合理地划分服务边界以及组织架构是否相匹配。不考虑研发团队的规模和组成就盲目上微服务是不良的技术选型。</li>
<li>Spring Boot是Spring全家桶的上层封装，并不是什么崭新的技术，也不是什么值得觉得成为自己杀手锏的技术。</li>
<li>Spring Cloud中Spring Cloud Netflix的组件是经过生产环境验证的，其他的则建议慎重选择。</li>
</ol>
</blockquote>

<!--more-->


<h2>微服务是什么</h2>

<p>微服务起源于2005年Peter Rodgers博士在云端运算博览会提出的微Web服务(Micro-Web-Service)，根本思想类似于Unix的管道设计理念。2014年，由Martin Fowler 与 James Lewis共同提出了微服务的概念，定义了微服务架构风格是一种通过一套小型服务来开发单个应用的方法，每个服务运行在自己的进程中，并通过轻量级的机制进行通讯（HTTP API）。关键的三点是<strong>small、automated以及lightweight</strong>。</p>

<p>对比SOA，微服务可以看做是SOA的子集，是轻量级的SOA，粒度更细的服务，独立进程、数据分离，更注重<strong>敏捷、持续交付、DevOps以及去中心化实践</strong>。其共同的<strong>架构原理</strong>：</p>

<ul>
<li>单一职责</li>
<li>关注分离：控制与逻辑相分离</li>
<li>模块化和分而治之</li>
</ul>


<p><strong>特点</strong>：</p>

<ul>
<li>用服务进行组件化</li>
<li>围绕业务能力进行组织</li>
<li>是产品而非项目</li>
<li>端点智能化和哑管道: 控制逻辑都在端点，管道仅仅是传输</li>
<li>全自动化部署</li>
<li>语言和数据的去中心化控制</li>
<li>面向失败设计</li>
<li>渐进式设计</li>
</ul>


<p>综合来看，其优缺点如下：</p>

<p><strong>优点</strong>：</p>

<ul>
<li>模块的强边界</li>
<li>独立部署</li>
<li>技术选型的多样性</li>
</ul>


<p><strong>缺点</strong>：</p>

<ul>
<li>分布式带来编程复杂度，远程调用的消耗</li>
<li>舍弃强一致性，实现最终一致性</li>
<li>操作复杂性要求有一个成熟的运维团队或者运维基础设施</li>
</ul>


<h2>为什么要采用微服务</h2>

<p>是否选择微服务取决于你要设计的系统的复杂度。微服务是用来把控复杂系统的，但是随之而来的就是引入了微服务本身的复杂度。需要解决包括自动化部署、监控、容错处理、最终一致性等其他分布式系统面临的问题。即使已经有一些普遍使用的解决方案，但是仍然是有不小的成本的。</p>

<p><img src="http://www.rowkey.me/post_images/msa/productivity.png" alt="" /></p>

<p>生产力和复杂度的关系如图所示，可见系统越复杂，微服务带来的收益越大。此外，无论是单体应用还是微服务，团队的技能都需要能够把控住。</p>

<p>马丁.福勒的一个观点是：除非管理单体应用的成本已经太复杂了（太大导致很难修改和部署），否则都不要考虑微服务。大部分应用都应该选择单体架构，做好单体应用的模块化而不是拆分成服务。</p>

<p>因此，<strong>系统一开始采用单体架构，做好模块化，之后随着系统变得越来越复杂、模块/服务间的边界越来越清晰，再重构为微服务架构是一个合理的架构演化路径。</strong></p>

<p><strong>四个可以考虑上微服务的情况</strong>：</p>

<ol>
<li>多人开发一个模块/项目，提交代码频繁出现大量冲突。</li>
<li>模块间严重耦合，互相依赖，每次变动需要牵扯多个团队，单次上线需求太多，风险大。</li>
<li>主要业务和次要业务耦合，横向扩展流程复杂。</li>
<li>熔断降级全靠if-else。</li>
</ol>


<p><strong>微服务的三个阶段</strong>：</p>

<ol>
<li>微服务1.0：仅使用注册发现，基于SpringCloud或者Dubbo进行开发。</li>
<li>微服务2.0：使用了熔断、限流、降级等服务治理策略，并配备完整服务工具和平台。</li>
<li>微服务3.0：Service Mesh将服务治理作为通用组件，下沉到平台层实现，应用层仅仅关注业务逻辑，平台层可以根据业务监控自动调度和参数调整，实现AIOps和智能调度。</li>
</ol>


<h2>微服务架构</h2>

<h3>先决条件</h3>

<ul>
<li>快速的环境提供能力：依赖于云计算、容器技术，快速交付环境。</li>
<li>基本的监控能力：包括基础的技术监控和业务监控。</li>
<li>快速的应用部署能力：需要部署管道提供快速的部署能力。</li>
<li>Devops文化：需要具有良好的持续交付能力，包括全链路追踪、快速环境提供和部署等，还需要快速的反应能力（对问题、故障的快速响应），开发和运维的协同工作。</li>
</ul>


<p>此外，根据康威定律和逆康威定律（技术架构倒逼组织架构改进），组织架构也是一个很关键的因素。对应于微服务架构，组织架构需要遵循以下原则：</p>

<ol>
<li>一个微服务由一个团队维护，团队成员以三人为宜。</li>
<li>单个团队的任务和发展是独立的，不受其他因素影响。</li>
<li>团队是功能齐全、全栈、自治的，扁平、自我管理。</li>
</ol>


<h3>基础设施</h3>

<p>微服务的推行需要依赖于很多底层基础设施，包括提供微服务的编译、集成、打包、部署、配置等工作，采用PaaS平台解决微服务从开发到运行的全生命周期管理，同时提供异构环境管理、容器资源隔离与互通、服务伸缩漂移、服务升级与回退、服务熔断与降级、服务注册与发现。</p>

<ol>
<li><p>最基本的基础设施</p>

<ul>
<li>进程间通讯机制：微服务是独立进程的，需要确定之间的通讯方式。</li>
<li>服务发现+服务路由: 提供服务注册中心，服务提供者和消费者通过服务发现获取服务的信息从而调用服务，实现服务的负载均衡等。</li>
<li>服务容错：微服务架构中，由于服务非常多，往往是一个服务挂了，整个请求链路的服务都受到影响，因此需要服务容错，在服务调用失败的时候能够处理错误或者快速失败，包括熔断、fallback、重试、流控和服务隔离等。</li>
<li>分布式事务支持：随着业务拆分为服务，那么有时候不可避免的就是跨服务的事务，即分布式事务的问题。原则是尽量避免分布式事务，如果无法避免那么可以使用消息系统或者CQRS和Event Sourcing方案来实现最终一致性。如果需要强一致性，则有两阶段提交、三阶段提交、TCC等分布式事务解决方案。</li>
</ul>
</li>
<li><p>提升外部服务对接效率和内部开发效率</p>

<ul>
<li>API网关: 负责外部系统的访问，负责跨横切面的公共层面的工作，包括安全、日志、权限控制、传输加密、请求转发、流量控制等。典型的网关功能即对外暴露一个域名xx.com，根据第一级目录做反向路由xx.com/user，xx.com/trade。每一级目录，如user、trade对应一个服务的域名。此外，API网关也可以有服务编排的功能（不推荐）。</li>
<li>接口框架: 规范服务之间通讯使用的数据格式、解析包、自解释文档，便于服务使用方快速上手等。</li>
</ul>
</li>
<li><p>提升测试和运维效率</p>

<ul>
<li>配置中心: 运行时配置管理能够解决动态修改配置并批量生效的问题。包括配置版本管理、配置项管理、节点管理、配置同步等。</li>
<li>持续交付：包括持续集成、自动化部署等流程。目的就是小步迭代，快速交付。

<ul>
<li>持续集成：这一部分并非是微服务特定的，对于之前的单体应用，此部分一般来说也是必要的。主要是指通过自动化手段，持续地对代码进程编译构建、自动化测试，以得到快速有效的质量反馈，从而保证代码的顺利交付。自动化测试包括代码级别的单元测试、单个系统的集成测试、系统间的接口测试。</li>
<li>自动化部署：微服务架构，节点数动辄上百上千，自动化部署能够提高部署速度和部署频率，从而保证持续交付。包括版本管理、资源管理、部署操作、回滚操作等功能。而对于微服务的部署方式，包括<strong>蓝绿部署、滚动部署以及金丝雀部署</strong>。</li>
</ul>
</li>
</ul>
</li>
<li><p>进一步提升运维效率</p>

<ul>
<li>服务监控: 微服务架构下节点数目众多，需要监控的机器、网络、进程、接口等的数量大大增加，需要一个强大的监控系统，能够提供实时搜集信息进行分析以及实时分析之上的预警。包括监控服务的<strong>请求次数、响应时间分布、最大/最小响应值、错误码分布</strong>等</li>
<li>服务跟踪：跟踪一个请求的完整路径，包括<strong>请求发起时间、响应时间、响应码、请求参数、返回结果</strong>等信息，也叫做全链路跟踪。通常的服务监控可以和服务监控做在一起，宏观信息由服务跟踪呈现，微观单个服务/节点的信息由服务监控呈现。服务跟踪目前的实现理论基本都是Google的Dapper论文。</li>
<li>服务安全：内网之间的微服务调用原则上讲应该是都可以互相访问写，一般并不需要权限控制，但有时候限于业务要求，会对接口、数据等方面有安全控制的要求。此部分可以以配置的方式存在于服务注册中心中，和服务绑定，在请求时由做为服务提供者的服务节点进行安全策略控制。配置则可以存储在配置中心以方便动态修改。</li>
</ul>
</li>
</ol>


<p>在微服务数量很少的情况下，以上基础设施的优先级自上而下降低。否则，仅仅依赖人工操作，则投入产出比会很低。</p>

<p>还需要提到的是Docker容器技术。虽然这个对于微服务并不是必须的，但是容器技术<strong>轻量级、灵活、与应用依存、屏蔽环境差异</strong>的特性对于持续交付的实现是至关重要的，即使对于传统的单体应用也能够给其带来交付效率的大幅提升。</p>

<h3>架构设计模式</h3>

<p>在引入微服务之后，传统的单体应用变为了一个一个服务，之前一个应用直接提供接口给客户端访问的架构不再适用。微服务架构下，针对不同设备的接口做为BFF层（Backend For Frontend），也叫做用户体验适配层，负责聚合、编排微服务的数据转换成前端需要的数据。服务之间的调用则在允许的情况下（允许延迟）尽可能使用异步消息传递方式，如此形成<strong>面向用户体验的微服务架构设计模式</strong>。如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/msa/msa-arch.png" alt="" /></p>

<p><strong>Client -> API Gateway -> BFF（Backend For Frontend） -> Downstream Microservices</strong></p>

<ul>
<li>后台采用微服务架构，微服务可以采用不同的编程语言和不同的存储机制。</li>
<li>前台采用BFF模式对不同的用户体验（如桌面浏览器，Native App，平板响应式Web）进行适配。</li>
<li>BFF、API Orchestration Layer，Edge Service Layer，Device Wrapper Layer是相同的概念。</li>
<li>BFF不能过多，过多会造成代码逻辑重复冗余。</li>
<li>可以将网关承担的功能，如Geoip、限流、安全认证等跨横切面功能和BFF做在同一层，虽然增加了BFF层的复杂性，但能够得到性能优势。</li>
</ul>


<h3>服务拆分</h3>

<p>微服务架构最核心的环节，主要是对服务的<strong>横向拆分</strong>。服务拆分就是讲一个完整的业务系统解耦为服务，<strong>服务需要职责单一，之间没有耦合关系，能够独立开发和维护</strong>。</p>

<p>服务拆分不是一蹴而就的，需要在开发过程中不断地理清边界。在完全理清服务之前，尽量推迟对服务的拆分，尤其是对数据库的拆分。</p>

<p><strong>拆分方法</strong>如下：</p>

<ul>
<li>基于业务逻辑拆分</li>
<li>基于可扩展拆分</li>
<li>基于可靠性拆分</li>
<li>基于性能拆分</li>
</ul>


<p>其中，对于无法修改的遗留系统，采用绞杀者模式：在遗留系统外面增加新的功能做成微服务方式，而不是直接修改原有系统，逐步的实现对老系统替换。</p>

<p><strong>拆分过程需要遵守的规范</strong>如下：</p>

<ul>
<li>先少后多、先粗后细（粒度）</li>
<li>服务纵向拆分最多三层，两次调用：Controller、组合服务、基础服务</li>
<li>仅仅单向调用，禁止循环调用</li>
<li>串行调用改为并行调用或者异步化</li>
<li>接口应该幂等</li>
<li>接口数据定义严禁内嵌，透传</li>
<li>规范化工程名</li>
<li>先拆分服务，等服务粒度确定后再拆分数据库。</li>
</ul>


<h3>微服务框架</h3>

<p>上面讲述了微服务架构的众多基础设施，如果每一个基础设施都需要自己开发的话是非常巨大的开发工作。目前市面上已经有不少开源的微服务框架可以选择。</p>

<ol>
<li><p>Spring Boot</p>

<p> Spring Boot是用来简化新Spring应用的初始搭建以及开发过程的。其虽然不是微服务框架，但其设计的初衷本质就是微应用的底层框架，因此非常适合用于微服务基础设施的开发以及微服务的应用开发。尤其对于Spring技术栈的团队来说，基于Spring Boot开发微服务框架和应用是自然而然的一个选择。</p></li>
<li><p>Dubbo&amp;&amp;Motan</p>

<p> Dubbo阿里开源的服务治理框架。其出现在微服务理念兴起之前，可以看做是SOA框架的集大成之作。但其仅仅包含了微服务基础设施的部分功能，诸如熔断、服务跟踪、网关等都没有实现。</p>

<ul>
<li>服务发现 ：服务发布、订阅、通知</li>
<li>高可用策略 ：失败重试（Failover）、快速失败（Failfast）、资源隔离 - 负载均衡 ：最少活跃连接、一致性 Hash、随机请求、轮询等</li>
<li>扩展性 ：支持 SPI 扩展（service provider interface）</li>
<li>其他 ：调用统计、访问日志等</li>
</ul>


<p>Motan则是微博开源的类似Dubbo的RPC框架，与Dubbo相比更轻量级。</p></li>
<li><p>Spring Cloud</p>

<p> Spring Cloud是基于Spring Boot实现的微服务框架，也可以看做一套微服务实现规范。基本涵盖了微服务基础设施的方方面面，包括配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等。其基于Spring生态，社区支持非常好。但其很多组件都没有经过生产环境验证，需要慎重选择。</p>

<p> Spring Cloud Netflix是Spring Cloud的一个子项目，是Spring对Netflix OSS的集成实现。基于Netflix的大规模使用，其中的已经被广泛使用的组件包括：</p>

<ul>
<li>Eureka： 服务注册和服务发现</li>
<li>Ribbon：弹性而智能的进程间和服务通讯机制，客户端负载均衡</li>
<li>Hystrix： 熔断器，在运行时提供延迟和容错的隔离</li>
<li>Zuul: 服务网关</li>
</ul>


<p>此外，另一个子项目Spring Cloud Alibaba则是Alibaba开源的基于Spring Boot的微服务框架，主要是对阿里云服务的支持。</p></li>
<li><p>Service Mesh</p>

<p> 上述的微服务框架都是侵入式的，服务化的过程都需要进行代码改造。Service Mesh则是下一代微服务架构，最明显的特征就是无入侵。采用sidecar模式来解决系统架构微服务化后的服务间通信和治理问题。如下图所示：</p>

<p> <img src="http://www.rowkey.me/post_images/msa/sm.png" alt="" /></p>

<p> 目前主流的开源实现包括：</p>

<ul>
<li>Linkerd和Envoy：以 sidecar 为核心，关注如何做好proxy，并完成一些通用控制平面的功能。缺乏对这些sidecar的管理和控制。</li>
<li>Istio和Conduit：目前最为流行的Service Mesh实现方案，集中在更加强大的控制平面(sidecar被称为数据平面)功能。前者由Google和IBM合作，并使用了Envoy作为sidecar部分的实现；后者则是Linkerd作者的作品。相比起来，Istio有巨头背景，功能强大，但可用性和易用性一直不高，Conduit则相对简单、功能聚焦。</li>
</ul>


<p>限于Service Mesh带来的性能延迟的开销以及sidecar对分布复杂性的增加，其对大规模部署(微服务数目多)、异构复杂(交互协议/开发语言类型多)的微服务架构带来的收益会更大。</p></li>
<li><p>Sofastack</p>

<p> 蚂蚁金服开源的构建金融级分布式架构的一套中间件。包括微服务开发框架、RPC框架、服务注册中心、全链路追踪、服务监控、Service Mesh等一整套分布式应用开发工具。</p>

<p> 特别值得一提的是SOFAMesh。其是对下一代微服务架构Service Mesh的大规模落地方案实践，基于 Istio改进和扩展而来，应该是国内最为成熟的开源Service Mesh方案。</p></li>
</ol>


<p>此外，需要提到<strong>Kubernetes(K8s)</strong>，其本身提供了部分的微服务特性支持（通过域名做服务发现），对代码无侵入。但服务调用、熔断这些都需要自己实现。</p>

<p>综上，目前公司技术团队技术栈是Spring，并且已有服务的实现都是基于Dubbo，因此选择Spring Cloud Netflix做为基础的微服务框架，对其中不成熟或者缺乏的组件，选择业界更为成熟的组件替代即可。</p>

<p><img src="http://www.rowkey.me/post_images/msa/msa-basic.png" alt="" /></p>

<ul>
<li>API网关：Zuul</li>
<li>服务注册中心：Dubbo</li>
<li>配置中心：disconf</li>
<li>服务监控&amp;&amp;全链路追踪：CAT</li>
<li>服务开发框架：Spring Boot</li>
<li>日志监控、告警：ELK + Elasalert</li>
<li>流量控制：Sentinel</li>
<li>消息队列：Kafka</li>
</ul>


<h2>参考资料</h2>

<ul>
<li><a href="https://www.ben-morris.com/whats-so-bad-about-monoliths-anyway/">What’s so bad about monoliths anyway…?!</a></li>
<li><a href="https://martinfowler.com/articles/microservices.html">Microservice</a></li>
<li><a href="https://martinfowler.com/bliki/MicroservicePremium.html">MicroservicePremium</a></li>
<li><a href="https://martinfowler.com/articles/microservice-trade-offs.html">Microservice Trade-Offs</a></li>
<li><a href="https://martinfowler.com/bliki/MicroservicePrerequisites.html">MicroservicePrerequisites</a></li>
<li><a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI2MzM3MzkyMg==&amp;mid=2247486544&amp;idx=1&amp;sn=999be8b4f06150b96d9a46ada6bb9ded&amp;chksm=eabd995dddca104bd3c6262d491572f7be9b2a763a43a388f66bd0e90e4bd60e5037727107e4&amp;mpshare=1&amp;scene=1&amp;srcid=0201lT7ZBVBGmTki8bYnmDgl%23rd">服务怎么拆？</a></li>
<li><a href="https://www.thoughtworks.com/insights/blog/bff-soundcloud">BFF@SoundCloud</a></li>
<li><a href="http://www.importnew.com/28798.html">Service Mesh 及其主流开源实现解析</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
